{"content": "ABINASH BAROOAH\n\n                                                                    E-MAIL:barooahabinash@yahoo.co.in \n                                                                                      Phone:+91 8971699155\n\n\nMobile Applications(IOS) developer having rich experience of over 6 years in the IT industry for creating feature rich mobile interfaces for IOS  apps. Lead iOS teams for prestigious clients such as ServiceMax (US), OMNI ISG (UK) and IBM on developing their core-products and various projects. Increased user adaptability, client satisfaction are among some of the major achievements. Proven experience in  Iphone and Ipad apps  with more than 6.5 years of experience in handling projects, currently spearheading with Infinite Computer Solutions\n\n\nEducation:         B.Tech\n\nSkills:\nMobile Technologies: iOS,Android,IBM Mobile First\nLanguages: C, Objective C, Swift,Javascript,Angular \nTechnologies: IOS, Salesforce.com,IBM Mobile First,Ionic,IBM Watson Services& APIs,IBM Bluemix\nDatabases: Sqlite,Workbench,Force.com\nGood knowledge of database management and design .Having good knowledge of sql.\nCapable of adapting to any new technology and a willingness to learn new technologies.\nGot Peer to Peer award for excellent team player which is distributed yearly once and awarded 4 times spot award \nGot an Agile Explorer&fundamentals badge from IBM\nGot IBM Bluemix essentials badge from IBM\n\n\nSignificant Projects :\n\n\n\n\n1)Project:\tIBM Personality Insights\nClient:\tIBM\nEnvironment:\tXcode, Mac OS X.,Swift\nFrameworks:\tCocoa Touch,UIKit,,AVFoundation\nRole:\t Lead Developer\nLanguages Used: Swift3.0 \nDuration: 2 Months\nProject Profile:\t\t   \nThis project involved developing an application which reads the twitter handler from a given QR Code and feeds the handler to the IBM Watson API.IBM Watson offers a service called Personality Insights where it gives the user a detailed analysis of his personality based on his tweets.The same analysis can be mailed to the user in the form of a PDF if he wishes to review it later.\nResponsibilities:\n* Effort estimation.\n* Interacting with client.\n* Developing all the features as well as the UI of the application.\n* Distributing iOS device builds via Test Flight for the client device. \n* Unit testing\n\n2)Project:\tPMI-iSMS\nClient:\tIBM,PMI\nEnvironment:\tXcode, Mac OS X. \nFrameworks:\tCocoa Touch,UIKit.,Pasteboard\nRole:\t Developer\nLanguages Used: Objective C\nDuration: 10 Months\nProject Profile:\t\t   \nThis is an Ipad Application meant for the employees of PMI(Philip Morris International) who undertake daily visits to different shops to sell cigarettes.Its a complex project involving a back office where a data sync occurs frequently with the IOS application.These employees perform a download  and upload operation  during the beginning and the end of the visits.They get all the customer data,planned visits as well as the activities they need to perform on that day.They can perform all these activities in the app and upload the results.This application is being used by more than 40 countries worldwide.\n\nResponsibilities:\n* Effort estimation.\n* Interacting with client.\n* Develop new modules and features like agreements,POSM etc\n* Integrating Field Planning tool where the user can push activities and related customers data via a different app using pasteboard.\n* Unit testing\n\n\n\n\n3)Project:\tEshop Mobile\nClient:\tIBM\nEnvironment:\tXcode, Mac OS X. \nFrameworks:\tCocoa Touch,UIKit,Touch ID.\nRole:\t Developer\nLanguages Used: Objective C\nDuration: 8 Months\nProject Profile:\t\t   \nThis project involved developing an online shopping application for the Iphone and Ipad.It is an online self service secured application that has been designed to support end user device roll outs.It supports End user services with the end to end one stop shop .It provides a self-service online, robust, secured portal shop for the procurement of end user devices \nResponsibilities:\n* Effort estimation.\n* Interacting with client.\n* Developing all the features as well as the UI of the application.\n* Distributing iOS device builds via Test Flight for the client device. \n* Unit testing\n\n\n\n\n\n4)Project:\tServiceMax iPad\nClient:\tServiceMax \nEnvironment:\tXcode, Mac OS X.\nFrameworks:\tCocoa Touch,UIKit\nRole:\tDeveloper\nLanguages Used: Objective C,Apex\nDuration: 12 Months\nProject Profile:\t\t\t\nServiceMax, one of the major ISVs of Salesforce, has Force.com based products on the app-exchange Field Service Automation. This project involved developing an online mobile application interfacing with the existing Force.com based Field Service Application.\nResponsibilities:\t\t\n* Analyzing requirement and developing a part of application.\n* Create and consume REST based Web services to access data from cloud (salesforce.com).\n* Functional testing.\n* Creating the offline version of the app.\n\n\nItunes Link: https://itunes.apple.com/us/app/servicemax-mobile/id514315119?mt=8\n\n\n\n\n5)Project:   Restopod,Pos for Smart Restaurants.\n        Client:   RestoPod LLC.( http://www.restopod.com)\n\nEnvironment:\tXcode, Mac OS X.\nFrameworks:\tCocoa Touch,UIKit\nRole:\tLead Developer\nLanguages Used: Objective C,Apex\nDuration: 6 Months\nProject Profile:\t\t\t\nRestopod is a cloud based restaurant pos that runs on ipod and iphone.This app has been securely hosted on database.com,by sales force .com cloud platform.This application is a smart solution for restaurant owners where they can manage and deliver their orders at the click of a finger.\n\nResponsibilities:\n* GUI implementation and performed software coding for functionality of module called kitchen display system.\n* GUI implementation for showing absolute sales report as a user readable format.\n* Implemented payment gateway.\n* Designed and implemented an independent kitchen display system only for the Ipad. \n\n\nItunes Link-  https://itunes.apple.com/us/app/restopod-mobile-pos/id519670061?mt=8\n\n\n\n\n6)Project:\tSEPODS (Small Per-iOperative Data Systems) for IPad(Beta)\nEnvironment:\tXcode, Mac OS X. \nFrameworks:\tCocoa Touch,UIKit\nRole:\tLead Developer\nLanguages Used: Objective C\nDuration: 4 Months\nProject Profile:\t\t\t\nSEPODS is a Ipad application that functions as a portable anesthesia information management system (AIMS) to facilitate the collection of accurate and comprehensive clinical data.It mains relevance comes at the time of preparing a patient for surgery and determining the correct readings of his pulses,pressure etc  and saving the data related to that patient.\n\nResponsibilities:\n* Designing the data model as per the business needs.\n* GUI design and implementation.\n* Interacting with client on daily basis and understanding and developing the needs as per their requirement.\n* Given demo presentation to customers and provided application support to users.\n\n\n\n\n7)Project:\tCauseview Events\nClient:\tBreakeven Inc\nEnvironment:\tXcode, Mac OS X. \nFrameworks:\tCocoa Touch, UIKit.\nRole:\tLead Developer\nLanguages Used: Objective C,Apex\nDuration: 6 Months\nProject Profile:\t\t   \nCauseview provides nonprofit organizations with user-friendly applications so they can focus\non advancing their cause and building relationships.\nCauseview Events works in conjunction with salesforce.com CRM.\nCheck your guest in by scanning tickets or searching for attendees. Capture guest contact information and stay organized faster than ever.\nResponsibilities:\n* Effort estimation, Architecture and UI/UX Design.\n* Problem solving among team.\n* Distributing iOS device builds via Test Flight for the client device. \n* Functional testing, bugs fixing and uploading app to App Store.\n\n\nItunes Link:  https://itunes.apple.com/us/app/causeview-events/id709003008?mt=8\n\n\n\n8)Project:\tSGS Quotes\nClient:\tDycusa (Datta Yoga Center USA)\nEnvironment:\tXcode, Mac OS X. \nFrameworks:\tCocoa Touch,UIKit\nRole:\tLead Developer\nLanguages Used: Objective C\nDuration: 2 Months\nProject Profile:\t\t\t\nSGS Quotes is a wonderful collection of words of wisdom by Sri Ganapathy Sachchidananda Swamiji.This app allows to view various categories of quotes from the collection, can be set as favorites and also schedule alarms to view random quotes daily.\nThis app facilitates to share quotes text among friends by messaging and sharing e-cards by email, facebook and twitter.\nResponsibilities:\n* Effort estimation, Architecture and UI/UX Design.\n* Designing the data model as per the business needs.\n* Distributing iOS device builds via Test Flight and Android builds for the client device. \n* Functional testing, bugs fixing and uploading app to App Store.\n\nItunes Link:  https://itunes.apple.com/app/sgs-quotes-mobile/id587378482?mt=8\n\n\n\n9)Project:\tLalita Sahasranama\nClient:\tDycusa (Datta Yoga Center USA)\nEnvironment:\tXcode, Mac OS X.\nFrameworks:\tCocoa Touch,UIKit\nRole:\tLead Developer\nLanguages Used: Objective C\nDuration: 2 Months\nProject Profile:\t\t\t\nLalita Sahasranama is a musical application dedicated to the devotees of goddess Lalita where \na musical composition sung by Sri Ganapathy Sachchidananda Swamiji is played along with a constant change of images of the goddess in the UX .Here the user can recite the slokas along with the singer .The lyrics are displayed synchronously with the song.This app is for both IOS and Android\nResponsibilities:\t\t\n* Effort estimation, Architecture and UI/UX Design.\n* Lead the team in developing the app in android also.\n* Synchronizing the song with the lyrics.\n* Distributing iOS device builds via Test Flight and Android builds for the client device. \n* Functional testing, bugs fixing and uploading app to App Store.\n\n\nItunes Link: https://itunes.apple.com/us/app/lalita-sahasranama/id720123738?mt=8\n\n\n\n10)Project:\tSGS BIRDS\nClient:\tDycusa (Datta Yoga Center USA)\nEnvironment:\tXcode, Mac OS X.\nFrameworks:\tCocoa Touch,UIKit\nRole:\tDeveloper\nLanguages Used: Objective C\nDuration: 2 Months\nProject Profile:\t\t\n: SGS Birds is a beautiful app that brings you stories from Shuka Vana SGS Birds Park in Mysore India. It displays bird�s information from a locally stored database. The information is synched to the database from salesforce.\n\nRESPONSIBILITY:\n* GUI design for the application. Implemented the customized split view controller to display the bird�s information.\n* Developed the synch logic to sync bird information to and from Salesforce.com server.\n* Support offline saving of data as well.\n\n\n\n\n11)Project:\tOMNI ISG\nClient:\tOMNI ISG\nEnvironment:\tXcode, Mac OS X. \nFrameworks:\tCocoa Touch,UIKit\nRole:\tLead Developer\nLanguages Used: Objective C,Apex\nDuration: 2 Months\nProject Profile:\t\t   \nThis project involved developing an online as well as offline mobile application interacting with salesforce cloud.This app uses the latest salesforce SDK.It involves retrieving data as well saving data online and offline.\nResponsibilities:\n* Effort estimation, Architecture and UI/UX Design.\n* Interacting with client.\n* Distributing iOS device builds via Test Flight for the client device. \n* Functional testing, bugs fixing and uploading app to App Store.\n\n\nEMPLOYERS:\n\n1)Working as a Software Engineer in INFINITE COMPUTER SOLUTIONS from October 2014 till now.\n\n2)Worked with BIT ORDER TECHNOLOGIES as a Senior Software Developer from June 2011 till September 2014\n\n\n1)Training:\tiPhone and iPad  Application development from Freshers Lab, Bangalore.\nDuration : 6 Months\n\n2)Training:\tHas undergone training on IBM MobileFirst,IONIC Frameworks\nDuration : 3 Months\n\n\nEDUCATIONAL QUALIFICATION:\n\n* Completed B.Tech  in Electrical  and Electronics from Sikkim Manipal Institute of Technology in 2008 with an aggregate of 64.3%.\n* Completed Pre-University from Salt Brook Academy in 2004 with 66.6%.\n* Completed SSLC from Don Bosco High school in 2002 with 79.3%. \n\nPERSONAL SKILLS:\n* Good Communication skills. Ability to clearly communicate ideas and messages.\n* Good team player.\n* Ability to quickly analyze situation and being proactive.\n* Ability to manage and support multiple projects.\n \nPERSONAL DETAILS:\n\n* Full name                     : Abinash Barooah\n* Father�s name\t             :Late Binit Pawan Barooah \n* Gender \t\t: Male                                                  \n* Date of birth\t\t: 6 September 1985.                                 \t\t\t.\n* Languages\t\t: English, Hindi, Assamese.\n* Hobbies\t\t: Swimming, reading books, watching movies.\n* Temporary Address    :\n\nDECLARATION:\n\nI hereby declare that above mentioned details are true and correct to the best of my knowledge \n\nPlace: Bangalore\t\t\t\t\t\t\t\tAbinash Barooah","annotation":[{"label":["Location"],"points":[{"start":12398,"end":12406,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":12282,"end":12282,"text":"C"}]},{"label":["Skills"],"points":[{"start":11685,"end":11685,"text":"C"}]},{"label":["Skills"],"points":[{"start":11610,"end":11610,"text":"C"}]},{"label":["Skills"],"points":[{"start":11597,"end":11597,"text":"C"}]},{"label":["Skills"],"points":[{"start":11526,"end":11526,"text":"C"}]},{"label":["Skills"],"points":[{"start":11395,"end":11395,"text":"C"}]},{"label":["Skills"],"points":[{"start":11384,"end":11384,"text":"C"}]},{"label":["Skills"],"points":[{"start":11368,"end":11368,"text":"C"}]},{"label":["Skills"],"points":[{"start":11330,"end":11330,"text":"C"}]},{"label":["Location"],"points":[{"start":11240,"end":11248,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":11089,"end":11089,"text":"C"}]},{"label":["Skills"],"points":[{"start":11015,"end":11015,"text":"C"}]},{"label":["Skills"],"points":[{"start":10449,"end":10449,"text":"C"}]},{"label":["Skills"],"points":[{"start":10439,"end":10449,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":10384,"end":10384,"text":"C"}]},{"label":["Skills"],"points":[{"start":10324,"end":10324,"text":"C"}]},{"label":["Skills"],"points":[{"start":9768,"end":9768,"text":"C"}]},{"label":["Skills"],"points":[{"start":9758,"end":9768,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":9708,"end":9708,"text":"C"}]},{"label":["Skills"],"points":[{"start":9654,"end":9654,"text":"C"}]},{"label":["Skills"],"points":[{"start":9627,"end":9627,"text":"C"}]},{"label":["Skills"],"points":[{"start":8765,"end":8765,"text":"C"}]},{"label":["Skills"],"points":[{"start":8755,"end":8765,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":8700,"end":8700,"text":"C"}]},{"label":["Skills"],"points":[{"start":8646,"end":8646,"text":"C"}]},{"label":["Skills"],"points":[{"start":8619,"end":8619,"text":"C"}]},{"label":["Skills"],"points":[{"start":7815,"end":7815,"text":"C"}]},{"label":["Skills"],"points":[{"start":7805,"end":7815,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":7750,"end":7750,"text":"C"}]},{"label":["Skills"],"points":[{"start":7695,"end":7695,"text":"C"}]},{"label":["Skills"],"points":[{"start":7668,"end":7668,"text":"C"}]},{"label":["Skills"],"points":[{"start":7251,"end":7251,"text":"C"}]},{"label":["Skills"],"points":[{"start":7183,"end":7183,"text":"C"}]},{"label":["Skills"],"points":[{"start":7178,"end":7178,"text":"C"}]},{"label":["Skills"],"points":[{"start":7120,"end":7120,"text":"C"}]},{"label":["Skills"],"points":[{"start":6974,"end":6974,"text":"C"}]},{"label":["Skills"],"points":[{"start":6926,"end":6926,"text":"C"}]},{"label":["Skills"],"points":[{"start":6916,"end":6926,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":6859,"end":6859,"text":"C"}]},{"label":["Skills"],"points":[{"start":6794,"end":6794,"text":"C"}]},{"label":["Skills"],"points":[{"start":6777,"end":6777,"text":"C"}]},{"label":["Skills"],"points":[{"start":6062,"end":6062,"text":"C"}]},{"label":["Skills"],"points":[{"start":6052,"end":6062,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":5997,"end":5997,"text":"C"}]},{"label":["Skills"],"points":[{"start":5136,"end":5136,"text":"C"}]},{"label":["Skills"],"points":[{"start":5126,"end":5136,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":5071,"end":5071,"text":"C"}]},{"label":["Skills"],"points":[{"start":4999,"end":4999,"text":"C"}]},{"label":["Skills"],"points":[{"start":4978,"end":4978,"text":"C"}]},{"label":["Skills"],"points":[{"start":4794,"end":4794,"text":"C"}]},{"label":["Skills"],"points":[{"start":4683,"end":4683,"text":"C"}]},{"label":["Skills"],"points":[{"start":4293,"end":4293,"text":"C"}]},{"label":["Skills"],"points":[{"start":4283,"end":4293,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":4233,"end":4233,"text":"C"}]},{"label":["Skills"],"points":[{"start":4171,"end":4171,"text":"C"}]},{"label":["Skills"],"points":[{"start":3508,"end":3508,"text":"C"}]},{"label":["Skills"],"points":[{"start":3498,"end":3508,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":3437,"end":3437,"text":"C"}]},{"label":["Skills"],"points":[{"start":3382,"end":3382,"text":"C"}]},{"label":["Skills"],"points":[{"start":2424,"end":2424,"text":"C"}]},{"label":["Skills"],"points":[{"start":2414,"end":2424,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":2351,"end":2351,"text":"C"}]},{"label":["Skills"],"points":[{"start":2292,"end":2292,"text":"C"}]},{"label":["Skills"],"points":[{"start":1763,"end":1763,"text":"C"}]},{"label":["Skills"],"points":[{"start":1616,"end":1620,"text":"Swift"}]},{"label":["Skills"],"points":[{"start":1546,"end":1546,"text":"C"}]},{"label":["Skills"],"points":[{"start":1528,"end":1532,"text":"Swift"}]},{"label":["Skills"],"points":[{"start":1486,"end":1486,"text":"C"}]},{"label":["Skills"],"points":[{"start":1128,"end":1128,"text":"C"}]},{"label":["Skills"],"points":[{"start":906,"end":913,"text":"Angular "}]},{"label":["Skills"],"points":[{"start":895,"end":904,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":889,"end":893,"text":"Swift"}]},{"label":["Skills"],"points":[{"start":886,"end":886,"text":"C"}]},{"label":["Skills"],"points":[{"start":876,"end":886,"text":"Objective C"}]},{"label":["Skills"],"points":[{"start":873,"end":873,"text":"C"}]},{"label":["Education"],"points":[{"start":794,"end":801,"text":"  B.Tech"}]},{"label":["Skills"],"points":[{"start":756,"end":756,"text":"C"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"ABINASH BAROOAH"}]}],"extras":null,"metadata":{"first_done_at":1532689294000,"last_updated_at":1532689294000,"sec_taken":117,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Amit Shinde\t\t                    amitshinde123@gmail.com +91 8879590576\n Machine Learning Engineer\t\t       \t\t\t      Mumbai\nSummary\n\n> 6.5 years of immersive experience in IT consulting including Machine learning/Natural language processing and other technologies \n> Experience of building data products and predictive models to enable better decision making. \n> Worked on wide variety of analytics projects.� \n> Strong experience of developing predictive models in R, Python and Matlab\n> Domain expertise in Manufacturing, IT Infrastructure, High Tech, Human Resources, Public Sector, Pharmaceutical, Insurance, Retail, Trading etc.\n\nSkills/ Tools\nPython, R, Scikit-learn, NLTK, Spacy, Gensim, Mallet, Pandas, Numpy, NN, CNN, RNN, LSTM, GRN, AWS, SQL, Splunk, Tableau, Hadoop, ABAP, Web services etc.\n\nEducation\nBTech, Mumbai University (First Class)\t\t\t\t\t\t\t    Jun�11\n\nExperience Summary\n\nLead Data Scientist � Accenture\t\t            \t\t\t   Jul�17 � Present\n\n> Working in the service optimization team to develop solutions that can help in engineering and optimizing resources for infrastructure services within Accenture which supports close to 4 lakh employees \n> Current use-cases (Details under projects)\n* Incident analysis and optimization for noise reduction.\n* Bandwidth and network optimization.\n* Log File Anomaly Detection.\n\nProduct Lead (AI) � Accenture \t\t\t\t\t\t Jul�15 � May�17\n\n> Product lead for AI product suite under Accenture Enterprise Services for Government(AESG) solution which is used by governments across the globe.\n> Pioneered the vision and scope of AI products in current ERP SaaS offering. \n> Responsible for communicating with the clients (20+) CXO�s to understand the problems needed to be solved and preparing an implementation plan.\n> Delivered four end to end products till date (ask for details)\n\n> Responsibilities:\n* Explore available data and come up with predictive modelling ideas�\n* Connect with business and marketing team to understand model use cases, connect with data team to understand data available�\n* Build predictive model and assist development team with implementation�\n* Conduct qualitative validations by analyzing model governance policies, testing controls and assessing whether model is fit for use�\n* Conduct quantitative validation by back-testing and building scoring engine prototypes to find out implementation bugs\n* Contribute towards development and scaling up AI practice by building internal tools, accelerators and POCs�\n\nData Scientist � Accenture                             \t      \t\t\t             Jun�15 � Jul�15\n\n> Built a chatbot using Question pair matching using Siamese LSTM Network for similarity match for Walmart employees to be deployed on their workday solution. The bot helped the employees navigate through HR and pay related queries in an autonomous manner.\n\n\n\nConsultant(SAP-ML) � CMC Ltd. \t\t\t\t\t                         March�14 � Jun�15\n\n> Worked on the SAP � Business Process Management (BPM) product implementation for 4 clients pan India.\n> Built a NLP pipeline to be integrated with the ERP offering which helped navigate through the business workflows of the organization.\n> Responsible for requirement gathering, developing technical blueprints and designing the integration flow of the process engine.\n\nSenior Executive (SAP) � Godrej Infotech Ltd. \t\t\t\t\t   Feb�12 � Mar�14\n\n> Onsite consultant for ABAP HR and Workflow development. \n> Worked in multiple client facing roles across various geographies across the globe.\n> `Development of Multilevel workflows for Leave and Travel Request Approval to be processed through ESS/MSS Systems with extended mail notification to Outlook.\n\nTrainee � Mphasis Ltd \t\t\t\t\t   \t\t\t Sep�11 � Dec�11\n\n> Underwent training on SQL, Java & ABAP\n\n\nMajor Projects\n\nIncident analysis and optimization for noise reduction \n\nAnalyze manual and automated incidents using NLP to find patterns and predict the trends.\nDeveloped an unsupervised cluster of the problem tickets using LDA, HDP to extract the inherent classes of each ticket.\n\nBandwidth and network optimization.\n\nDeveloped a deep learning model using two layer LSTM network in Keras to predict the sequence output for bandwidth utilization across 245 Accenture office locations worldwide. \nThe model demonstrated an accuracy measure of 93% on test set.\n\n\n\n\n\nLog File Anomaly Detection\n\nUsing the recent development in text analysis using Deep neural networks, developed a method to reduce the effort needed to analyze the log file generated during a fail run. This is done by highlighting the most probably useful text in the failed log file , which can assist in debugging the cause of failure. \nWe were able to show reduction in log file by 85% using raw log files while keeping more than 77% of the useful information intact.\n\n\nAuto-Classification of Incidents\n\nThis model was built to work on ServiceNow and other ITSM platforms. Its job is to classify the incident when raised to any of the available assignment groups. The model is trained on group assignments done by SME�s in the past and the existing scope of the project available. \nWon Innovation Award for this product,\n\n\nAuto-Resolution of tickets\n\nThis model was built to work on ServiceNow and other ITSM platforms. Its job is to predict the incident resolution steps. It feeds off similar ticket analyzer tool which is built on a sophisticated text mining pipeline in python, AdaBoost algorithms and TF-IDF and partial PCA for feature engineering.\n\nAnalytics Platform�\n\nClients use many ERPs such as SAP, Oracle Financial to maintain financial data, though different ERPs are used data captured and analysis requirement remains same for each client�\nAudit analytics platform was built to transform this data to single data model, provide users interface for conducting exploratory data analysis, visualization and built analytics tools such as anomaly detection, duplication on top of this data model��\nThis project involved designing data model, creating scripts to get data from ERPs, creating ETL scripts to transform data to new data model, understanding business problems, crating interactive data exploration and visualization templates, perform feature engineering and training anomaly detection algorithms. Visualization was built using SPLUNK","annotation":[{"label":["Skills"],"points":[{"start":6022,"end":6022,"text":"R"}]},{"label":["Skills"],"points":[{"start":5608,"end":5608,"text":"R"}]},{"label":["Skills"],"points":[{"start":5528,"end":5528,"text":"R"}]},{"label":["Skills"],"points":[{"start":5163,"end":5163,"text":"R"}]},{"label":["Skills"],"points":[{"start":3759,"end":3762,"text":"ABAP"}]},{"label":["Skills"],"points":[{"start":3752,"end":3755,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3747,"end":3749,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3570,"end":3570,"text":"R"}]},{"label":["Skills"],"points":[{"start":3395,"end":3395,"text":"R"}]},{"label":["Skills"],"points":[{"start":3389,"end":3392,"text":"ABAP"}]},{"label":["Skills"],"points":[{"start":3164,"end":3164,"text":"R"}]},{"label":["Skills"],"points":[{"start":3076,"end":3076,"text":"R"}]},{"label":["Skills"],"points":[{"start":2789,"end":2789,"text":"R"}]},{"label":["Skills"],"points":[{"start":1831,"end":1831,"text":"R"}]},{"label":["Skills"],"points":[{"start":1619,"end":1619,"text":"R"}]},{"label":["Skills"],"points":[{"start":1598,"end":1598,"text":"R"}]},{"label":["Skills"],"points":[{"start":777,"end":780,"text":"ABAP"}]},{"label":["Skills"],"points":[{"start":747,"end":749,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":738,"end":738,"text":"R"}]},{"label":["Skills"],"points":[{"start":726,"end":726,"text":"R"}]},{"label":["Skills"],"points":[{"start":656,"end":656,"text":"R"}]},{"label":["Skills"],"points":[{"start":648,"end":653,"text":"Python"}]},{"label":["Skills"],"points":[{"start":612,"end":612,"text":"R"}]},{"label":["Skills"],"points":[{"start":559,"end":559,"text":"R"}]},{"label":["Skills"],"points":[{"start":479,"end":484,"text":"Matlab"}]},{"label":["Skills"],"points":[{"start":468,"end":473,"text":"Python"}]},{"label":["Skills"],"points":[{"start":465,"end":465,"text":"R"}]},{"label":["Skills"],"points":[{"start":194,"end":238,"text":" Machine learning/Natural language processing"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Amit Shinde"}]}],"extras":null,"metadata":{"first_done_at":1532689009000,"last_updated_at":1532689009000,"sec_taken":57,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Brijesh Kumar\n\n\nMail:   brijesh365@gmail.com\n\nMobile: +91 8800288177\n\nCareer Objective:\nTo be excellent software professional and move into higher technology areas which provide an environment to improve my technical and analytical abilities.\n \nWork History:\n\nCurrently working at Google India pvt ltd as Senior Specialist in Tools Development via Global Logic.\nSept2014 to Present (3.4 years)\n\nGoogle app engine, Python, webapp2 development using Jquery and Google closure.\n\nPreviously worked with One97 Communications (P) Limited as Senior Software Developer.\nJun 2012 to Sep 2014  (2 year(s) - 3 month(s))\n\nManaging Hadoop and hive,\nPython ETL development,\nVectorwise ETL development,\nDjango panels\n\nPreviously worked with Bygsoft Pvt Ltd. as Software Developer\nJul 2010 to May 2012 (1 year(s) - 10 month(s))\n\nworked on client-site (Symantec, Pune) for 10 months.\n\nTechnical Background/Software Proficiency:\n\nOperating Systems :  Linux\nLanguages              :  Python, Shell, Perl, C, C++, Javascript\nDatabases              :  Hadoop, hive , MySQL, Postresql, GAE dataStore, mongodb,  vectorwise\nFrameworks           :  Django, Plone, Tipfy(GAE), Jquery, flask, webapp2\nWeb Server            :  Apache, GAE\nWeb languages      :  Javascript, XML, CSS, HTML, Jquery, bootstrap css, Google Closure.\n\nEducational Background:  \n\nB.E. (Computer), 2010, A.I.T/ Pune University, First class � 60.00%\nS.S.C, 2003 � C.B.S.E, First Class with Distinction � 79.98%\nH.S.C, 2005 � C.B.S.E, First Class � 69.77%\n\nWork Details:  \n\n\n\nProject Title:�Internal Project\nClient:� Google\nEmployment Type:�Full-Time\nDuration:�Sep 2014 - Present\nProject Location:� Google\nSite:�Onsite\nRole:�Sr. Programmer\nTeam Size:�5\nSkill Used:�Python, Google App Engine, Django, jQuery, JS, CSS, HTML, webapp2\nRole Description:� �i. Development of new modules from scratch based on given requirements.\n                              ii. Bug fixes, refactoring, and scaling old code.\n                              Iii. Achieving 100% code coverage in unit tests.\nProject Details:� Enhancing features of a Google website (developers.google.com) created in Python, Django, GAE. Role is to add new modules from scratch as per requirement, maintain it and achieve 100% code coverage in unit tests.\n\n\n\n\n\n\nProject Title:�FFL � Football fives league\nClient:� Addrush\nEmployment Type:�Full-Time\nDuration:� Dec 2016 � Feb 2017\nProject Location:� Gurgaon\nSite:�Offsite\nRole:�Project Leader\nTeam Size:�1\nSkill Used:�Python, Django, jquery, HTML, CSS, MySQL,\nRole Description:� Design and development from scratch.\nProject Details:� Football five league organises football event between multiple teams\n                           http://ffl.addrush.com.\n\n\nOrganization: One97 Communications pvt. Ltd.\n\nProject Title:�Reprocessing module for ETL.\nClient:�One97 Communications pvt. ltd.\nEmployment Type:�Full-Time\nDuration:�Jun 2014 - Present\nProject Location:�One97 Communications pvt. ltd.\nSite:�Onsite\nRole:�Sr. Programmer\nTeam Size:�1\nSkill Used:�Python, vectorwise, shell scripts, mysql.\nRole Description:�Development and testing of reprocessing module built using python for mysql database.\nProject Details:�Development and testing of reprocessing module built using python for mysql database.\n\nProject Title:�Integration and development of new version of ETL code with mysql.\n\nClient:�One97 Communications pvt. ltd.\n\nEmployment Type:�Full-Time\nDuration:�Dec 2013 - May 2014\n\nProject Location:�One97 Communications pvt. ltd.\nSite:�Onsite\n\nRole:�Sr. Programmer\nTeam Size:�1\n\nSkill Used:�Python, vectorwise, shell scripts.\n\nRole Description:�Development and testing of new version ETL code in python for mysql database.\nIntegration of telecom operators data with mysql.\n\nProject Details:�Development and testing of new version ETL code in python for mysql database.\nIntegration of telecom operators data with mysql.\n\n\n\n\nProject Title:�Integration and development of ETL code with vectorwise. \nClient:�One97 Communications pvt. ltd.\nEmployment Type:�Full-Time\nDuration:�Aug 2013 � Nov 2013\nProject Location:�One97 Communications pvt. ltd.\nSite:�Onsite\nRole:�Sr. Programmer\nTeam Size:�1\nSkill Used:�Python, vectorwise, shell scripts\nRole Description:�Development and testing of ETL code in python for Ingres vectorwise database.\nIntegration of telecom operators data with vectorwise.\nProject Details:�Development and testing of ETL code in python for Ingres vectorwise database.\nIntegration of telecom operators data with vectorwise.\n\nProject Title:�Web Panel for Hadoop data Management\nClient:�One97 Communications pvt. ltd.\nEmployment Type:�Full-Time\nDuration:�Jan 2013 � Jun 2013\nProject Location:�One97 Communications pvt. ltd.\nSite:�Offsite\nRole:�Sr. Programmer\nTeam Size:�2\nSkill Used:�Hadoop, hive, python, Django, shell scripts, jquery.\nRole Description:�Integration of business units (telecom operators) with hadoop using tools like hive, python, django, shell scripts.\nstoring and managing client data on hadoop in optimized way.\nProject Details:�Design and develop web panel for hadoop data management.\nIt includes data reconciliation of hadoop with central servers, data loading to hadoop for sequence and text files, Scheduling jobs for other process too.\n\n\n\n\nProject Title:�Hadoop management(Administration)\nClient:�One97 Communications pvt. ltd.\nEmployment Type:�Full-Time\nDuration:�May 2012 - Present\nProject Location:�One97 Communications pvt. ltd.\nSite:�Onsite\nRole:�Project Leader\nTeam Size:�1\nSkill Used:�Hadoop, hive, python, shell scripts.\nRole Description:�Integration of business units (telecom operators), paytm with hadoop using tools like hive, python, shell scripts.\nProject Details:�Integration of business units (telecom operators) with hadoop using tools like hive, python, shell scripts.\nstoring and managing client data on hadoop.\nMonitoring GUI for tracking hadoop activities in python.\n\n\nOrganization: Bygsoft Pvt. Ltd. \n\n\nProject Title:�Yadesk and interpreview\nClient:�Bygsoft\nEmployment Type:�Full-Time\nDuration:�Jan 2012 - May 2012\nProject Location:�Pune\nSite:�Onsite\nRole:�Programmer\nTeam Size:�3\nSkill Used:�Vi editor, GAE, CSV, Python, GAE Datastore\nRole Description:�Doing some bug fixes.\nProject Details:�Yadesk is a online ticketing system build on google app engine.\nInterpreview is used for conducting online coding contests is also build on google app engine.\n\nProject Title:�GUI for SFHA Team\nClient:�Symantec\nEmployment Type:�Contractual\nDuration:�Nov 2011 - Dec 2011\nProject Location:�Pune\nSite:�Onsite\nRole:�Programmer\nTeam Size:�1\nSkill Used:�VI editor, Perl, Apache, Jquery, Template toolkit\nRole Description:�Team Lead\nProject Details:�It is designed for SFHA Team.\nIt Extracts different parameter from server\ndirectory and produce a graphical reports. With some effects like sorting etc.;\n\nProject Title:�AutoSFAE\nClient:�Symantec\nEmployment Type:�Contractual\nDuration:�May 2011 - Dec 2011\nProject Location:�Pune\nSite:�Onsite\nRole:�Programmer\nTeam Size:�1\nSkill Used:�VI editor, Perl, Apache, Jquery, mysql\nRole Description:�Team Lead\nProject Details:�The Automated Performance Test Suite Solution (AutoSFAE) is developed for the Symantec India, Storage Foundation Application Editions Group. The solution is developed to schedule multiple performance test requests automatically on a given test-harness. The solution also provides an interface to visually see the results of the performance tests done on various drops and see the trends.\n\n\n\n\nProject Title:�AutoPeg(Automation for PEG team) \nClient:�Symantec\nEmployment Type:�Contractual\nDuration:�Nov 2010 - Apr 2011\nProject Location:�Pune\nSite:�Onsite\nRole:�Programmer\nTeam Size:�2\nSkill Used:�Vi editor, Python, Plone(CMS), Postgres, Jquery\nRole Description:�Team Member\nProject Details:�The Automated Performance Test Suite Solution (AutoPeg) is developed for the Symantec India, Performance Engineering Group.\nThe solution is developed to schedule multiple performance test requests automatically on a given test-harness. It allows user to�\nchoose from a range of benchmarking levels.�\nThe solution also provides an interface to visually see the results of the performanc tests done on various drops and see the trends.\n\nProject Title:�Perfalize\nClient:�Bygsoft\nEmployment Type:�Full-Time\nDuration:�Aug 2010 - Dec 2010\nProject Location:�Pune\nSite:�Offsite\nRole:�Programmer\nTeam Size:�3\nSkill Used:�Vi editor, GAE, XML, Python, GAE Datastore\nRole Description:�Team member\nProject Details:�PerfALIZE runs through the server logs and analyze them and presents a report of your system. The report at the outset presents an\nExecutive Performance Statement about the system. Direct inferences like resource utilization, hot spots, trends etc are presented in�\na graphical report.\nUse native operating system utilities like 'sar', 'iostat', 'memstat' etc to gather statistics or choose an application generated log e.g. Apache\nWeb Server for analysis.\nCurrently it supports only Linux logs(sar logs.)\n\nProject Title:�SFTA\nClient:�B.E Project\nEmployment Type:�Full-Time\nDuration:�Jun 2009 - Jun 2010\nProject Location:�Pune\nSite:�Offsite\nRole:�Programmer\nTeam Size:�4\nSkill Used:�Notepad++, Java, Linux, Windows, mysql, ms-access\nRole Description:�Team member\nProject Details:�The project SFTA software developed to achieve transfer of files between any two ports in a well-secured manner. It supports encryption , multiple port sharing etc.\nThis project owns Share Manager, User�\nManager, Log Manager and Server Manager as its modules. Encryption and Decryption\nmodule is an important sub module, which comes\nunder the Server Manager.\n\nPersonal Profile:\n\n Name                : Brijesh Kumar\nFather�s Name  : Ram Chandra\nDate of Birth     : 04st Nov, 1987.\nNationality        : Indian\nPassport           : M0771822\nHobbies            : Riding Bikes, Listening Music, Traveling, Reading\nInterests           : System Programming, Web Development, Data structures.\nPermanent Address: E-149, Ground floor, Sushant lok-3, Gurgaon, Haryana - 122003\nMobile No.               : +91 88002881777","annotation":[{"label":["Location"],"points":[{"start":9971,"end":9977,"text":"Gurgaon"}]},{"label":["Skills"],"points":[{"start":9667,"end":9667,"text":"C"}]},{"label":["Name"],"points":[{"start":9632,"end":9644,"text":"Brijesh Kumar"}]},{"label":["Skills"],"points":[{"start":8977,"end":8977,"text":"C"}]},{"label":["Skills"],"points":[{"start":8907,"end":8907,"text":"C"}]},{"label":["Skills"],"points":[{"start":8381,"end":8386,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8208,"end":8208,"text":"C"}]},{"label":["Skills"],"points":[{"start":7678,"end":7678,"text":"C"}]},{"label":["Skills"],"points":[{"start":7664,"end":7669,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7533,"end":7533,"text":"C"}]},{"label":["Skills"],"points":[{"start":7499,"end":7499,"text":"C"}]},{"label":["Skills"],"points":[{"start":6985,"end":6988,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":6854,"end":6854,"text":"C"}]},{"label":["Skills"],"points":[{"start":6820,"end":6820,"text":"C"}]},{"label":["Skills"],"points":[{"start":6557,"end":6560,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":6426,"end":6426,"text":"C"}]},{"label":["Skills"],"points":[{"start":6392,"end":6392,"text":"C"}]},{"label":["Skills"],"points":[{"start":6120,"end":6125,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6115,"end":6115,"text":"C"}]},{"label":["Skills"],"points":[{"start":5948,"end":5948,"text":"C"}]},{"label":["Skills"],"points":[{"start":5392,"end":5392,"text":"C"}]},{"label":["Skills"],"points":[{"start":5287,"end":5287,"text":"C"}]},{"label":["Skills"],"points":[{"start":5273,"end":5273,"text":"C"}]},{"label":["Skills"],"points":[{"start":4658,"end":4658,"text":"C"}]},{"label":["Skills"],"points":[{"start":4552,"end":4552,"text":"C"}]},{"label":["Skills"],"points":[{"start":4538,"end":4538,"text":"C"}]},{"label":["Skills"],"points":[{"start":4150,"end":4155,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4066,"end":4066,"text":"C"}]},{"label":["Skills"],"points":[{"start":3960,"end":3960,"text":"C"}]},{"label":["Skills"],"points":[{"start":3946,"end":3946,"text":"C"}]},{"label":["Skills"],"points":[{"start":3541,"end":3546,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3455,"end":3455,"text":"C"}]},{"label":["Skills"],"points":[{"start":3347,"end":3347,"text":"C"}]},{"label":["Skills"],"points":[{"start":3333,"end":3333,"text":"C"}]},{"label":["Skills"],"points":[{"start":3000,"end":3005,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2916,"end":2916,"text":"C"}]},{"label":["Skills"],"points":[{"start":2811,"end":2811,"text":"C"}]},{"label":["Skills"],"points":[{"start":2797,"end":2797,"text":"C"}]},{"label":["Skills"],"points":[{"start":2727,"end":2727,"text":"C"}]},{"label":["Skills"],"points":[{"start":2499,"end":2499,"text":"C"}]},{"label":["Skills"],"points":[{"start":2469,"end":2474,"text":"Python"}]},{"label":["Location"],"points":[{"start":2401,"end":2407,"text":"Gurgaon"}]},{"label":["Skills"],"points":[{"start":2307,"end":2307,"text":"C"}]},{"label":["Skills"],"points":[{"start":2119,"end":2124,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1757,"end":1757,"text":"C"}]},{"label":["Skills"],"points":[{"start":1710,"end":1715,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1553,"end":1553,"text":"C"}]},{"label":["Skills"],"points":[{"start":1486,"end":1486,"text":"C"}]},{"label":["Skills"],"points":[{"start":1471,"end":1471,"text":"C"}]},{"label":["Skills"],"points":[{"start":1461,"end":1461,"text":"C"}]},{"label":["Skills"],"points":[{"start":1425,"end":1425,"text":"C"}]},{"label":["Skills"],"points":[{"start":1410,"end":1410,"text":"C"}]},{"label":["Skills"],"points":[{"start":1400,"end":1400,"text":"C"}]},{"label":["Skills"],"points":[{"start":1334,"end":1334,"text":"C"}]},{"label":["Skills"],"points":[{"start":1291,"end":1291,"text":"C"}]},{"label":["Skills"],"points":[{"start":1250,"end":1250,"text":"C"}]},{"label":["Skills"],"points":[{"start":1233,"end":1242,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":994,"end":1003,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":989,"end":991,"text":"C++"}]},{"label":["Skills"],"points":[{"start":989,"end":989,"text":"C"}]},{"label":["Skills"],"points":[{"start":986,"end":986,"text":"C"}]},{"label":["Skills"],"points":[{"start":980,"end":983,"text":"Perl"}]},{"label":["Skills"],"points":[{"start":973,"end":977,"text":"Shell"}]},{"label":["Skills"],"points":[{"start":965,"end":970,"text":"Python"}]},{"label":["Skills"],"points":[{"start":636,"end":641,"text":"Python"}]},{"label":["Skills"],"points":[{"start":505,"end":505,"text":"C"}]},{"label":["Skills"],"points":[{"start":414,"end":419,"text":"Python"}]},{"label":["Skills"],"points":[{"start":260,"end":260,"text":"C"}]},{"label":["Skills"],"points":[{"start":70,"end":70,"text":"C"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Brijesh Kumar"}]}],"extras":null,"metadata":{"first_done_at":1532675977000,"last_updated_at":1532675977000,"sec_taken":180,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "AMMI SHADDAI U  \t\t\t\t\t\t                \nMob: +91 9686704699\t\t\t\t\t\t\t\t      Email: shaddai.k@gmail.com\n\n\nAnalytics Professional with a career spanning   9 + YEARS\n\n\n· Profile: Professional with of insightful experience across Project Management, Marketing & Advanced Analytics.\n\n\n· Goal: Exploring opportunities in Analytics.\n\nAdded Expertise\n\tPredictive Modeling\nSegmentation /Profiling \nData Mining Applications\nMachine Learning/NLP – LSA, LDA, CTM.\n\tLogistic/Life Time Value\nMarkov Chain / ML Algorithms\nProduct Development / Optimization\nMarketing & Campaign Targeting/Affinity Analysis/Collaborative filtering/Market Basket Analysis/RFM/Text Mining/Topic modelling\n\n\tCustomer Insights\nR,SAS & Quantum \nProject Management\nIT/FMCG/Retail/Airlines/Chabot analysis\n\n\nKey Points of Success\n\n· Adept at in analysing, designing and leading complex business solutions. Knowledge of Consumer Perceptions and various Consumer Insights projects, identifying Business Objective, Analyzing the Data & Presentation of the final report.\n· 3 plus years of experience in data science, machine learning.\n· Working knowledge of R, SAS and SPSS along with critical business and industry information that help develops executable Business Strategies.\n· Adept at managing cross-functional and multi-cultural teams with efficiency in training, motivating and monitoring performance as per organizational objectives.\n· Working on SPARK R, Extracting data from HBASE,HIVE \n· Currently working on Text mining, NLP methods like LSA, LDA.\n\n\n\n\n\n\n\n\n\nProfessional Experience And Career Advancements\n\n- Consultant in Mindtree Ltd since September 2014 to till date           \n\n· From last 3 years, worked on various domains like CPG,retail,Airlines\n· Supporting Product development team in optimizing the product, implementing ML algorithms, improving Business.\n· Worked on digital analytics\n· Working on customer Personalization and 360 degrees customer View\n· Working on Chabot analysis \n· Working on text mining, social media Analytics, Topic modelling – LSA, LDA, CTM etc.…\n· Worked on deployR and plumber to deploy R as a service.\n\n- Senior Business Analyst in TCS (Tata Consultancy Services) since September 2010 to August 2014\n· Part of  Analytics & Insights Team \n· Worked in various domains like CPG, Digital, media, Campaign Analytics etc. \n· Handled a Team of  5 members \n· Worked  on Media & online Research in US\n· Created Various reports regarding Media & online Estimates in US\n\nAnalytics Executive in IMRB (India Market Research Bureau) International since June 2008 to August 2010\n\nKey Results Areas: \n· Extensively working on large data bases using QUANTUM, SPSS and other customized tools.\n· Analysis of Large sets of Retail data, Consumer panel data on a regular basis\n· Data Processing & Analysis which includes statistical analysis like correlation, Regression, Chi Square test, NOVA etc...\n· Liaison with Field work, Project Managers & Clients\n· Link & trace Projects(Ad testing)\n· Concept testing\n· Dealing with Brand Dynamics (Calculation Brand & market essence) calculating the future of a brand in the next coming years using extensive analysis through customized software’s.\n· Collecting, collating and carrying out complex data analysis in support of management & customer requests.\n· Competitor Intelligence Analysis\n· Custom Reporting using Microsoft Excel,SPSS,QUANTUM\n· Understand and analyze the source data file containing information of various competitors\n· Managing the design, coding, validation and execution of data analysis supporting various campaign programs.\n\n\nFaculty member in ICFAI national college from march-2005 to June 2008\n\nKey Results Areas: \n· Resource Management – Successfully led the teams of 30 + members and guided them   \n· Through the achievement of their project objectives.\n· Anchored marketing initiatives, lead resource teams in recruitment and training and \n· Development, played key role in the successful completion of projects with optimum  \n· Utilization of resources and time.\n· Assisting the students in collecting Analyzing and interpreting the data for their projects.\n·  Guided a number of students in various Market Research Projects.  \n\nFaculty member in Statistics in Sri Krishnaveni Degree College, Vijayawada from November 2002 till March 2005\n\nKey Results Areas: \n· Teaching statistics to graduates & undergraduates.\n· Guiding them to achieve their Project objectives.\n\nCredentials\n\nAcademic:\n· MSc (Statistics), Andhra University (2000-2002)\n· BSc (Statistics), Nagarjuna University (2000)\n\n\nOther Skills:\n· \n· MS Office\n· Statistical Packages - SPSS, SAS, & R\n\nPersonal Details\n\n· Date of Birth: 30 Aug 1979\n· Languages Known: English, Hindi & Telugu","annotation":[{"label":["Skills"],"points":[{"start":4597,"end":4600,"text":"SPSS"}]},{"label":["Education"],"points":[{"start":4445,"end":4460,"text":"MSc (Statistics)"}]},{"label":["Skills"],"points":[{"start":3361,"end":3367,"text":"QUANTUM"}]},{"label":["Skills"],"points":[{"start":3356,"end":3359,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":2644,"end":2647,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":2635,"end":2641,"text":"QUANTUM"}]},{"label":["Skills"],"points":[{"start":1121,"end":1124,"text":"SPSS"}]},{"label":["Skills"],"points":[{"start":703,"end":720,"text":"Project Management"}]},{"label":["Skills"],"points":[{"start":340,"end":358,"text":"Predictive Modeling"}]},{"label":["Skills"],"points":[{"start":242,"end":271,"text":"Marketing & Advanced Analytics"}]},{"label":["Skills"],"points":[{"start":222,"end":239,"text":"Project Management"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"AMMI SHADDAI U "}]}],"extras":null,"metadata":{"first_done_at":1532674246000,"last_updated_at":1532674246000,"sec_taken":190,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Gaurav Yadav \nMobile: +91-8971132762\nE-Mail: gauravy25041991@gmail.com \n· In quest of a universal solution to all kinds of global problems by sieving useful data patterns from largely unstructured data, hence I am seeking assignments in data science domain which gives me the scope of widening the spectrum of my knowledge.\n· Professional Summary\n\n· A Computer Engineer having experience in machine learning (ML), algorithms and natural language processing (NLP). In 7+ Years of total experience (2.5+ years in Data Science, 2.5 years in SAP implementation, support & 1.5 development.)\n· Presently associated with Tata Consultancy Services Bengaluru as a Data Scientist and previously associated with PDIL, NOIDA, Sr. Engineer (Computer).\n· Organisational Experience\n\n\t1.\n\tCompany 2: TCS, Bengaluru -- (Dec 2011 to present)\n\n\t\n\tProject 1 : NLP (Email Analysis engine)\n \nClassifying incoming e-mail from customers to related product using e-mail subject and body text.\nE-mail will be classified in related product queue and issue will be addressed accordingly. \n\nResponsibilities:\n \n\n 1) Worked on data labelling for this project and label around 1000 data points.\n\n 2) Worked on data pre-processing.\n\n 3) Reading mail and getting intent and entity of mail.\n\n 3) Worked on prototyping/Model Creation for mail classification.\nProject 2: Client: US based bank (Churn Analysis)\nDeposits are the key phenomenon for any bank. SunTrust has a total of 18 million deposit accounts belonging to individuals, corporate and affiliates. Each year, SunTrust adds 2-3 million new accounts but the grand total of accounts has plateau at 18 million. This implies that there are as many customer accounts churning out that keeps the grand total largely unchanged. The Analytics team was called in to perform a deep dive analysis to identify the Key performance indicators that contribute to the customer attrition. This project needed to answer two business questions:\n\n1) Will the customer churn?\n\n2) Can we predict the when the customer will churn?\n\n3) Played the role of Analyst working with the business to come up with a statistical model to reduce the deposit attrition and was involved in the following tasks\n\nResponsibilities:\n\n1)  Understand business problem to be solved and formulate analytics problem statement.\n\n2)  Identify the response/dependant variable Y - what does churn mean?\n\n3)  Perform data requirement analysis to conclude whether the data is present to solve the problem.\n\n4)  The available data set had transactional data of all the 18 million account holders that ran into millions of records. Each monthly file was 100GB.\n\n5)  Obtain the dataset containing the customer complaint transactions and merge it with the main dataset.\n\n6)  Conduct Exploratory Data Analysis.\n\n7)  Measures of central tendency - Mean, Median, Mode (1st moment business decision).\n\n8)  Measures of dispersion - Variance, Standard Deviation, Range (2nd moment business decision).\n\n9)  Skewness and Kurtosis (3rd and 4th moment business decision respectively).\n\n10) Visualization using Graphical analysis - Scatter plots, Box plot, histogram, QQ Plots.\n\n11) Identify outliers, Inter-quartile range (IQR), anomaly detection.\n12) Missing value analysis - Deletion methods such as list wise deletion and pair wise deletion.\n\n13) Missing value imputation - Mean/mode substitution, Regression imputation, K-nearest imputation.\n14) Maximum Likelihood, Multiple imputation Identify significant variables using Decision Tree analysis.\n15) Feature Engineering - Work with the SMEs utilizing their domain knowledge to create features that represent the underlying problem which can significantly increase the accuracy of the predictive models Autocorrelation problem identification between different significant variables.\n\n16) Dummy variable creation for categorical data.\n\n17) Cluster analysis to identify the naturally occurring clusters within the data.\n\n18) Build Classification models using Logistic Regression to predict Churn = Yes or No (requirement 1) \nConduct Survival Analysis to predict time from starting subscription to churning (requirement 2).\n\n19) Score the models and refine them based on accuracy and the insights business is able to derive from\nProject Result: The final model was able to predict the customer churn with 72% accuracy. \n\nEnvironment: Python, Pandas\nProject 3: Client: Rating Model for European Medicines Evaluation Agency (EMEA)\nEMEA wanted to design a predictive model on the basis of hospital historical data to give a rating of new hospital.  Model was developed to identify overall hospital rating using decision trees. This analysis helps hospital regulatory body to rate any new hospital that comes into system by identifying on some basic parameters, like patient admission procedure in hospital, behaviour of doctors and supporting staff, hospital care, timeliness, hygienic condition, type of hospital and  mode of payment before exit. Decision tree algorithm was used in this model to identify factors to find the overall ratings of a hospital.\n\nResponsibilities:\n\n1) Worked with project team to understand the problem and business requirements.\n\n2) Worked with developers to extract data from HDFS.      \n\n3) Imported data into Python and R for exploring and understanding the data.\n\n4) Exploring the data and data structures for developing model.\n\n5) Prepared data for creating training and test sets. \n\n6) Developed hospital rating model to identify overall rating using decision tree algorithm.\n\n7) Communicated results using presentations and visualization.\nEnvironment: Linux, Hadoop, MySQL, R, R-Studio\n\n\n\n\t2.\n\tCompany 1: Projects and Development India Limited, NOIDA-- (Oct 2010 to Nov 2011)\nPDIL is a PSU (Government of India, under the ministry of chemical & fertilizer). PDIL is providing to technical and design solution for fertilizer sector. Currently holds approximately 5-7% of total market in their domain after Engineers India Limited, India.\n\n\n\n\t\n\t1) Project 1: SAP Implementation: ‘Sarthak’ - SAP ECC 6.0\nResponsibilities: \n\n1) Collection of the requirements, creation of blue print, functional design documents.\n\n2) Configuration of customer master, material master, sales organization structure, support.\n\n3) Production support, End user support, troubleshooting.\n\nEnvironment: SAP ECC 6.0 - SAP BI, BO\n\n\n\n· Analytical skills\n\n\tStatistics and Predictive Modelling-Linear and Logistic Regression, Hypothesis Testing, ANNOVA, Cluster analysis\n\tMachine Learning-Supervised and Unsupervised Learning using Logistic regression, Decision tree, Random forest\n\n\tBig Data-Learning Hadoop, HDFS, Map Reduce, PIG, HIVE\n\tData Visualization-Matplotlib, ggplot2-R,\nTableau\n\n\tNLP -Text Mining\n\t\n\n\t\n\t\n\n\n· Tools\n\tR Studio-R for Data Mining, Web Mining, Data Analysis\n\tPython-Anaconda, Notebook, Scikit-Learn, Numpy, Pandas\n\n\n\n\tUnix- OS, basic shell script\n\n\tMySQL workbench 6.0\n\n\tSAP - BO, BI\n\tSQL 2005,2008, Oracle\n\n\n· Qualifications:\n\tS.N.\n\tQualification\n\tInstitute\n\tPercentage\n\n\t1.\n\tB. Tech (CSE)\n\tB.I.E.T. Jhansi, U.P.T.U., Lucknow, U.P.\n\t70.36 %\n\n\t2.\n\tXII\n\tC.I.C. Allahabad, U.P. Board\n\t69.60%\n\n\t3.\n\tX\n\tS.M.V.M. Unnao, U.P. Board\n\t77.83%\n\n\nLocation: Bengaluru\nPage 4 of 4","annotation":[{"label":["Location"],"points":[{"start":7179,"end":7188,"text":" Bengaluru"}]},{"label":["Education"],"points":[{"start":7011,"end":7017,"text":"B. Tech"}]},{"label":["Skills"],"points":[{"start":6905,"end":6907,"text":"SAP"}]},{"label":["Skills"],"points":[{"start":6596,"end":6603,"text":"Big Data"}]},{"label":["Skills"],"points":[{"start":6484,"end":6499,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":6334,"end":6336,"text":"SAP"}]},{"label":["Skills"],"points":[{"start":6320,"end":6322,"text":"SAP"}]},{"label":["Skills"],"points":[{"start":6033,"end":6035,"text":"SAP"}]},{"label":["Skills"],"points":[{"start":6001,"end":6003,"text":"SAP"}]},{"label":["Location"],"points":[{"start":788,"end":797,"text":" Bengaluru"}]},{"label":["Location"],"points":[{"start":639,"end":648,"text":" Bengaluru"}]},{"label":["Skills"],"points":[{"start":538,"end":540,"text":"SAP"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Gaurav Yadav "}]}],"extras":null,"metadata":{"first_done_at":1532694779000,"last_updated_at":1532694779000,"sec_taken":96,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Joshi Chand Sunkara\nMail: Sunkara.joshi07@gmail.com                         Mob:09966667590\nProfessional Summary\n· 9 years of IT experience includes 3+ years of Data Scientist experience (Data Mining/ Modeling,Business/Data/Predictive/TextAnalytics,Optimization),data Analysis/Visualization, and BI. \n\n· Executed software projects for Banking, Supply Chain Management [SCM], HealthCare and Insurance industry’s.\n· Experience in leading and managing teams. Handled multiple roles – Data Scientist, Senior Data Analyst, System Analyst and System Engineer.\n\n· Hands on experience on Devops, BLUEMIX and automation projects.\n\n· Extensive experience with analysis, design, development, customizations and implementation of software applications including ERP applications. \n\n· Proficient in analyzing and translating business requirements to technical requirements and architecture.\n\n· Strong Data Analytical skills,SQL, Programming and Development knowledge.\n\n· Received Eminence & Excellence award, Manager Choice award for application automation and Client First award for application support.\n\nCertifications\n\n· Diploma in Statistics.\n· IBM Certified Machine Learning with R .\n\n· IBM Certified Solution Developer InfoSphere QualityStage V8.\n· BigData Fundamentals Technical Mastery Test V1.\n\n· IBM Certified DB2 9.7 DBA LUW.\nCore Skills  \n\n\tSkills\n\tDetails\n\n\tBusiness Analytics     \n\n\n\tDataStage, Hyperion,SPSS,Watson Analytics, Congnos,\n\nQMF, Tableau, R Markdown \n\n\tPrograming Languages\n\tR, JAVA, SQL, VB ,Python , Hive, SQLRPG and Shell(QSH) \n\n\n\n\tAutomation \n\tBlueprism,VB Macros, Win automation\n\n\tBluemix/Devops\n\tRapid Mobile/Web Apps ,UCD, GIT, Java Liberty, Dash DB, SDK Node js, DB2 on Cloud DB.\n\n\tDatabase\n\tSQL Server, Cloudant DB, DB2 UDB, Oracle,\n\nDB2/400, , DB2 9.1,  MS Access \n\n\tOperating System \n\tOS/400, Z/OS, Linux/Unix, Windows\n\n\n\n\tHardware\n\tIBM Power Systems, SAP and IBM PC compatibles\n\n\n\n\nEducation\n\n· Master of Science in Information Technology (Data Warehousing and Software Project Management)-from Kuvempu University(DM)-2014, India.\n\n· Master’s in Business Administration (Finance and Marketing) - from Acharya Nagarjuna University-2006, India.\n\n· Bachelor’s in Computer Applications –from Andhra University-2003, India.\n\nWork Experience\n\n· IBM Global Services Bangalore, India ,  2009 July to  Till date.\n\n· HSBC’s Global Technology Centre Pune, India , 2008 May to  2009 April.\nIBM Global Services Bangalore, India\n\nPROJECTS SUMMARY\n\nProject# 1         Apr -2016 to  Till Date\n\nProject Name    :  ICAS,\n\nEnvironnent      :  R ,Watson Analytics, SPSS,Python, DB2 ,SQL Server ,DashDB ,Tableau.\nRole                   : Data Scientist.  \nDomain              : BFSI \nResponsibilities: \n\n• Gather, analyses& translate business requirements into relevant analytic approaches& share for peer review. \n• Contribute to Finance and Risk management, Operations management, and Marketing; and maximize ROI on advanced data analytics technology. \n• Design, model, validate and test statistical algorithms against various real-world data sets including behavioral data and deploy models in the backend (batch) and cloud (streaming) \n• Perform Data Transformation method for Rescaling and Normalizing variables. \n• Apply different methods on data sets to predict credit risk, customer churn, and for target marketing. \n• Work on data to increase cross-& up-sell revenues, enhance customer value or reduce non-credit losses. \n\n• Reporting, data mart and ETL Support.\n• Perform quantitative analysis of product sales trends and doing Revenue Cycle Management using Watson Analytics. \n\n• Making \"Customer Segmentation model\" and doing \"Write off Prediction\". \n\n• Analyzing the Payor Behavior for different Segments using data modeling and doing collection optimization based on payor segmentation techniques. \n\n• Designing Automation strategies for future and current deliveries. \n\n• To recognize a specific demographic of Payors based on statistical modeling to improve collection efficiency, working capital and optimize collector efforts. \n\nProject# 2         Sep -2014 to Mar -2016\nProject Name    :  Scotia Bank IGS,\n\nEnvironnent      : Java, Iseries,DB2 ,SQL Server, MQ and Hyperion.\nRole                   : Senior Data Analyst  \nDomain             : BFSI\nResponsibilities: \n\n• Interact with users to know their business while gathering the business requirements and provided several report samples to finalize the business requirements. \n\n• Co-ordinate with the team and business analysts in discussing about the technical and functional requirements for enhancing existing business objects universes based on business requirements. \n\n• Design, develop, maintain and test universes for supporting ad-hoc queries and canned reports. \n\n• Create Web Intelligence reports based on the requirements against the universes and tested them. \n\n• Update and maintained existing universes based on changes in user requirements& in data source. \n\n• Create Master/Detail and Crosstab reports and export Excel, PDF and text formats. \n\n• Implement Row Level Security in the universe using CMC and resolve user tickets in production support. \n\n• Train end users to use various functionalities of Business Objects and provided technical support.\nProject# 3         Sep-2012 to Aug -2014\nProject Name   :  Cost Tracker\nEnvironnent      : Iseries, Java,Datastage,Linux and SAP   \nRole                   : Senior System Analyst.\nDomain             : SCM\nResponsibilities: \n\n• Analyzing the functional specs and technical spec.\n\n• Involved in coding for enhancements and developments.\n\n• Support to various applications which using cost tracker.\n\n• Performing CLAS operations for various user’s in cost tracker\n\n• Working with the user queries related to the production environment.\n\n• Handling Monthly cost tape production runs from different source systems. \nProject# 4         Jun-2011 to Aug -2012\n\nProject Name   :  RxCliam CVS,\n\nEnvironnent      : RPG,JAVA,SQL, DB2.\nRole                   : Senior System Engineer.\nDomain            : Health Care \n\nResponsibilities: \n• Working with the user queries related to the product environment tickets.\n\n• Production support for critical adjudication part.\n\n• Jobs Monitoring with IBM job Scheduler.\n\n• Monitoring weekly feeds from CaremarkRxclaim to FEDB\n\n• Analyzing the functional specs and technical spec.\n\n• Involved in code fixing and enhancements.   \nProject# 5         Jul-2009 to   May-2011\nProject Name   : PROPMART, BOA.  \nEnvironnent     : RPG/400,DB2/400, DataStage, SQL/400, SQL Server.\nRole                  : System Engineer  .\nDomain             : BFSI\nResponsibilities: \n\n• Analyzing the functional specs and technical spec.\n\n• Involved in coding for enhancements and developments.\n\n• Jobs Monitoring with IBM job Scheduler and IFS folder data transfer.\n\n• Tapes operations of various vendors given data Assessor, Recorder and Port.\n\n• Working with the user queries related to the production environment.\n\n• Weekly Data Mirroring from AS/400 to SQL Server. \nHSBC’s Global Technology Centre Pune, India\n\nPROJECTS SUMMARY\n\nProject# 1       Jun-2008 to Apr -2009    \n\nProject Name   :HFC AS400 Engagements,\n\nEnvironnent    :  RPG/400,CL/400, DB2/400, SQL/400,\nRole                 : Software Engineer.\nDomain             : BFSI\n\nResponsibilities: \n\n• Involved in coding for enhancements and developments.\n• Generating Adhoc and General Reports for system maintenance.\n\n• Involved in the Unit Testing & Regression testing in time to time.\n\n• Updating the production support documents when new releases come up.\n\n• Jobs Monitoring with ROBOT job Scheduler.\n\n• Worked on CBS applications Sunguard ambit core banking and Fiserv CBS","annotation":[{"label":["Skills"],"points":[{"start":7591,"end":7591,"text":"R"}]},{"label":["Skills"],"points":[{"start":7459,"end":7459,"text":"R"}]},{"label":["Skills"],"points":[{"start":7393,"end":7393,"text":"R"}]},{"label":["Skills"],"points":[{"start":7286,"end":7286,"text":"R"}]},{"label":["Skills"],"points":[{"start":7217,"end":7217,"text":"R"}]},{"label":["Skills"],"points":[{"start":7208,"end":7210,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":7208,"end":7210,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":7183,"end":7183,"text":"R"}]},{"label":["Skills"],"points":[{"start":7077,"end":7077,"text":"R"}]},{"label":["Skills"],"points":[{"start":7064,"end":7064,"text":"R"}]},{"label":["Skills"],"points":[{"start":7005,"end":7007,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":7005,"end":7007,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6874,"end":6874,"text":"R"}]},{"label":["Skills"],"points":[{"start":6612,"end":6612,"text":"R"}]},{"label":["Skills"],"points":[{"start":6543,"end":6543,"text":"R"}]},{"label":["Skills"],"points":[{"start":6531,"end":6533,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6531,"end":6533,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6522,"end":6524,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6522,"end":6524,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6494,"end":6494,"text":"R"}]},{"label":["Skills"],"points":[{"start":6465,"end":6465,"text":"R"}]},{"label":["Skills"],"points":[{"start":6460,"end":6460,"text":"R"}]},{"label":["Skills"],"points":[{"start":6282,"end":6282,"text":"R"}]},{"label":["Skills"],"points":[{"start":6050,"end":6050,"text":"R"}]},{"label":["Skills"],"points":[{"start":5967,"end":5967,"text":"R"}]},{"label":["Skills"],"points":[{"start":5957,"end":5959,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":5957,"end":5959,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":5952,"end":5955,"text":"JAVA"}]},{"label":["Skills"],"points":[{"start":5948,"end":5948,"text":"R"}]},{"label":["Skills"],"points":[{"start":5915,"end":5915,"text":"R"}]},{"label":["Skills"],"points":[{"start":5449,"end":5449,"text":"R"}]},{"label":["Skills"],"points":[{"start":5376,"end":5376,"text":"R"}]},{"label":["Skills"],"points":[{"start":5048,"end":5048,"text":"R"}]},{"label":["Skills"],"points":[{"start":4270,"end":4270,"text":"R"}]},{"label":["Skills"],"points":[{"start":4197,"end":4197,"text":"R"}]},{"label":["Skills"],"points":[{"start":4168,"end":4170,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4168,"end":4170,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3542,"end":3542,"text":"R"}]},{"label":["Skills"],"points":[{"start":3438,"end":3438,"text":"R"}]},{"label":["Skills"],"points":[{"start":3185,"end":3185,"text":"R"}]},{"label":["Skills"],"points":[{"start":2915,"end":2915,"text":"R"}]},{"label":["Skills"],"points":[{"start":2847,"end":2847,"text":"R"}]},{"label":["Skills"],"points":[{"start":2688,"end":2688,"text":"R"}]},{"label":["Skills"],"points":[{"start":2617,"end":2617,"text":"R"}]},{"label":["Skills"],"points":[{"start":2588,"end":2590,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2588,"end":2590,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2549,"end":2549,"text":"R"}]},{"label":["Skills"],"points":[{"start":2455,"end":2455,"text":"R"}]},{"label":["Skills"],"points":[{"start":2442,"end":2442,"text":"R"}]},{"label":["Location"],"points":[{"start":2423,"end":2431,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":2284,"end":2292,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":2059,"end":2093,"text":"Master’s in Business Administration"}]},{"label":["Education"],"points":[{"start":1920,"end":1936,"text":"Master of Science"}]},{"label":["Skills"],"points":[{"start":1713,"end":1715,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1713,"end":1715,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1615,"end":1615,"text":"R"}]},{"label":["Skills"],"points":[{"start":1607,"end":1612,"text":"Devops"}]},{"label":["Skills"],"points":[{"start":1571,"end":1573,"text":"VB "}]},{"label":["Skills"],"points":[{"start":1571,"end":1572,"text":"VB"}]},{"label":["Skills"],"points":[{"start":1561,"end":1569,"text":"Blueprism"}]},{"label":["Skills"],"points":[{"start":1521,"end":1523,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1521,"end":1523,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1502,"end":1503,"text":"VB"}]},{"label":["Skills"],"points":[{"start":1497,"end":1499,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1491,"end":1494,"text":"JAVA"}]},{"label":["Skills"],"points":[{"start":1488,"end":1488,"text":"R"}]},{"label":["Skills"],"points":[{"start":1452,"end":1452,"text":"R"}]},{"label":["Skills"],"points":[{"start":1172,"end":1172,"text":"R"}]},{"label":["Skills"],"points":[{"start":958,"end":958,"text":"R"}]},{"label":["Skills"],"points":[{"start":911,"end":913,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":911,"end":913,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":751,"end":751,"text":"R"}]},{"label":["Skills"],"points":[{"start":588,"end":595,"text":"BLUEMIX "}]},{"label":["Skills"],"points":[{"start":580,"end":585,"text":"Devops"}]},{"label":["Name"],"points":[{"start":0,"end":18,"text":"Joshi Chand Sunkara"}]}],"extras":null,"metadata":{"first_done_at":1532694947000,"last_updated_at":1532694947000,"sec_taken":167,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "CURRICULUM VITAE\nR – 4/5\n\nPython – 4/5 \n\nML – 4/5\n\nClaims he is Very Much intertered in coding and can do high level coding.. \n\nLokanath Baral\n#27,R.Murugan,Maruthi \n\nLayout,Kudlu,Near Kudlu\n\nGate, Bangalore,\n\nPin Code- 560068.\n\nL.M- Srichaitnya techno school                                Email: lokanath1986@gmail.com \n                                                                            Contact no.:+91-7406353702                                                    \n\nCAREER OBJECTIVE:\nTo get a significant   position in   IT Industry as a dedicated IT Professional where I can continuously upgrade my knowledge & skill sets. I am looking forward to face new challenges while focusing on the contribution of the desirable achievements of the Organization.\nPROFESSIONAL PROFILE:\n\n· Total Work Experience of around 7.9 years in analysis, design and development of Enterprise applications with Banking, Finance and E-commerce domain.\n· 2+ years of experience in Data Scientist and having good exposure to R, Python,Machine Learning,Deeplearning,NLP,Neural network,Data visualization\n· Develop machine learning predictive models like Logistic Regression,Classification and clustering etc by using Python and R language.\n· Having good exposure to machine learning algorithms like Linear regression,Logistic regression,Decision tree,Support vector machine(SVM),Naive bayes,KNN(K-Nearest neighbors),K-means, Random forest etc.\n\n· 2+ years of experience in building and managing hosted big data architecture, toolkit familiarity in: Hadoop with Oozie, Sqoop, Pig, Hive, Flume, HBase, Avro, Storm, Spark\n· Extracted streaming data using using Flume and Kafka\n· Good working experience using Sqoop to import data into HDFS from RDBMS and vice-versa.\n\n· Assisted in loading large sets of data (Structure, Semi Structured, Unstructured)\n\n· Having exposure in writing SQL quires in SQL,HIVE and Spark SQL\nEDUCATION QUALIFICATION: \n· B.E in Computer Science and Engineering from Sapthagiri College of Engineering From Anna University, Chennai.\n· Council of Higher Secondary Education,Orissa.\n· Board of Secondary Education,Orissa.\nTechnical Skills:\n· Languages\n\n: R,Python,Hive,SQL ,Java,C#.NET, Scala Languages\n· Analytical Tools           : Python-3.6, Anaconda distribution,R-(3.0.1 -3.2.3), RStudio,\nIPython notebook,Spyder,Jupyter\n· Packages                    : Pandas,numpy,nltk,datetime,Dplyr,rattle,reshape,Scikit \n· Big Data Ecosystem    : Map Reduce, HDFS, HBase, Hive, Pig, Sqoop, Oozie and Flume.\n· Apache Spark             : Spark SQL, Spark MLlib, Spark streaming,Spark Graphx\n· Databases\n\n : SQL SERVER, Oracle, MySQL and NoSql.\n· Big Data Tools               : Hadoop User Experience (HUE), Cloudera Manager, Eclipse IDE \n· Source Control             :Team Foundation Server(TFS), GitHub\n· SDLC                          : Waterfall , Agile Methodologies\n· Operating System        : Windows and Linux Red Heart, Ubuntu, CentOS.\n· Ticket tracking tool       : ServiceNow, Remedy 5.0.1, Jira\n· Visualization tool          : Tableau\nPROFESSIONAL EXPERIENCE:\n\tEmployer\n\t             Designation\n\t        Experience\n\n\tDatamatics Global Services\n\nWipro Technologies\nXchanging Solution Ltd.\nC V SOFT. \n\tSenior Consultant\n\nSenior Project Engineer\nSenior Software Engineer\nDotnet Developer.\n\tOctober,2016 to till present\n\nApril,2015 to June,2016\nAugust,2014 to  April,2015\nApril 2010 – february,2014 \n\n\nEmployment Summary\n         \n\nPROJECTS DETAILS:\nCurrent Project:\n      Firm                  : Dell Inc. \n\n      Project Title     : www.dell.com - DCP(Dell commerce Platform)\n      Client               : Dell Inc. \n\n      Environment    : R,Python,Machine Learning,Deep Learning,NLP,Data visualization,Data Mining,Text mining,HDFS,Hive,Sqoop,Flume,MySql, Oozie, Hue\n      Team Size        : 10\n      Duration          : October,2016 to till present.\nDescription:\n\nDell commerce platform is leading a transformation to optimize the support experience for customers. End- to-End Global support framework to unify our support processes,providing a common language around our processes that will make life simpler for our support organization and improve the customer experience. An Integrated platform that will better align our support processes and data providing a 360 degree view of the customer,improving our total customer experience and solving for increasing customer demands from sales through support. Develop next generation capabilities that will support our unified delivery capability framework enabling new TS Support portfolio and increased efficience for our support Teams.\n\nRoles and Responsibilities:\n\n· Preprocessing and analyzing csv,text,xml,json and excel dataset in R , Python language and plotting various visualization graphs to analyze prediction accuracy.\n\n· Creating (GLM) Generalized Linear Model, Neural Networks , Naive Bayes ,Support Vector Machine (SVM)  to build a model and analyzing Acceptance Rate , Close Rate etc using Confusion Matrix.\n· Worked with Business team in identifying problem statement with impact analysis.\n· Divided the data in 80/20 as training and testing set and build the model using training set and tested it using the testing dataset and verified the model using confusion matrix. Apply incentive technique to generalize the model to get more accuracy result.\n· Performed Data modelling activities such as data cleansing and merging.\n· Worked on the in-depth analysis of Random forest technique to improve the accuracy of prediction model.\n· Used data modelling,data mining and text mining technique to preprocessed the data in R (Removing Outliers,filling missing values in cells ,removing rows having NA's ) and Python (used nltk packages for text mining).\n· Developing R and Python scripts for modelling.\n· Deploy Python and R Machine learning predictive models in production and track the metrics of performance.\n· Using \"Rhdfs\" package for basic connection to Hadoop ecosystem .\n\n· Using  \"Plymr\" package  to analyze the data for  performing various data analysis.\n· Responsible for importing un-structure data log files from various sources into HDFS using Flume. \n\n· Imported large sets of structured data using Sqoop to load data from MySQL to HDFS on regular basis. \n\n· Created Hive tables for loading and analyzing data using hive queries.\n· Involved in loading data from LINUX file system to HDFS, HBase and OOZIE workflows.\n· Importing and exporting the data from relational databases, NoSQL DB'S using SQOOP.\nPrevious Project:\n      Firm                  : Wipro Technologies\n      Project Title     : GDN\n      Client               : VISA, USA\n\n      Environment    : R,Python,Machine Learning,Deep Learning,Data visualization,Data mining,ML Algorithms,HDFS,HIVE,Map Reduce,Pig,Oozie,Flume,YARN,Java,HBase\n      Team Size        : 10\n      Duration          : April,2015 to October,2016\nDescription:\n\nThe GDN Upgrade project is Re-engineering of 3 applications under GDN\n\n(Global Delivery Network) that is, GDN Embossing, GDN Inventory Management and GDN Card Production applications, so as to replace the existing ones that are currently in use by Visaâ€™s call center.These 3 applications allow Visaâ€™s call center to provide emergency card replacement services for Visaâ€™s clients worldwide.\nRoles and Responsibilities:\n\n· Developed machine learning models like Logistic Regression,Classification and clustering etc by using Python and R language.\n\n· Preprocessed and analyzed different datasets in R and Python language and plotted various graphs also created a predict model.\n· Performed Data modeling activities such as data cleansing and merging.\n· Used Machine learning algorithms like Logistic regression,SVM,KNN,K-means,Random forest etc. to create the best optimized predict model.\n· Responsible for importing log files from various sources into HDFS using Flume. \n\n· Imported large sets of data using Sqoop to load data from MySQL to HDFS on regular basis. \n\n· Optimizing the Hive queries using Partitioning,Bucketing techniques with ACID properties for controlling the data distribution. \n\n· Created Hive tables for loading and analyzing data using hive queries.\n\n· Write pig scripts to load the data into HDFS\n\n· Developed multiple Map Reduce jobs in java for data cleaning and preprocessing\n\n· Involved in loading data from LINUX file system to HDFS, HBase and OOZIE workflows.\n\n· Working with different types of  data in Map Reduce.\n\n· Used different types of joins in Map Reduce.\n\n· Importing and exporting the data from relational databases, NO SQL DB'S using SQOOP.\n· Worked with NoSQL database Hbase to create tables and store data. \n\n· Experienced with different kind of compression techniques like LZO, GZip, ZLib and Snappy. \n· Monitoring of Oozie jobs periodically.\nProject:1\n      Firm                  : Xchanging\n\n      Project Title     : SMMT\n\n      Client               : SMMT, London, United Kingdom\n\n      Environment    : .NET4.5.1,C#5.0,MVC5 , Entity Framework,Sql server 2012,\n\n                                 LINQ,WCF,AJAX,Jquery,HTML5,CSS3,ASP.NET4.5.1,NUnit\n\n      Team Size        : 10\n\n      Duration          : 6th,August,2014 to 7th,April,2015.\nDescription:\n\n      The Society of Motor Manufacturers & Traders(SMMT) exists to support and promote the interests of the UK automotive industry at home and abroad. SMMT working closely with member companies and acts as the voice of the motor industry,promoting it’s position to government stakeholders and the media. Also Enabling the UK motor industry to fulfil it’s potential. SMMT addresses the major issues that impact on the automotive sector like Competitiveness , Consumer protection, Educating & Training , Environment, Globalisation , Legislation and New Technology.Around 1.5 million cars and commercial vehicles and three million engines are produced annually in the UK, according for 9% of the UK’s total exports with an annual turnover of 40 billion and a workforce of over 700,000 people, the UK is a key global player within the automotive sector and the industry is a significant contributor to the UK’s economy. \nRoles and Responsibilities:\n· As per client requirement FSD contain some informations which related to user interface(wear frame), according requirement we use to develop the module .\n· Develop applications using .NET Framework 4.5.1,C#.NET,MVC5,WCF,LINQ, Entity Framework,ASP.NET, Jquery,JSON,XML,AJAX,HTML5,CSS3,NUnit\n· According Requirement create solutions from scratch.Responsible for designing Architecture, application design and Database Design.\n· Responsible for creating Table and Stored Procedures according to the Database Design and requirement. Tuning query for better performance.\n· As per Database Design we use Entity Framework in Data Access Layer to create Entity class and call the properties of objects which associated with entity class then do the data logic in DAL using LINQ to perform write query,fetch query and execute query.\n· We are using TDD(Test Driven Development) to create Test Cases. Write NUnit Testing to test the method of logic wheather it’s pass or fail.\n· Responsible to fix the DR#(Defects) Raised by customer in JIRA Tool.\n· Responsible to Deploy the application in Different tiers(Servers) like Web tier,Application tier and Data tier.\nProject : 2\n      Firm                  : CV SOFT\n\n      Project Title     : Preventive Maintenance\n\n      Client               : Caterpillar Inc. ,Peoria,Illinois, USA\n\n      Environment    : .NET4.5.1,C#,MVC5 with WebAPI, Entity Framework,Sql server 2012,\n\n                                 LINQ,WCF(Rest),AJAX,Jquery,HTML5,CSS3,ASP.NET4.5.1\n\n      Team Size        : 10\n\n      Duration          : March,2013 to February,2014\nDescription:\n        Preventive Maintenance based on to track an Asset Widget. The main scope of Caterpillar Inc. they manufacture heavy vehicles like D11 Bulldozer,345C L Excavator,930G Wheel Loader,797F Haul Truck,C13 Diesel Engine, Class 7 and Class 8 Trucks etc. This application based on to track an asset widget(machines,Assert level,fleet level) aslo service detail of Asset.Release1.0 Contain service detail of customers,dealers,prospective buyer and sellers. Using this application they can track where the asset is located and can change the status Enabled/Disabled.also they can figure out upcoming service maintenance of asset level as well fleet level. Preventive maintenance include partial or complete overhauls at specific period,oil change,lubrication and so on.Caterpillar employee keep maintenance history log so that they can track the detail of assets before cause any system failure. Main objective of this application prevent all equipment failure before it occurs.  \nProject:  3\n     Firm\n\n:   CV SOFT\n     Project Title\n:   IMES (Infringement Management Enforcement Order)\n     Client\n\n:   Govt. of Victoria, Australia \n     Environment\n:   .Net 4.0,C#4.0,MVC3,WCF,LINQ,JAVA SCRIPT,AJAX,SQLSERVER 2008\n     Team Size  \n:   10\n     Duration\n\n:   November, 2011 to To March,2013\nDescription:\n             This Project Based on Traffic Control System which is control by Govt. of Victoria, \nAustralia. In Australia full city covered by CCTV Camera even camera control the traffic \nSystem. If some debtor violate the traffic Rule immediately issue infringement on debtor \nThrough his/her Vehicle details. We developed some applications to get the detail of debtor \nAnd detail of vehicle. Govt. of Victoria, Australia they issues the infringement for some time \nPeriod like 7 to 15Days within this time period debtor have to pay the amount which is issued \nOn. Otherwise they serve Enforcement Order from the court. Unfortunately if the debtor has \n\nForgotten to pay the Enforcement amount at the end Sheriff’s team which is control all \n\nCivilized cases stuff at Australia they will serve Warrant on Debtor.  \nProject: 4 (URL: www.swarnakrishi.com)\n     Firm\n\n:   CVSOFT\n\n     Project Title\n:   Accounting /Financial Management\n     Client\n\n:   Swarnakrishi Farms India (P) Ltd\n\n     Environment\n:   .Net 2.0,C#2.0,HTML,CSS,XML,JAVA SCRIPT,AJAX,SQL SERVER 2005\n     Team Size  \n:   4\n     Duration\n\n:   April 2010 to October,2011\nDescription:\n\nThis company having few small investment plans, according to those plans they will collect the amount from the customer daily/weekly/monthly basis, customer will be paid with some benefits after completing the plan duration.  Field executive also plays very important role here, He is responsible to collecting the money from customers daily and getting new customers etc, for this he will be paid with some commission, Awards, Incentives and promotions.\nPERSONAL SKILLS:\n\nComprehensive problem solving abilities, excellent verbal and written communication skills, ability to deal with people diplomatically, willingness to learn, team facilitator and hard worker.\nPERSONAL PROFILE:\nName\n\n\n: LOKANATH BARAL\nNationality\n\n: Indian\n\nDate of Birth\n\n: 28.June.1986\nPassport                   : H7635560\n\nVisited Country         : Singapore,Malaysia\nLanguages known     : English(US), English(UK),Hindi,Oriya\nDECLARATION:\n\nI hereby declare that all the information furnished above is correct to the best of my Knowledge and Belief.\nPlace: Bangalore\nDate:\n\n\n\n\n\n\n\n\n(Lokanath Baral)","annotation":[{"label":["Name"],"points":[{"start":15231,"end":15244,"text":"Lokanath Baral"}]},{"label":["Location"],"points":[{"start":15206,"end":15214,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":15081,"end":15081,"text":"R"}]},{"label":["Skills"],"points":[{"start":14876,"end":14876,"text":"R"}]},{"label":["Skills"],"points":[{"start":14848,"end":14848,"text":"R"}]},{"label":["Skills"],"points":[{"start":14840,"end":14840,"text":"R"}]},{"label":["Skills"],"points":[{"start":14630,"end":14630,"text":"R"}]},{"label":["Skills"],"points":[{"start":14083,"end":14083,"text":"R"}]},{"label":["Skills"],"points":[{"start":14080,"end":14080,"text":"R"}]},{"label":["Skills"],"points":[{"start":14074,"end":14076,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":14069,"end":14072,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":14064,"end":14064,"text":"R"}]},{"label":["Skills"],"points":[{"start":14054,"end":14055,"text":"ML"}]},{"label":["Skills"],"points":[{"start":14046,"end":14047,"text":"ML"}]},{"label":["Skills"],"points":[{"start":13852,"end":13852,"text":"R"}]},{"label":["Skills"],"points":[{"start":13254,"end":13254,"text":"R"}]},{"label":["Skills"],"points":[{"start":12928,"end":12928,"text":"R"}]},{"label":["Skills"],"points":[{"start":12925,"end":12925,"text":"R"}]},{"label":["Skills"],"points":[{"start":12920,"end":12922,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":12915,"end":12918,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":12910,"end":12910,"text":"R"}]},{"label":["Skills"],"points":[{"start":12090,"end":12090,"text":"R"}]},{"label":["Skills"],"points":[{"start":11606,"end":11609,"text":"CSS3"}]},{"label":["Skills"],"points":[{"start":11602,"end":11603,"text":"ML"}]},{"label":["Skills"],"points":[{"start":11600,"end":11604,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":11593,"end":11598,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":11588,"end":11591,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":11582,"end":11582,"text":"R"}]},{"label":["Skills"],"points":[{"start":11169,"end":11169,"text":"R"}]},{"label":["Skills"],"points":[{"start":11158,"end":11158,"text":"R"}]},{"label":["Skills"],"points":[{"start":11134,"end":11134,"text":"R"}]},{"label":["Skills"],"points":[{"start":11122,"end":11122,"text":"R"}]},{"label":["Skills"],"points":[{"start":11098,"end":11098,"text":"R"}]},{"label":["Skills"],"points":[{"start":10556,"end":10556,"text":"R"}]},{"label":["Skills"],"points":[{"start":10474,"end":10474,"text":"R"}]},{"label":["Skills"],"points":[{"start":10432,"end":10432,"text":"R"}]},{"label":["Skills"],"points":[{"start":10409,"end":10412,"text":"CSS3"}]},{"label":["Skills"],"points":[{"start":10405,"end":10406,"text":"ML"}]},{"label":["Skills"],"points":[{"start":10403,"end":10407,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":10398,"end":10401,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":10395,"end":10396,"text":"ML"}]},{"label":["Skills"],"points":[{"start":10382,"end":10387,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":10110,"end":10110,"text":"R"}]},{"label":["Skills"],"points":[{"start":10100,"end":10100,"text":"R"}]},{"label":["Skills"],"points":[{"start":9054,"end":9057,"text":"CSS3"}]},{"label":["Skills"],"points":[{"start":9050,"end":9051,"text":"ML"}]},{"label":["Skills"],"points":[{"start":9048,"end":9052,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":9041,"end":9046,"text":"Jquery"}]},{"label":["Skills"],"points":[{"start":9036,"end":9039,"text":"AJAX"}]},{"label":["Skills"],"points":[{"start":8582,"end":8584,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":8544,"end":8546,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":8470,"end":8470,"text":"R"}]},{"label":["Skills"],"points":[{"start":8422,"end":8422,"text":"R"}]},{"label":["Skills"],"points":[{"start":8231,"end":8231,"text":"R"}]},{"label":["Skills"],"points":[{"start":7920,"end":7922,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":7776,"end":7776,"text":"R"}]},{"label":["Skills"],"points":[{"start":7711,"end":7711,"text":"R"}]},{"label":["Skills"],"points":[{"start":7489,"end":7494,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7483,"end":7483,"text":"R"}]},{"label":["Skills"],"points":[{"start":7420,"end":7420,"text":"R"}]},{"label":["Skills"],"points":[{"start":7409,"end":7414,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7355,"end":7355,"text":"R"}]},{"label":["Skills"],"points":[{"start":7286,"end":7286,"text":"R"}]},{"label":["Skills"],"points":[{"start":7276,"end":7276,"text":"R"}]},{"label":["Skills"],"points":[{"start":6907,"end":6907,"text":"R"}]},{"label":["Skills"],"points":[{"start":6771,"end":6771,"text":"R"}]},{"label":["Skills"],"points":[{"start":6746,"end":6746,"text":"R"}]},{"label":["Skills"],"points":[{"start":6737,"end":6740,"text":"HIVE"}]},{"label":["Skills"],"points":[{"start":6718,"end":6719,"text":"ML"}]},{"label":["Skills"],"points":[{"start":6649,"end":6654,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6647,"end":6647,"text":"R"}]},{"label":["Skills"],"points":[{"start":6465,"end":6467,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6210,"end":6212,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":6037,"end":6037,"text":"R"}]},{"label":["Skills"],"points":[{"start":5930,"end":5935,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":5891,"end":5891,"text":"R"}]},{"label":["Skills"],"points":[{"start":5793,"end":5793,"text":"R"}]},{"label":["Skills"],"points":[{"start":5782,"end":5787,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5743,"end":5748,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5737,"end":5737,"text":"R"}]},{"label":["Skills"],"points":[{"start":5679,"end":5684,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5596,"end":5596,"text":"R"}]},{"label":["Skills"],"points":[{"start":5593,"end":5593,"text":"R"}]},{"label":["Skills"],"points":[{"start":5436,"end":5436,"text":"R"}]},{"label":["Skills"],"points":[{"start":4948,"end":4948,"text":"R"}]},{"label":["Skills"],"points":[{"start":4935,"end":4935,"text":"R"}]},{"label":["Skills"],"points":[{"start":4698,"end":4703,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4694,"end":4694,"text":"R"}]},{"label":["Skills"],"points":[{"start":4606,"end":4606,"text":"R"}]},{"label":["Skills"],"points":[{"start":4596,"end":4596,"text":"R"}]},{"label":["Skills"],"points":[{"start":3648,"end":3653,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3646,"end":3646,"text":"R"}]},{"label":["Skills"],"points":[{"start":3437,"end":3437,"text":"R"}]},{"label":["Skills"],"points":[{"start":3059,"end":3059,"text":"R"}]},{"label":["Skills"],"points":[{"start":3043,"end":3043,"text":"R"}]},{"label":["Skills"],"points":[{"start":2983,"end":2983,"text":"R"}]},{"label":["Skills"],"points":[{"start":2913,"end":2913,"text":"R"}]},{"label":["Skills"],"points":[{"start":2674,"end":2679,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":2626,"end":2628,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2613,"end":2613,"text":"R"}]},{"label":["Skills"],"points":[{"start":2610,"end":2610,"text":"R"}]},{"label":["Skills"],"points":[{"start":2604,"end":2606,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2575,"end":2579,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":2559,"end":2563,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":2552,"end":2553,"text":"ML"}]},{"label":["Skills"],"points":[{"start":2546,"end":2550,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":2541,"end":2543,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2535,"end":2539,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":2515,"end":2519,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":2450,"end":2450,"text":"R"}]},{"label":["Skills"],"points":[{"start":2301,"end":2306,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2291,"end":2291,"text":"R"}]},{"label":["Skills"],"points":[{"start":2273,"end":2273,"text":"R"}]},{"label":["Skills"],"points":[{"start":2239,"end":2244,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2174,"end":2176,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2162,"end":2167,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2160,"end":2160,"text":"R"}]},{"label":["Skills"],"points":[{"start":1898,"end":1900,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1892,"end":1896,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1883,"end":1886,"text":"HIVE"}]},{"label":["Skills"],"points":[{"start":1879,"end":1881,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1865,"end":1867,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1728,"end":1728,"text":"R"}]},{"label":["Skills"],"points":[{"start":1599,"end":1603,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1535,"end":1540,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1411,"end":1411,"text":"R"}]},{"label":["Skills"],"points":[{"start":1214,"end":1214,"text":"R"}]},{"label":["Skills"],"points":[{"start":1203,"end":1208,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1149,"end":1149,"text":"R"}]},{"label":["Skills"],"points":[{"start":1015,"end":1020,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1012,"end":1012,"text":"R"}]},{"label":["Skills"],"points":[{"start":780,"end":780,"text":"R"}]},{"label":["Skills"],"points":[{"start":767,"end":767,"text":"R"}]},{"label":["Skills"],"points":[{"start":483,"end":483,"text":"R"}]},{"label":["Skills"],"points":[{"start":480,"end":480,"text":"R"}]},{"label":["Location"],"points":[{"start":198,"end":206,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":147,"end":147,"text":"R"}]},{"label":["Name"],"points":[{"start":128,"end":141,"text":"Lokanath Baral"}]},{"label":["Skills"],"points":[{"start":41,"end":42,"text":"ML"}]},{"label":["Skills"],"points":[{"start":26,"end":31,"text":"Python"}]},{"label":["Skills"],"points":[{"start":17,"end":17,"text":"R"}]},{"label":["Skills"],"points":[{"start":3,"end":3,"text":"R"}]},{"label":["Skills"],"points":[{"start":2,"end":2,"text":"R"}]}],"extras":null,"metadata":{"first_done_at":1532684881000,"last_updated_at":1532684881000,"sec_taken":201,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "R.D.PRAVEEN KUMAR \n +91-740-679-1792 | 91-888-692-4300 | rdpraveen@ymail.com \n\n \n\nSUMMARY \n\n1. Experience in working with Machine learning algorithms. \n\n2. Seven years of experience in development of IVR application, static and dynamic prompts using TCL with \n\nenhanced multi language support.  This application is designed to handle calls on a voice gateway to suite \n\nthe requirement of several corporates. \n\n3. Developed a Database oriented middleware for Pervasive Sensor Environment (PSN) project. \n\n4. Built Heterogeneous wireless server for green buildings in Cyber Physical system (CPS) project. \n\n5. Actively involved in Intelligent Transport Systems (ITS) project and developed an application to track a \n\nvehicle – Smart Public Transport Notification System (SPTNS). \n\n6. Created a platform in TinyOS operating system for a low cost Wireless Sensor Network (WSN) module \n\ndeveloped at Indian Institute of Technology Hyderabad. \n\n \n\nTECHNICAL SKILLS \n\nIVR Tools                   Syntellect, Five9, Power Connect \n\nComputer Languages    C, Java/J2EE, Python \n\nMachine Learning tools   Scikit-Learn \n\nData Wrangling Tools    Pandas \n\nData Visualization   Matplotlib, Seaborn \n\nMachine Learning Algorithms  Regression, Decision trees, Naïve-Bayes, K-means, KNN, SVM,                                                                                                \n\n                                                                 Classification, Clustering \n\nDatabase    MS-SQL, MySQL \n\n \n\n \n\nWORK AND RESEARCH EXPERIENCE \n\nSr. Systems Analyst \nSonata Software, Bangalore               April 2015 – Present \n\n \n1. Implementing Machine learning algorithms. \n\n2. Migration of existing IVR to a cloud based platform. \n\n3. Co-coordinating with on-site team to implement the migration. \n\n4. Designed the call routing strategy. \n\n \n\n\n\nR. D. Praveen Kumar \n\nPage 2 of 4 \n \n\nTelecom Developer \nC3I-Inc., Hyderabad        July 2012 – March 2015 \n \n \n\n1. Support for IVR system developed using Python and Syntellect.   \n\n2. Text-to-Speech applications   (TTS ) \n\n3. Profound knowledge of T1 interfaces with Call center technology. \n\n4. Ensured to tune speech applications.  \n\n5. Volunteered in supporting minor enhancements and maintenance activity on Syntellect Customer \n\nInteraction Management multi-node deployment. \n\n6. Ensure all the processes pertaining to CIM are always up and running and report any deviation. \n\n7. Scripts version control using TFS (Team Foundation Server). \n\n8. Documentation of scripts and writing test cases. \n\n9. Coordinating with database team to modify database structure and make appropriate changes to query in \n\nVB Script which fetches user details. \n\n \n\nProject Associate \nIIT, Hyderabad         March 2011 – July 2012 \n \n\nPervasive Sensor eNvironment (PSN) project (Oct 2011 – July 2012) \n \n\nDatabase  PostgreSQL \nWebsite Designing JSP \nRTOS   TinyOS \n\n \na. It is a project done as theme 2 for India-UK Advanced Technology Center of Excellence (IUATC). \n\nPervasive Sensor environment is a project on pervasive sensor networks for environmental \n\npollution monitoring. Project includes development of Zigbee based WSN node (IITH-mote) and a \n\nsensor board for air pollution monitoring. \n\nb. Made WSN node TinyOS compatible and also developed a Database Oriented Middleware for \n\ncollection and processing of real time sensor data. Developed website for interactive display of \n\nair pollution monitoring using JSP and Glassfish. \n\nc. Developed a newTinyOS platform for the board developed at IIT Hyderabad. The platform is \n\ntested with most of sample examples given in TinyOS. \n\nd. Demonstrated the project at IU-ATC Workshop, January 2012 \n\n \n\nIntelligent Transport Systems (ITS) project  (Jan 2012 –Mar 2012) \nAdvisors: Prof. U. B. Desai, Dr. Bheemarjuna Reddy Tamma \n\n \n Database  MySQL \n OS   Android \n\n\n\nR. D. Praveen Kumar \n\nPage 3 of 4 \n \n\n Server-Side  JSP \n\na. Developed complete architecture of Smart Public Transport Notification System (SPTNS) which \n\nincludes Tracking buses in real-time with GPS receivers, Sending location feeds of GPS receiver to \n\nthe server, Map matching, Data Handling, Travel-time estimation. \n\nb. Built an Android app for offering ITS services to commuters. \n\nc. Demonstrated the project at CORD Workshop, February 2012. \n\n \n\nCyber Physical Systems (CPS) project  (Oct 2011 – July 2012) \n Advisors: Prof. U. B. Desai, Dr. P.Raja Lakshmi \n\n \n  Programming Language  Java \n\n Database   MySQL  \n\na. It is a DIT funded project. The main goal of Cyber-Physical Systems (CPS) innovation hub at IIT \n\nHyderabad is to create, develop and proto-type ideas for a smarter planet \n\nb. Developed the Cognitive-Server (Heterogeneous Wireless Server) for the smart-home test bed  \n\nwhich involves collecting sensor data from various sensor s like RFID, PIR, LDR, Magnetic door \n\nswitch deployed across the room via Zigbee motes and taking decision depending on the sensor \n\nstatus and sending the decision to Wi-Fi module which operates the loads in the room. \n\nc. Demonstrated the project at DIT Workshop, December 2012. \n\n \nAssociate Software Engineer \nUniphore Software Systems, India (May 2010 - Mar 2011) \n\n \n Programming language  Java \n Database   MSSQL \n\nSpeech Engine  Nuance Speech Recognition \n  \n\nSub-K Financial Inclusion:  \n\na. Handling IVR implementation \n\nb. Database design for the application \n\nc. Integration of IVR with ISO 8583 \n\nd. Handling production issues \n\ne. Created state-of-the art Voice User Interface (VUI).  \n\nMobile Voice Banking: \n\na. Voice Banking is an interactive voice based banking application performing balance checks, account \n\ntransactions, payments etc., via mobile device such as mobile phone   \n\nb. The application has a provision and an ailment of banking and financial services with the help of \n\nmobile telecommunication devices.  \n\nc. Handled IVR and Database for this project. \n\n\n\nR. D. Praveen Kumar \n\nPage 4 of 4 \n \n\n \n\nACHIEVEMENTS \n\n1. PresentedIITH Mote – A Low Cost ZigBee based Mote,Cognitive Radio (CORD 2012),February 2012 \n\n2. Presented Smart Building Architecture using Heterogeneous Wireless Technologies for Cyber Physical \n\nSystems - IBM Collaborative Academia Research Exchange (I-CARE 2011), October 2011 \n\nINTERNSHIP \n\nIndian Space Research Organization (ISRO), Sriharikota, India   Dec 2007 – Jan 2008 \n\n Advisor: Mr Babu Rao, Mr. R. Tatayya Babu \n\nStudy of S-Band TTC and Communication systems of ISTRAC at ISRO \n\nEDUCATION \n\nMaster of Engineering in Communication Systems     \n\nAnna University, Chennai, TN        June 2010 \n\nArticles Published \n\n1. Employing Hybrid Automatic Repeat reQuest (HARQ) on MIMO  - International Conference on Signal \n\nProcessing and VLSI (SPVL 2010)  \n\n2. Design and Implementation of MIMO Transceivers using Hybrid Automatic Repeat Request (HARQ) - Third \n\nNational Conference on Digital Convergence (TNDC 2010) \n\nBachelor of Technology in Electronics and Communication Engineering   \n\nJawaharlal Nehru Technological University, Hyderabad     May 2008 \n\nIntermediate in Mathematics Physics and Chemistry \n\nBoard of Intermediate Education, Hyderabad      Mar 2004","annotation":[{"label":["Skills"],"points":[{"start":7052,"end":7052,"text":"C"}]},{"label":["Skills"],"points":[{"start":6914,"end":6914,"text":"C"}]},{"label":["Skills"],"points":[{"start":6862,"end":6862,"text":"C"}]},{"label":["Skills"],"points":[{"start":6846,"end":6846,"text":"C"}]},{"label":["Skills"],"points":[{"start":6824,"end":6824,"text":"C"}]},{"label":["Skills"],"points":[{"start":6652,"end":6652,"text":"C"}]},{"label":["Skills"],"points":[{"start":6523,"end":6523,"text":"C"}]},{"label":["Skills"],"points":[{"start":6478,"end":6478,"text":"C"}]},{"label":["Skills"],"points":[{"start":6444,"end":6444,"text":"C"}]},{"label":["Skills"],"points":[{"start":6429,"end":6429,"text":"C"}]},{"label":["Skills"],"points":[{"start":6399,"end":6399,"text":"C"}]},{"label":["Skills"],"points":[{"start":6393,"end":6393,"text":"C"}]},{"label":["Skills"],"points":[{"start":6204,"end":6204,"text":"C"}]},{"label":["Skills"],"points":[{"start":6160,"end":6160,"text":"C"}]},{"label":["Skills"],"points":[{"start":6129,"end":6129,"text":"C"}]},{"label":["Skills"],"points":[{"start":6015,"end":6015,"text":"C"}]},{"label":["Skills"],"points":[{"start":5998,"end":5998,"text":"C"}]},{"label":["Skills"],"points":[{"start":5975,"end":5975,"text":"C"}]},{"label":["Skills"],"points":[{"start":5931,"end":5931,"text":"C"}]},{"label":["Skills"],"points":[{"start":5443,"end":5443,"text":"C"}]},{"label":["Skills"],"points":[{"start":4659,"end":4659,"text":"C"}]},{"label":["Skills"],"points":[{"start":4537,"end":4537,"text":"C"}]},{"label":["Skills"],"points":[{"start":4513,"end":4513,"text":"C"}]},{"label":["Skills"],"points":[{"start":4322,"end":4322,"text":"C"}]},{"label":["Skills"],"points":[{"start":4298,"end":4298,"text":"C"}]},{"label":["Skills"],"points":[{"start":4263,"end":4263,"text":"C"}]},{"label":["Skills"],"points":[{"start":3649,"end":3649,"text":"C"}]},{"label":["Skills"],"points":[{"start":2984,"end":2984,"text":"C"}]},{"label":["Skills"],"points":[{"start":2958,"end":2958,"text":"C"}]},{"label":["Skills"],"points":[{"start":2541,"end":2541,"text":"C"}]},{"label":["Skills"],"points":[{"start":2361,"end":2361,"text":"C"}]},{"label":["Skills"],"points":[{"start":2260,"end":2260,"text":"C"}]},{"label":["Skills"],"points":[{"start":2104,"end":2104,"text":"C"}]},{"label":["Skills"],"points":[{"start":1991,"end":1996,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1893,"end":1893,"text":"C"}]},{"label":["Skills"],"points":[{"start":1726,"end":1726,"text":"C"}]},{"label":["Skills"],"points":[{"start":1634,"end":1649,"text":"Machine learning"}]},{"label":["Skills"],"points":[{"start":1526,"end":1526,"text":"C"}]},{"label":["Skills"],"points":[{"start":1515,"end":1515,"text":"C"}]},{"label":["Skills"],"points":[{"start":1453,"end":1453,"text":"C"}]},{"label":["Skills"],"points":[{"start":1437,"end":1437,"text":"C"}]},{"label":["Skills"],"points":[{"start":1061,"end":1066,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1050,"end":1058,"text":"Java/J2EE"}]},{"label":["Skills"],"points":[{"start":1047,"end":1047,"text":"C"}]},{"label":["Skills"],"points":[{"start":1025,"end":1025,"text":"C"}]},{"label":["Skills"],"points":[{"start":1015,"end":1015,"text":"C"}]},{"label":["Skills"],"points":[{"start":949,"end":949,"text":"C"}]},{"label":["Skills"],"points":[{"start":945,"end":945,"text":"C"}]},{"label":["Skills"],"points":[{"start":783,"end":783,"text":"C"}]},{"label":["Skills"],"points":[{"start":590,"end":590,"text":"C"}]},{"label":["Skills"],"points":[{"start":567,"end":567,"text":"C"}]},{"label":["Skills"],"points":[{"start":251,"end":251,"text":"C"}]},{"label":["Skills"],"points":[{"start":122,"end":137,"text":"Machine learning"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"R.D.PRAVEEN KUMAR "}]}],"extras":null,"metadata":{"first_done_at":1532683242000,"last_updated_at":1532683242000,"sec_taken":125,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Rajeev Kumar Jha​​​​\nAround 7 Yrs of experience in Data Science role\nContact no.: +91-9900097851\nEmail: rajeevjha0101@gmail.com\nSeeking challenging assignments in Data Science, Data Analytics, Statistical Analysis, Predictive modelling, Statistical Modelling, Machine Learning Modelling, R, Python and Other challenging roles ​with a frontline organization.\nCAREER PRÉCIS\n\n· B. Tech, MBA and 9.5 years' experience as a data scientist, advance data analysis, machine learning models, statistical model, predictive models, data visualization etc with R, Python and Tableau.\n· Currently associated with Sobha Ltd, Bangalore/Dubai as Senior Manager Data Analytics and Data Science.\n· Proficient in managing & development of a Team, ensuring that it adheres to policies / best practices. \n· Quick to grasp new concepts and appetite for modern technology.\n· Excellent in mathematical, statistical and Analytical skills.\n· An effective communicator with excellent relationship building and interpersonal skills.\nSKILLS \n\n· Experience in analytics tools such as R, Python, Tableau, SQL, MATLAB, Advance Excel etc \n· Experience on Machine Learning Models: Linear Regression, Logistics Regression, Neural Network, Decision trees, Random Forest, boosting, Clustering, kNN, Time Series Analysis, PCA, SVM, NLP and Text Mining.\n· Ability to work with large data sets and to interpret them statistically & exploratory data analysis.\n· Familiarity with web analytics, Google analytics.\n· Domain knowledge of Banking, Finance, Insurance and Real Estate.  \n\nCAREER CONTOUR\n\nSince Jan’2017: Sobha Ltd, Bangalore/Dubai\nSenior Manager (Data Analytics and Data Science)\n· Deliver customized analysis leveraging internal and external, structured and unstructured datasets using R & Python. \n\n· Using cutting edge machine learning statistical modelling techniques and develop predictive models.\n· Trained Linear Regression and SVM models to predict pricings of a project with 97.6% accuracy.\n\n· Used K-means clustering on existing customers base to get clusters for customised target marketing.   \n· Improve existing data analysis by always researching cutting edge statistical modeling and data visualization techniques.\n\n· Using advanced modeling techniques to Manipulate large data sets.\n· Develop advance analytics platform to house and analyze big data. \n\n· Help with the process of curating, cleaning and integrating data to enable scalability of analysis. \n\n· Leverage several internal databases as well as external data sources.\n\n· Collaborate with other teams to leverage tools and techniques developed across company. \n\n· Always strive to automate analyses where possible. \n\n· Help with advancing Data Visualization capabilities\n\n· Leading, motivating and training of growing data science team.\n\nJan’2016 to Jan’2017: Axis Bank, Bangalore \n\nSenior Manager (Data Science), Axis Bank\n· Applied appropriate techniques, such as exploratory data analysis, regression, Random Forest, trees, cluster analysis, association analysis etc with R and Python.\n\n· Developed statistical models to and delivery of analytic offerings and solutions.\n\n· Trained Logistic Regression model to predict customer eligibility for loan on card with 93.40% accuracy. \n\n· Managed a team of analytics resources to ensure that deliverables are met with quality and in a timely fashion\n\n· Engaged with middle and senior management effectively to understand business problems \n\n· Developed and articulate strategic recommendations based on rigorous data analysis. \n\n· Developed executive dashboards to present the analytical insights derived from the data analytics. \n\n Jan’2013 To Dec’2015: Bharti AXA General Insurance, Bangalore\n\nDy. Manager (Underwriting and Data Science)\n· Translated the business requirements into data driven insights.\n\n·  Features selection, build and optimized classifiers using machine learning techniques.\n\n· Trained Random Forest Model to detect fraud claim with 96.37% accuracy.  \n\n· Trained linear regression model to predict risk based pricing with 98.6% accuracy.\n·  Enhanced data collection procedures to include information that is relevant for building analytic systems.\n\n·  Processing, cleansing, and verifying the integrity of data used for analysis.\n\n·  Done ad-hoc analysis and presented results in a clear manner.\n\n·  Created automated anomaly detection systems and constant tracking of its performance.\n\n· Risk based pricing models for individual proposal and fleet proposals for Risk evaluations & right pricing.\n Jan’2011 to Dec’2012: HDFC BANK, Bangalore\n\nDy Manager (Data Analysis)\n· Analysed business data and customer analysis for business done through online channels.\n· Visualize (dashboards, charts, infographics), analyse, and provide analytics on sensitive data to build insights. Assist teams to take un-analysed data and transform into rich visual storytelling.\n· Created predictive models to suggest banking products for existing customers of the bank.\n\n· Collaborate with different teams to elicit & understand their requirements & challenges and develop potential solutions.\n· Stay current with latest research and technology ideas; share knowledge by clearly articulating results and ideas to key decision makers.\n\nSept’2009 to Dec’2010: ICICI Lombard General Insurance, Bangalore\nUnderwriting and Data Analytics\n·  Collect, analyses, interpret and summaries data in preparation for generation of statistical and analytical reports\n\n· Develops periodic performance reports and Scorecards.\n\n· Risk Analysis in proposal, decisions for acceptance of risks and Determining the risk prices.\n· Analysed data from existing portal for loss ratio of businesses. \n\n· Internally coordinate with vertical heads to improve/ eliminate the above gaps.\n· Worked with data to derive valuable and consumable insights to improve business quality.\n\nMAr’2008 to Sept’2009: Deutsche Bank, Bangalore \nAcquisition Manager \n· Analysed market data and identified opportunity for business growth.\n\n· Translated the business requirements into data driven insights.\n\n· Identified key data sources and obtained access files necessary to perform data analytics\n· Created (dashboards, charts, infographics), analysed, and provided analytics on data to build insights.\n\n· Presented key findings for the management team.\n\nSCHOLASTICS\n· MBA in Information Technology from IBS Hyderabad with 71% in 2008.\n· B.E. in ECE from MIT Muzaffarpur (Government Engg College) with 79% in 2006.\n· Machine Learning from Stanford University in 2017 (Taught by: Andrew Ng on Coursera).  \n\nCOMPUTER PROFICIENCY\n\nProductivity Tools \n: R, Python, Tableau, SQL, MATLAB, Octave, Microsoft Excel & PowerPoint and Google Analytics.\nPERSONAL DOSSIER\n\nLanguage:\nEnglish & Hindi.\nDOB       :          05-FEB-1981\nAddress : Flat No-G13, Avani Shringeri Nagar, Nyanappanahalli Main Road , Bangalore-560076.","annotation":[{"label":["Location"],"points":[{"start":6841,"end":6849,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":6834,"end":6834,"text":"R"}]},{"label":["Skills"],"points":[{"start":6704,"end":6704,"text":"R"}]},{"label":["Skills"],"points":[{"start":6691,"end":6691,"text":"R"}]},{"label":["Skills"],"points":[{"start":6622,"end":6627,"text":"MATLAB"}]},{"label":["Skills"],"points":[{"start":6616,"end":6619,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":6608,"end":6614,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":6600,"end":6605,"text":"Python"}]},{"label":["Skills"],"points":[{"start":6597,"end":6597,"text":"R"}]},{"label":["Skills"],"points":[{"start":6563,"end":6563,"text":"R"}]},{"label":["Skills"],"points":[{"start":6560,"end":6560,"text":"R"}]},{"label":["Education"],"points":[{"start":6316,"end":6318,"text":"MBA"}]},{"label":["Location"],"points":[{"start":5881,"end":5889,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":5506,"end":5506,"text":"R"}]},{"label":["Location"],"points":[{"start":5285,"end":5293,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":4545,"end":4553,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":4477,"end":4477,"text":"R"}]},{"label":["Skills"],"points":[{"start":4403,"end":4403,"text":"R"}]},{"label":["Skills"],"points":[{"start":3900,"end":3900,"text":"R"}]},{"label":["Location"],"points":[{"start":3677,"end":3685,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":3139,"end":3139,"text":"R"}]},{"label":["Skills"],"points":[{"start":3026,"end":3031,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3020,"end":3020,"text":"R"}]},{"label":["Skills"],"points":[{"start":2950,"end":2950,"text":"R"}]},{"label":["Location"],"points":[{"start":2816,"end":2824,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1889,"end":1889,"text":"R"}]},{"label":["Skills"],"points":[{"start":1760,"end":1765,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1756,"end":1756,"text":"R"}]},{"label":["Location"],"points":[{"start":1584,"end":1592,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":1554,"end":1554,"text":"R"}]},{"label":["Skills"],"points":[{"start":1546,"end":1546,"text":"R"}]},{"label":["Skills"],"points":[{"start":1543,"end":1543,"text":"R"}]},{"label":["Skills"],"points":[{"start":1525,"end":1525,"text":"R"}]},{"label":["Skills"],"points":[{"start":1220,"end":1220,"text":"R"}]},{"label":["Skills"],"points":[{"start":1176,"end":1176,"text":"R"}]},{"label":["Skills"],"points":[{"start":1154,"end":1154,"text":"R"}]},{"label":["Skills"],"points":[{"start":1079,"end":1084,"text":"MATLAB"}]},{"label":["Skills"],"points":[{"start":1073,"end":1076,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":1065,"end":1071,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1057,"end":1062,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1054,"end":1054,"text":"R"}]},{"label":["Location"],"points":[{"start":611,"end":619,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":563,"end":569,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":552,"end":557,"text":"Python"}]},{"label":["Skills"],"points":[{"start":549,"end":549,"text":"R"}]},{"label":["Education"],"points":[{"start":384,"end":386,"text":"MBA"}]},{"label":["Skills"],"points":[{"start":366,"end":366,"text":"R"}]},{"label":["Skills"],"points":[{"start":363,"end":363,"text":"R"}]},{"label":["Skills"],"points":[{"start":360,"end":360,"text":"R"}]},{"label":["Skills"],"points":[{"start":291,"end":296,"text":"Python"}]},{"label":["Skills"],"points":[{"start":288,"end":288,"text":"R"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"Rajeev Kumar Jha​​​​"}]},{"label":["Skills"],"points":[{"start":0,"end":0,"text":"R"}]}],"extras":null,"metadata":{"first_done_at":1532688378000,"last_updated_at":1532688378000,"sec_taken":104,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Ravishankar R\nMail:  ravi_starr@yahoo.com\n\n\n\n\nMob: +919901206282 \n\nPROFILE SUMMARY:\n\n\nNearly 8.5+ Years Hands-on Experience in Image Processing, ADAS, Machine Learning, Computer Vision, Robotics and Machine vision algorithm development\n· Been to MvTec - Halcon 11 training in Munich, Germany\n\n· Been to Delarue - Gateshead, UK(Onsite-Machine vision) for deployment & support\n· Over all 8.5 + years of rigorous industrial experiences in product development on MS Windows Systems using VC++, C++, Opencv, Win32 SDK, MFC, Python, Scikit Learn, SVM, RandomForest.\n· Analysis the client requirements\n\n· Selecting the industrial cameras, lenses and the appropriate lighting \n\n· Designing, developing the machine vision algorithm,  POC algorithms\n\n· Responsible for Vision machine implementation, Support at client place & interacting with Customer \n· Responsible for designing, developing and implementing the imaging algorithms using C++, Python and OpenCV, Halcon.\n· Identifying use cases based on Clients and Countries.\n\nEMPLOYMENT HISTORY:\n\n\tFrom\n\tTo\n\tName of Company\n\tDesignation\n\n\tJuly 2015\n\tTill date\n\tTata Consultancy Services, \n\nCochin\n\tI.T Analyst\n\n\tMarch 2011\n\tJuly 2015\n\tLucid Imaging private limited,\n\nBangalore\n\tSenior SW Engineer\n\n\tFeb 2009\n\tFeb 2011\n\tVizzitec solutions private limited, Coimbatore\n\tSW Engineer\n\n\nSKILL DETAILS:\n\n\tLANGUAGES\n\tVC++, C++, C, Visual studio 2008,2013\n\n\tOTHER INFORMATION\n\t· Windows programming in C/C++ using VC++6, WIN32 SDK, MFC.\n\n· Halcon 10.0,11, Opencv\n\n\n\nPROJECTS EXPERIENCE DETAILS in Robotics\nADAS Projects – Machine Learning:\nDriver Drowsiness Detection:\n\nDriver drowsiness detection system is an Driver assistance system which helps the driver from accident, it monitors the driver’s face / eyes continuously while driving and warns driver if fatigue detected.\n\nKeywords: Haar Features, Contour based approach, opencv, c++, Machine Learning\nVehicle detection system:\n\nDesigned and implemented vehicle detection system, Persistent vehicle detection and tracking from a single camera in motorway scenario, in different traffic and varying lighting condition and tests on with available vehicle detection datasets (TME Motorway Datasets, LISA datasets)\n\nKeywords: SVM, HOG, R-HOG, OpenCV, Python, Scikit Learn\nCognitive Computing Suite v2.0:\nCCS is the intelligent software that can be used mainly used for product digitization for retail and banking domain clients, It has intelligence of reading the text from the given product images and categorize in to the respective product type and can also categorize attributes.\n\nKeywords: Text Extraction, Text analysis, OCR, Tesseract, opencv,c++\n\nMachine Learning Solution for Document Content Extraction: \n\n\n\nTo develop the solution for extracting attributes from Invoice and packaging list documents for logistics domain.\nModules: Data Analysis and Preparation, Text Analysis, Attribute extraction, Machine Learning, OCR, Tesseract, C++, Opencv\nKeywords: Random Forest, Normalization.\nResponsibilities : Requirement analysis, Prototype Demo and Solution Approach presentation given to customer at their premises, developing algorithm and system testing.\n\nMachine Learning Solution for Gift Card Fraud Detection for Walmart \n           To develop a POC solution for anonymzed gift card transactions as fraudulent or genuine. \nModules: Data Analysis and Preparation, Compute Feature Vector and Machine learning module. \n\nKeywords: Python, Simple Logistic Regression, Voting Approach, Normalization, Scikit, Clustering\nResponsibilities : Requirement analysis, developing algorithm and system testing.\nPROJECTS EXPERIENCE DETAILS – Machine Vision/ Computer Vision Applications:\n\nPaper inspection system\n\n\tProject start to end date\n\tJan’15 to April 2015\n\n\tDetails of skills used\n\tC#.net, MVTec Halcon 12.0, Microsoft Windows 7.0\n\n\tTeam size\n\t3\n\n\tRole \n\tSr. Software Engineer\n\n\tResponsibility \n\tResponsibility for developing imaging algorithm & implementation\n\n\tProject details\n\n\n\tThis is a product to fulfill the requirement of inspect and validate the quality of paper boards. The system inspects various parameters like quality of Paper boards using a using a Line scan monochrome camera .\n\n\tImaging Techniques & Image processing properties\n\tImage Normalization, Finding mean & deviation of an image, Threshold\n\n\nCommercial Print inspection system\n\n\tProject start to end date\n\tJan’13 to Dec’14\n\n\tDetails of skills used\n\tVC++ 6.0, MFC ,MVTec Halcon 10.0, Microsoft Windows XP\n\n\tTeam size\n\t2\n\n\tRole \n\tSr. Software Engineer\n\n\tResponsibility \n\tResponsibility for developing imaging algorithm & implementation\n\n\tProject details\n\n\n\tThis is a product to fulfill the requirement of inspect and validate the quality of a new cartons machine vision system. The system inspects various parameters like print quality and measurements of a Cartons using a Line scan color camera \n\n\tImaging Techniques & Image processing properties\n\tDefect Identification algorithm, Model creation and the image matching, Min & max threshold \n\n\nCurrency inspection system\n\n\tProject start to end date\n\tJuly’11 to August 2014\n\n\tDetails of skills used\n\tVC++ 6.0, MFC , MVTec Halcon 9.0, Microsoft Windows XP\n\n\tTeam size\n\t2\n\n\tRole \n\tSr. Software Engineer\n\n\tResponsibility \n\tResponsibility for developing imaging algorithm & implementation\n\n\tProject details\n\n\n\tThis is a product to fulfill the requirement of banknote printers (Currencies) to inspect and validate the quality of a new currency sheet while printing using machine vision system. The system inspects various parameters like print quality and measurements of a currency sheet using a four mega pixel color camera with a speed of four currency sheets per second\n\n\tImaging Techniques & Image processing properties\n\tDefect Identification algorithm, Model creation and the image matching, Min & max threshold \n\n\nCrack Vision based Identification System: \n\n\tProject start to end date\n\tApr’09 to May’09\n\n\tClient / Customer name\n\tAuto Mikro Tek, Chennai\n\n\tDetails of skills used\n\tWindows programming under VC++,MFC, Sql server\n\n\tTeam size\n\t2\n\n\tRole \n\tSoftware Developer\n\n\tResponsibility \n\tSoftware coding & implementing\n\n\tProject details\n\n\n\tCrack identification system is an machine vision inspection system which is mainly design for inspecting the pneumatic components which inspect and identify the defects and images are captured by color camera with the resolution of 640 * 480\n\n\tImaging Techniques & Image processing properties\n\tCrack Identification algorithm, 10x10 White Round LED’s. \n\n\nVision Based Ocular Inspection System for line4:\n\n\tProject start to end date\n\tNov’09 to Jan’10\n\n\tClient / Customer name\n\tSKF India, Pune\n\n\tDetails of skills used\n\t1. Windows programming under VC++,MFC\n\n2. Sql server 7.0 for database connection\n\n\tTeam size\n\t2\n\n\tRole \n\tSoftware Developer\n\n\tResponsibility \n\tResponsible for complete Image processing system and  software implementation, Requirement collection, Design, Lead, Develop and Documentation \n\n\tProject details\n\n\n\tOcular inspection system is an machine vision inspection system which is mainly design for inspecting the ocular, which is an bearing component, the functionality of the system includes (Two types of inspections End view, Track view, dimple dia and other surface defects) and image acquired by area scan camera.\n\n\n\tImaging Techniques & Image processing properties\n\tGrey scale image, Edge detection, Surface scanning,  Threshold, DeNoising, Multiple Image processing, Ultraviolet LED’s, Sensors. \n\n\nEDUCATION DETAILS: \n\tYear\n\tCourse\n\tName of Inst.\n\tPercentage\n\n\tJun2005 – May2008\n\tB.Tech[IT]\n\tCIET, Coimbatore.\n\t65%\n\n\tJun2002 – Apr2005\n\tDiploma in IT\n\tSNGPC, Coimbatore.\n\t72%\n\n\tMay 2002\n\tSSLC\n\tSVVM Hr. Sec. School, Coimbatore.\n\t67%\n\n\nAcademic Projects:\n\nCheating prevention using cryptography:\n\nDescription:\n\n\nThe objective of the project is to prevent cheating from the unauthorized users or intruders to access the image.\n\nInventory control:\n\nDescription:\n\n\nThe application project of customizing the day to day activities by maintains a stock maintenance like sales, purchase, customer details of the concern.\n\nExtra-Curricular activities:\n\n1. Active volunteer in NSS.\n\n2. Prepared many technical question papers for college symposium.\n\n3. Won second prize in English essay writing competition.\n\n4. Participated in school, College cultural and won many prizes.\n\nPERSONAL INFORMATION:\n\n\tName as appearing in Passport\n\tRavishankar R\n\n\tSex\n\tMale\n\n\tDate of birth\n\t14-12-1985\n\n\tNationality\n\tIndian\n\n\tPassport\n\tNumber\n\nDate of Issue\n\nDate of expiry\n\nH6119970\n\n21-12-2009\n\n20-12-2019","annotation":[{"label":["Name"],"points":[{"start":8396,"end":8408,"text":"Ravishankar R"}]},{"label":["Education"],"points":[{"start":7556,"end":7565,"text":"B.Tech[IT]"}]},{"label":["Skills"],"points":[{"start":6698,"end":6700,"text":"C++"}]},{"label":["Skills"],"points":[{"start":6697,"end":6700,"text":"VC++"}]},{"label":["Skills"],"points":[{"start":6017,"end":6019,"text":"C++"}]},{"label":["Skills"],"points":[{"start":6016,"end":6019,"text":"VC++"}]},{"label":["Skills"],"points":[{"start":5110,"end":5112,"text":"C++"}]},{"label":["Skills"],"points":[{"start":5109,"end":5112,"text":"VC++"}]},{"label":["Skills"],"points":[{"start":4411,"end":4413,"text":"C++"}]},{"label":["Skills"],"points":[{"start":4410,"end":4413,"text":"VC++"}]},{"label":["Skills"],"points":[{"start":3638,"end":3651,"text":"omputer Vision"}]},{"label":["Skills"],"points":[{"start":3637,"end":3651,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":3148,"end":3163,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2926,"end":2928,"text":"C++"}]},{"label":["Skills"],"points":[{"start":2892,"end":2907,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2638,"end":2653,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1872,"end":1887,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1555,"end":1570,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1539,"end":1542,"text":"ADAS"}]},{"label":["Skills"],"points":[{"start":1530,"end":1537,"text":"Robotics"}]},{"label":["Skills"],"points":[{"start":1448,"end":1450,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1447,"end":1450,"text":"VC++"}]},{"label":["Skills"],"points":[{"start":1437,"end":1439,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1357,"end":1359,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1352,"end":1354,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1351,"end":1354,"text":"VC++"}]},{"label":["Skills"],"points":[{"start":929,"end":931,"text":"C++"}]},{"label":["Skills"],"points":[{"start":490,"end":492,"text":"C++"}]},{"label":["Skills"],"points":[{"start":485,"end":487,"text":"C++"}]},{"label":["Skills"],"points":[{"start":484,"end":487,"text":"VC++"}]},{"label":["Skills"],"points":[{"start":199,"end":213,"text":"Machine vision "}]},{"label":["Skills"],"points":[{"start":186,"end":193,"text":"Robotics"}]},{"label":["Skills"],"points":[{"start":169,"end":183,"text":"Computer Vision"}]},{"label":["Skills"],"points":[{"start":151,"end":166,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":145,"end":148,"text":"ADAS"}]},{"label":["Skills"],"points":[{"start":127,"end":142,"text":"Image Processing"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Ravishankar R"}]}],"extras":null,"metadata":{"first_done_at":1532682064000,"last_updated_at":1532682064000,"sec_taken":221,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "t seshasai\nEmail ID:-   SAI.TNLR@ GMAIL.com\nMobile No:- 9880311697\n\t                           \n\n\tProfile Summary\n· 9 years of Experience in IT industry, involved in Automation Framework Development using Python, \n· Web development using Javascript, AngularJS, HTML and CSS.\n\n· VBA development.\n\n· Protocol testing on WCDMA (3G) and mobile applications testing.\n\n· Bug fixing.\n\n· Given Demonstrations of feature development to the client managers.\n\n· Worked on Agile methodology.\n\n· Experience in SDLC and STLC.\n· Helping peer engineers and mentoring new team members.\nWork Experience\nPersistent Systems Limited - Bangalore, India – Mar 2015 to till date\n\nTeam Lead\n· Worked in Verifone client location.\n· Worked on Automation framework development using python.\n\n· Web UI developmet and VBA development.\nFubeus Technology private Limited - Bangalore, India – Oct 2013 to Feb 2015\nSr. Software Engineer\n· Worked in Intel Client location.\n· Developed new python scripts using ACS Framework.\n\n· Worked on Mobile applications testing on Android platform.\n· Android Compatibility Test Suite (CTS) execution and test report analysis.\n\nCybercom Datamatics Information Solutions private Limited - Bangalore, India – Apr 2011 to July 2013\nConsultant\n· Worked in ST Ericsson Client location.\n\n· Developed new python scripts using ATF Framework.\n· Protocol testing on WCDMA.\n· Reporting issues in Bug tracking tool and verification of issues after bug fix.\n\nSasken Communication Technologies Limited - Bangalore, India – Feb 2008 to Apr 2011\nSoftware Engineer\n· Worked on Mobile applications testing on Android and Symbian platforms\n\n· Test cases writing and execution using Quality center tool.\n\n· Issues reporting and sending test reports.\nEducation\nM.Sc  in Electronics – 2003 - 2005\nB.Sc in Electronics – 2000 - 2003\n\nProject Details (Persistent Systems Limited)\nVerifone Automation Test System (VATS Framework)\nClient: Verifone, Bangalore\nRole: Team Lead\nVATS Automation Framework is an integrated testing tool developed in python that aids testing applications written for POS terminals. This windows based tool simulates user actions, such as key presses, inser card and magnetic card swipes, which help automate the execution of test suites. It provides Excel interface to write test cases in Excel and internally convert those excel test cases to xml data files which are act as input data files to the Framework, and after completion of execution, framework will send the final test report as Email\nResponsibilities:\n· Development of multiple features of VATS Framework using Python.\n· Development of Excel Interface tool to write new test cases using VBA. \n\n· Development of  web UI for scheduling test executions and for test reports analysis using Django Framework, Javascript, AngularJS, html and CSS.\n\n· Developmet of test reports Performance charts using google charts in Javascript.\n\n· Giving demonstrations of features development to the stake holders.\n\n· Bug fixing.\nEnvironment: Windows 2007, Python 3.4\n\tKey Skills and Knowledge\nPython\nAutomation testing\nOther Skills\nJavascript\n\nAngularJS\n\nHTML\n\nCSS\n\nVBA\nPHP\n\nTools\nJira\nGit\n\nClearquest\n\nQuality center\n\nWireshark\n\n\n\nProject Details (Fubeus Technology Private Limited)\nIntel Android Platform Validation \n\n                                     \nClient: Intel, Bangalore\nRole : Sr. Software Engineer\n\nIntel Atom Z3000 Processor series (“Bay Trail”) is the company’s first mobile multi-core SoC and its most powerful offering is up to date for tablets and other sleek mobile designs. It delivers a fast and fluid experience and a powerful balance of performance, battery life, graphics and features. These products are Android tablets which have wifi, Bluetooth, wireless display and other multimedia features.\nResponsibilities:\n· Android Compatibility Test Suite (CTS) Execcution and Test report analysis.\n\n·  Development of new python scripts using ACS Framework.\n\n· System testing of DUTs using multiple Android builds.\n\n· Reporting issues in Jira tool and verification of issues after bug fix.\n\nEnvironment: Windows 7, Python 2.7\n\nProject Details (Cybercom Datamatics Information Solutions Private Limited)\nSTS Validation\nClient: ST Ericsson, Bangalore\nRole: Consultant\nST Ericsson is a manufacturer of wireless products and semiconductors, supplying to mobile device manufacturers  ST Ericsson was a 50/50 joint venture of Ericsson and ST Microelectronics. Performing the Modem testing and system testing of ST Ericsson Platforms (U8500, L9540 & L8540)  based on the requirement of Internal Customer Acceptance team. Complete analysis of message flows between device and network in different scenarios of Circuit switched and Packet switched sessions in 3G and 2G networks. Modem level log analysis. Understanding of Layer 2 and Layer 3 protocols message flows. Tested the applications like Telephony and Bluetooth.  Performing testing using ATF (Automation Test Frame Work) which runs on Python scripts. Created new test cases in Telephony area using Python scripting language. Performing Feature interaction tests like BT-Wlan, During streaming and During data connection by using ATF.\n\nResponsibilities:\n· System testing of DUTs using multiple Android builds.\n\n· Reporting issues in FIDO tool and verification of issues after bug fix.\n\n· Development of new python scripts using ATF Framework.\n\n· Complete log analysis of CS and PS sessions in WCDMA.\n· Reporting crashes, freezes and application force closes with relevant log files.\n· Fixing Python script errors.\n\nEnvironment: Windows 2007, Python 2.7\nProject Details (Sasken Communication Technologies Limited)\nSony Ericsson Mobile Communication (SEMC)\nClient: Sony Ericsson, sweden\nRole: Software Engineer\nSony Ericsson is a telecommunications company headquarters in Sweden and it is a joint venture of Sony and Ericsson. It is mobile handset manufacturer of different mobile platforms like Android, Symbian and Windows. Performing the functional and system testing of handsets based on the requirement of Internal Customer Acceptance team. For non-functional testing like stress and performance testing we used BRAT automation tool.\nResponsibilities:\n· System testing of mobile handsets on Android and Symbian platforms.  \n\n· Reporting issues in CleraQuest tool and verification of issues after bug fix.\n· Writing new test cases as per client requirements using Quality center tool.\n· Good experience in creation of Test scenarios \n\n· Good experience with development and Execution of Test Cases\n· Executing Smoke and Regression Testing \n\n· Execution Report and daily Report sheet preparation\n· Attending daily stand-up meetings.\nEnvironment: Windows 2007","annotation":[{"label":["Skills"],"points":[{"start":5558,"end":5563,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5508,"end":5513,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5015,"end":5020,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4952,"end":4957,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4081,"end":4086,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3117,"end":3119,"text":"PHP"}]},{"label":["Skills"],"points":[{"start":3113,"end":3115,"text":"VBA"}]},{"label":["Skills"],"points":[{"start":3108,"end":3110,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":3102,"end":3105,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":3079,"end":3088,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":3040,"end":3045,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3003,"end":3008,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2878,"end":2887,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":2801,"end":2803,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":2780,"end":2789,"text":" AngularJS"}]},{"label":["Skills"],"points":[{"start":2769,"end":2778,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":2652,"end":2654,"text":"VBA"}]},{"label":["Skills"],"points":[{"start":2576,"end":2581,"text":"Python"}]},{"label":["Education"],"points":[{"start":1742,"end":1745,"text":"M.Sc"}]},{"label":["Skills"],"points":[{"start":788,"end":790,"text":"VBA"}]},{"label":["Skills"],"points":[{"start":278,"end":280,"text":"VBA"}]},{"label":["Skills"],"points":[{"start":270,"end":272,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":261,"end":264,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":249,"end":258,"text":" AngularJS"}]},{"label":["Skills"],"points":[{"start":238,"end":247,"text":"Javascript"}]},{"label":["Skills"],"points":[{"start":205,"end":210,"text":"Python"}]},{"label":["Skills"],"points":[{"start":166,"end":197,"text":"Automation Framework Development"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"t seshasai"}]}],"extras":null,"metadata":{"first_done_at":1532688112000,"last_updated_at":1532688112000,"sec_taken":160,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SUBHASISH CHATTERJEE\nMobile: 9850482354(Pune) ~ E-Mail: chatterjee.subhasish@gmail.com\n\n Deep Learning Developer\n Deep Learning for speech recognition and computer vision\n Machine learning applications.  \n Decision Science\n Information Security data scientist\n\n Highest  Degree:  Master  of  Science (Computer  Application),  Symbiosis  Institute  of    Computer \nStudies and Research, Specialising in System Administration.\nTotal Experience: 8 years.\nExperience relating to Bigdata/Data Science/Machine Learning: 3 years (current experience)\nExperience relating to Information Security/admin, Programmer: 5 years (past)\n\nObjective: Perfecting skills in the various fields of Artificial intelligence, including but not limited to \nthe  area  of  Natural  Language  Processing,  Predictive  Modelling,  Recommendation  Engines,  Deep \nLearning and Neural networks, Statistical Mathematics and Computational Neurocience.  \n\nCurrent Experience:\n\n Machine learning techniques, Natural Language Processing.\n\n Computational Neuroscience\n\n Deep learning: RNN based neural network, speech recognition.\n\n Deep learning: Convolutional neural network, computer vision.\nPast experience:\n\n Administrating and architecting defensive and offensive security.\n\n Hadoop based big data, data science techniques.\n\n Hands-on experience in providing solutions, implementation, configuration, troubleshooting \n& fine-tuning of Firewalls, IDS/IPS, Network Security Monitoring.\n\n Software Defined Networking and Machine Learning.\n\n Configuring  Availability  monitoring  with Open source tools  like  Nagios,  Security  Onion, \nOpenflow, Openstack.\n\n Ethical hacking.\n\nSkill Sets utilised at work \n\nMANAGERIAL & FUNCTIONAL\n Tech Lead a small team of infosec infrastructure management\n  Machine Learning Systems with Python/R\n NLP with Deep Learning \n Working on various machine learning algorithms.\n Creating Network Security monitoring, IDS infrastucture with Security Onion.\n\n\n\n Involved  on  SDN and  Openstack  Network  with  hadoop  and  Mapreduce.  Using  mininet \nimplementation.\n\n Understanding  open source  projects  like  Security  Onion,  Openstack  Network  neutron, \nApache Mahout and Cloudera\n\n Architecting customized solutions for Firewall with Cisco ASA and Iptables.\n Hadoop based Big Data implementation\n Creating Vulnerability Analysis and Penetration Testing plans with Backtrack.\n\nTECHNICAL\n\n Data Science, BigData and Machine learning:\n Deep Learning using Python Theano\n Natural Language Processing.\n NLTK\n Mapreduce and NoSQL\n Installing apache hadoop single and multi node.\n Predictive Modeling and Anomaly detection\n Machine learning feasibility\n Machine Learning system with Python.\n Linear model, non-linear transformation, training data, neural network, support vector \n\nmachines, Deep learning concepts.\n Python and R\n Learning algorithm\n Data mining methodology.\n\n Defensive Security (Firewalls, IDS / IPS, System Security)\n Installation,  Configuration  and  implementation  of  snort,  barnyard2,  snorby  and  Security \n\nOnion.\n Linux iptables, Cisco ASA\n Offensive Security (Vulnerability  Analysis  and Penetration Testing),  Network penetration \n\ntesting with backtrack.\no Footprinting and Enumeration Active-, NMAP, xprobe2, Passive- P0f.\no Exploit Testing – Metasploit.\n Linux System Administration.\n\no Cloud and Virtualisation and Software Defined Networking, Openstack networking\n Installation of openstack in ubuntu\n Implementation of openstack network neutron.\n\n     \n Automation, programming and scripting:\n• Python\n• R programming\n• Tcl/Tk, Shell script\n\nEducational Credentials\n\n\n\n M.Sc.  in Computer Applications specializing in System Administration from  Symbiosis \nInstitute of Computer Studies and Research, Symbiosis International University, Pune in \n2010. Secured GPA 2.375 out of 4.\nDuration of Masters : 2008-2010\n\nHighlights -\n• Handling multiple International Open Source events\n• Practical Lab experience on System Administration, Network Admin/Security.\n\n Bachelor in Computer Application from Techno India, West Bengal University of Technology, \nKolkata in 2007. Secured 73.6%\n\nEmployment History\n\n   \nGenpact Headstrong Capital Market (Current) as Principal Consultant from 31 August 2016\n\nAccountabilities\n Machine Learning/ Speech recognition using neural networks\n NLP and NLG\n\n Worked on a research project using Deep learning for predictive medical care,  bioinformatics \nwith ISI - kolkata\n                 \nTechniques\n      Deep Learning, Python Theano, Natural language processing, bioinformatics.\n  \n\nMastercard (Teksystem) from March 2015 to March 2016 as Lead Analyst\n\nAccountabilities\n Text mining, NLP.\n Machine Learning Techniques, neural networks\n Responsible for Information Security Technical Services for Mastercard network.\n Hardware Security Module\n nCipher for encryptions on Mastercard applications.\n\nHighlights\n one of the four recipients out of whole mastercard for project coin award on march 2nd 2016\n A finishing a flagship and extremely critical project for mastercard regarding HSM\n\nTranscomm sister concern of Flightcase IT services (Under Birdwell Companies), Pune: from \nJanuary’13 to March 2015( till the closing of transcomm business unit)\n\n \nAccountabilities\n\n Responsible for Network / System Security Architecture, system admin of the small/medium \nscale network\n\n Machine Learning application using Python.\n Setting up Bigdata framework using Hadoop.\n\n\n\n Active directory and LDAP domain administration\n Cisco ASA, iptables, security testing implementation.\n\nAdministrating centOS, windows server 2008 based production server\n\n Creating IDS/IPS and Network Security infrastructure.\n Cloud computing and bigdata.\n Automation of tasks with Tcl Tk Expect, Shell script, Perl, Python.\n\n Highlights\n  Completed in Architecting the Network Security Monitoring and IDS/IPS system for the \n\norganisation.\n Configuring security and virtualisation needs for data center.\n Completed and Implemented Automation process for their system with shell and expect.\n Apache Cloudstack project.\n Back up system with bacula, web bacula and my backup pc.\n\n----------------------------------------------------------------------------------------------------------------\nSungard, Pune:  May’11 to January’13 as Information Security Engineer\n\nAccountabilities\n Responsible for Network / System Security Architecture,\n Understanding requirement of a client.\n Preparing Unified Security Architecture Blueprint.       \n Spearheading the operations for Sungard Global Trading (GL Trade previously) and BRASS \n\nto support full lifecycle trading.\n Performing  processing  activities  including  information  services,  market  connectivity  and \n\norder management to help improving trade efficiency and risk monitoring.\n\nHighlights\n Honoured with Kudos Award in just 3 months of joining for handling a critical issue; also \n\nnominated for Spot Award.  \n Distinguished for completing project requirements which led to client renewal of contract and \n\nappreciation from Senior Management.  \n Major  Projects  Handled:  Created  Unified  Security  Architecture  for  client  starting  from \n\nRequest for Proposal to cost assessment to proposing security architecture for their business  \nneeds.\n\n Recognized with the numerous appreciation letters.\n\nSecurView Systems, Pune: Jan’10 – Apr’11 as Security Engineer\n\nAccountabilities            \n Monitored Security Operations Centre for multiple client needs.\n Handled and troubleshoot firewalls and IDS/IPS.    \n Vulnerability Assessment/ Penetration Testing, Incident handling\n Involved in incident handling in real life security scenario and documented attack signatures \n\nfor CISCO.\n\nHighlights\n Accredited for various detection of vulnerability and involved in Incident handling; rendered \n\nvulnerability mitigation suggestions to clients.\n\n\n\n Configured Client Firewall, Cisco ASA, VPN Concentrator in the Nagios under Availability \nServices.\n\nCommenced Career: National Informatics Centre, Kolkata, West Bengal: Aug’07 – Apr’08 as \nSoftware Developer\n\nAccolades\n\n Enthusiastically took part in Debate, Quizzing like D.I. and J.U. quiz circuit.\n Functioned as:\n Active Member of Science Club of Techno India and Media Club.\n Founding Member of College Magazine Graffiti.\n Holds the distinction of being a member of GNUNIFY 2009 (technical festival and seminar of \n\nSICSR).","annotation":[{"label":["Skills"],"points":[{"start":571,"end":608,"text":"Information Security/admin, Programmer"}]},{"label":["Skills"],"points":[{"start":480,"end":516,"text":"Bigdata/Data Science/Machine Learning"}]},{"label":["Education"],"points":[{"start":285,"end":327,"text":"Master  of  Science (Computer  Application)"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"SUBHASISH CHATTERJEE"}]}],"extras":null,"metadata":{"first_done_at":1532675055000,"last_updated_at":1532675055000,"sec_taken":86,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "T Riyaz Ahammad\n\n\n\n\n                      Mobile: +91-8553391089 \n\nJr Data Analyst\n\n\n\n\n\n                    Email:riyazahammad.ds@gmail.com         \n\nEXPERIENCE SUMMARY:-\n\n· Around 7.3 years of rich experience in IT, both SDLC & STLC.\n\n· Have very good experience in Expertise in building statistical models in Fraud Management Analysis and Supply-Management Risk Analysis.\n· Strong expertise in analytical and quantitative techniques including predictive modelling, Response modelling, multivariate analysis, Decision Trees, Targeting and Segmentation Analytics.\n· Proficient at leading teams for running successful process operations \n\n· Managing the project stakeholders with Preparation and Maintenance of Project Plans and schedule.\n\n· Established and maintained relationships with third parties/vendors\n\n· Adept in end-to-end development of products from requirement analysis, system study, designing, coding, testing, de-bugging, documentation, implementation and maintenance.  \n\n\n· Extensive knowledge on Planning and People, Stakeholders Managements Process Improvement, Implementation.\n\n· Significant exposure in Application Development, Maintenance & Support, Business Intelligence & Product Engineering across Multiple Technologies\n\n· Adroit in analysing, design, developing, testing and implementing varied software applications\n\nBusiness Analytics experience:-\n\n· Maintained a deep understanding of business and the marketplace dynamics to bring about continuous improvements\n\n· Building and optimizing classifiers using machine learning techniques\n\n· Understand the problem in-depth, map it using a structured approach and identify the appropriate analytical model to solve the problem\n\n· Selecting features, building and optimizing classifiers using machine learning techniques\n\n· Processing, cleansing, and verifying the integrity of data used for analysis\n\n· Doing ad-hoc analysis and presenting results in a clear manner\n\n· Provide expertise on statistical / mathematical concepts for identified problems and provide appropriate models to solve them.\n\n· Test various machine learning and analytical tools, build prototypes which can be easily scaled up for production deployments\n\nAgile experience:-\n\n· Work on all stages of a product from conception to completion. Drive the team (6+) to build not just a good but a great product.\n\n· Create and manage testing plans. Collect and analyze multiple metrics around testing. \n\n· Provide inputs to Development on software design and on ways to increase product testability to support more extensive test automation.\n· Find and apply industry standard testing methodologies and technologies and evangelize innovative use of technology.\n\n· As Scrum Master: Organize and facilitate daily stand-ups, release planning, sprint planning, sprint reviews, product demos and retrospectives. Creates and maintains Scrum artefacts. \n\n· Build relationship with Product owner/stake holders and facilitate team's interaction with them (e.g., coaching Product Owners in creation and maintenance of Product Backlog).\nCertifications:-\n\n· DATA ANALYTICS Internal course from TCS\n\n\n\n\n2016\n· INS 21 certification\n\n\n\n\n\n\n\n2015\n· LOT-801 - IBM Lotus Notes Domino 8 Application Development Update\n2011\nSkill Sets – Software proficiency:-\n\n· Analytical Methods       \n:   Regression, ANOVA, Hypothesis Testing, Experimental Design,\n\n                                             \n    Time Series Analysis, Confidence intervals\n\n· Data Analytics Tool         \n:   R Scripting language, XL Miner tool for data mining                    \n\n·  Data Mining Techniques :  Market Basket Analysis, Cluster Analysis, Principal component          analysis, Classification using SVM, Decision Tree\n·  Tools/Scripting Language  :   R-Studio, Hadoop, Hive, Pig, Scoop, Lotus Notes C, Java, JavaScript, Lotus Script, R-programming\n· Change Management    \n:   Service-Now\n\nCORE COMPETENCIES:-\n\nROLES & Responsibilities:-\n\nAs Data Analyst\n\n· Used R to understand data patterns and proposed machine learning based solutions for Fraud Management Analysis and Supply-Management Risk Analysis.\n\n· Managing offshore customer visits and managing client relationships for India Incubating and evangelizing data science service.\n· Analysing business problems and identifying key solution interventions leveraging advanced analytics methods.\n· Experienced in Statistical Learning: - Predictive & Prescriptive Analytics, Web Analytics, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Neural Networks, Deep Learning Algorithms\n\n· Experienced in Machine Learning, supervised and unsupervised: - Forecasting, Classification\n\n· Parametric and Non-parametric models, Regression, Time Series, Dynamic/Causal Model\n\n· Awareness in big data analytics and advanced data mining techniques to analyse data, identifying trends, patterns, and outliers in data.\n· Experienced with statistical programming languages, analytical packages/libraries (R, Python)\n\n· Tracking of the new requirements from the project and forecast/estimate the project future requirements.\n\n· Ability to adapt to a dynamic, rapidly changing business and technical environment is required.\n\n· Vendor management skills - Relationship management and co-ordination for deliverables; ability to Consult with and provide leadership to outsourced partners.\nAs Agile Scrum Master\n· Analysed the requirements and design documents along with Product owner and the scrum master\n\n· Attended the Business/System Requirements Review Meeting, and provide feedback from the testing teams perspective.\n\n· Answerable for removing the impediments of the Scrum team members and protecting them from outside interference \n\n· Facilitating Scrum ceremonies like Sprint Planning, Sprint Review and Sprint Retrospective and Daily Scrum Meetings\n\nProjects:-\n\nPROJECT: 1\nClient              :   Allianz Global Corporate & Speciality\nProject            :   Fraud Detection in Insurance Claims\nEnvironment :   Analytics Model using R, Regression and Time Series Analysis, Neural   \n\n                            Networks, Hive, Sqoop\n\nRole                 :   Jr Data Analyst\n\nDuration         :   Oct 16 – Jan 18.\n\nTeam Size       :    5\nAbstract          :  Identifying claim fraud using predictive analytics, however, represents a unique challenge. Most predictive analytics applications have a complete target variable which can be analyzed. Fraud is unique in that there is generally a lot of fraud that has occurred historically that has not been identified.  There is a natural assumption that the past will bear some resemblance to the future. In the case of fraud, methods of defrauding insurance companies change quickly and it can make the analysis of a historical database less valuable for identifying future fraud.  Identify fraud and allow an insurer to optimize the resources they have available in combating this fraud. \n\n More consistent referral of suspicious claims to claim investigative units , Better identification of suspicious claims, even as techniques used to defraud insurers are changing and  Incorporating claim adjuster insight into analytics results to improve the process.\n\nPROJECT: 2\n\tClient Name\n\tAVIVA\n\n\tProject Title\n\tAVIVA – Application Maintenance Onsite SPoC\n\n\tPeriod\n\n\tJan 2013 to May 2016\n\n\tPosition\n\n\tOnsite Lead\n\n\tResponsibilities\n\t· Playing the role of a Team Lead, Issue tracking & Status Reporting\n\n· Leading a team of 4, coordinating and supporting them on their activities, and also involved in Enhancement/ Change Requests.\n\n· Extensive client interaction as part of the activities.\n\n· Experience in understanding client business requirements and preparation of use cases for the same.\n\n\tProject\n\t· AVIA is Specialty Insurers are one of the world's leading specialty Insurance Company. Their Corporate IT department has different types of IT systems like policy administration, underwriting, accounts, etc.. IT department will be enhancing many Legacy systems and consolidating systems to obtain optimal efficiency and to reduce the complexity and risk” \n\n\n\n\tLanguages\n\tJava, Lotus Notes, MS Dynamics, AS400\n\n\tDatabase\n\tOracle and SQL Server\n\n\tSpecial Software\n\tNA\n\n\tProject Location\n\tTCS Bangalore\n\n\nPROJECT: 3\n\tClient Name\n\tPWC(PriceWaterHouseCoopers)\n\n\tProject Title\n\tPWC – Application Maintenance \n\n\tPeriod\n\n\tOct 2010 to Dec 2012\n\n\tPosition\n\n\tTeam Member\n\n\tResponsibilities\n\t· Playing the role of a Team member, Issue tracking & Status Reporting\n\n· Supporting applications and also involved in Enhancement/ Change Requests.\n\n· Extensive client interaction as part of the activities.\n\n· Experience in understanding client business requirements and preparation of use cases for the same.\n\n\tLanguages\n\tJava, Lotus Notes, MS Dynamics, AS400\n\n\tDatabase\n\tOracle and SQL Server\n\n\tSpecial Software\n\tNA\n\n\tProject Location\n\tTCS Bangalore\n\n\nTeaching Experience:\n\nJune 2006 to September 2010 worked as a Mathametics lecture in SV Degree College, Anantapur.\nEducation:-\n\n\tQualification\n\tYEAR\n\tUniversity / \nBoard\n\tPercentage\n\n\tBsc(Mathametics, Physics and Computer science)\n\t2003-2006\n\tS.V. Degree College, Sk univercity, Anantapur\n\t65.56\n\n\tINTERMEDIATE\n\t2001-2003\n\tBoard of Intermediate, Andhra Pradesh\n\t56%\n\n\tS.S.C EXAMINATION\n\t2000-2001\n\tS.S.C\n\t84.5%\n\n\nPersonal Details:-\n\nNAME \n\n\n\n: T RIYAZ AHAMMAD\nEMAIL \n\n\n\n: riyazahammad.ds@gmail.com\nDOB\n\n\n\n:  12th  JUL 1986\n\nGENDER \n\n\n:  MALE\n\nCONTACT\n \n\n: +91 8553391089\nPRESENT ADDRESS\n\n:  Door No 49, 3rd block, 5th main, Ayyappa Nagar, Kr puram,\n                                    \n\n   Bangalore,\n\n                                     \n\n   Karnataka -560036\nDECLARATION:\n\nI hereby declare that all the above furnished details are true to the best of my knowledge.\n\nPlace: Bangalore\n\n\n\n\n\n\n\nRiyaz Ahammad T\nMapping Strategic Business needs into Technical Solutions\n\nLeading POCs/Prototyping Solutions\n\nRapid Solution Development using Agile Methodologies\n\nExcellent Communication & Cross Functional Collaboration Skills\n\n\n\n\n\n6","annotation":[{"label":["Location"],"points":[{"start":9739,"end":9747,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":9553,"end":9561,"text":"Bangalore"}]},{"label":["Education"],"points":[{"start":9047,"end":9049,"text":"Bsc"}]},{"label":["Location"],"points":[{"start":8851,"end":8859,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":8764,"end":8768,"text":"AS400"}]},{"label":["Skills"],"points":[{"start":8750,"end":8761,"text":" MS Dynamics"}]},{"label":["Skills"],"points":[{"start":8738,"end":8748,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":8732,"end":8735,"text":"Java"}]},{"label":["Location"],"points":[{"start":8218,"end":8226,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":8131,"end":8135,"text":"AS400"}]},{"label":["Skills"],"points":[{"start":8117,"end":8128,"text":" MS Dynamics"}]},{"label":["Skills"],"points":[{"start":8105,"end":8115,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":8099,"end":8102,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3813,"end":3816,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3807,"end":3810,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3792,"end":3802,"text":"Lotus Notes"}]},{"label":["Skills"],"points":[{"start":3576,"end":3597,"text":"Data Mining Techniques"}]},{"label":["Skills"],"points":[{"start":3522,"end":3529,"text":"XL Miner"}]},{"label":["Skills"],"points":[{"start":3500,"end":3519,"text":"R Scripting language"}]},{"label":["Skills"],"points":[{"start":3184,"end":3194,"text":"Lotus Notes"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"T Riyaz Ahammad"}]}],"extras":null,"metadata":{"first_done_at":1532692460000,"last_updated_at":1532692460000,"sec_taken":121,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Shobharani Thabjeela\ndata ANALYST\nR / Python / Base SAS / SQL / Tableau / Hive / MS Excel\n\tFlat No: 302,3rd Floor, Vivkes Aroma Apartments, Panathur Main Road, Kadubeesanahalli, Bangalore-560103, \nPhone: +91-9483033887\nEmail ID:shobharani.dnd@gmail.com\n\n\tData Scientist (Wipro Technologies Ltd):\n· Analytics professional with 2 years of experience in Data Analytics domain and 3 years of experience in Mainframes domain.\n· A team player having in-depth understanding and experience in Data Analytics and Reporting.\n· Focal point of making sound decisions related to Data collection and Data Analysis.\n· Maintained the data integrity during the extraction, manipulation, processing and storage.\n· Made data chart presentations and coded variables from original data, conducted statistical analysis whenever required and provided summaries of analysis.\nKey Projects:\nRetail Store Data Analysis:\n· Generating Reports for analysis – Creating Transaction Table, Customer Table and Product Table in SAS using the data. Generating reports by Arranging the customers as per most Loyal customers.\n· Divide them in 3 equal categories according to the total number of customers to provide them with different promotional offers.\n· Finding the Maximum sale of the week and generating monthly sale report.\n\nKey Skills:  Base SAS\nCredit Risk Analysis:\n· While receiving application of a borrower, the bank asks certain details about the applicant for checking eligibility criteria.\n· Company wants to automate the loan eligibility process based on customer detail provided while filling online application form. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers.\n· To identify the loss estimation given that the customers is a defaulter, those are eligible for loan amount so that they get to know what features are leading to defaults up to which amount. \n\nKey Skills: Python, Linear regression, Logistic Regression, SVM\n\nPricing Analysis for Airlines:\n\n\n· To identify how many people will be accommodated in the flights, what was the highest number of people with the lowest amount of revenue.\n· Identifying the highest revenue generation year and quarter.\n\nKey Skills: Hive, Linear Regression {Machine Learning Algorithms}, R\n\nMainframe Developer (IBM India Pvt Ltd):\nProject Details:\nExpress Scripts Inc(2011 Nov to May 2013)\n\n· ESI is a pharmacy benefit management company (PBM) and managed care organization (MCO) that focuses specifically on the cost-effective and appropriate delivery of prescription medications in a unique way of dispensing medicines to the members at their doorstep. \n· A pharmaceutical benefit manager (PBM) is an organization that delivers monitors and manages prescription drug benefits for a benefit sponsor (or client). \n· ESI unique approach to creating and managing integrated pharmacy networks lowers costs, while delivering quality care and high member satisfaction. \n· ESI Health Solutions services—including network options that integrate retail pharmacies, mail order pharmacies for maintenance medications by mail, and specialty pharmacies for biotech inject able—enable us to leverage our buying power to offer you superior cost management and flexibility while providing your members high quality choices to meet their need.\nKey Skills: COBOL, JCL, CICS, DB2.\nTools: Endeavor, File-AID, Expeditor, Spufi.\n\tProfessional Experience\n· Wipro Technologies Ltd.,\nData Analyst (March 2016 – Till Date)\n· IBM India Pvt.Ltd., \nMainframe Developer\n(Nov2010 – May 2013)\nKey Skills\n· R Programing\n· Python\n· SQL\n· SAS\n· MS Excel\n· Tableau\n· Spark\n· Hive\n· Cobol\n· DB2\n\nTechniques\n· Linear Regression\n· Logistic Regression \n· Support Vector Machine\n· Decision Tree\n· Random Forest\nEducation\n· B.E in Computer Science Engineering from Anna University - May 2009.\n· Intermediate (10+2) from Board of Intermediate Education, A.P - June 2005.\n· SSC (10th) from Board of Secondary Education, A.P May 2003.\n\n· DOB -28/08/1988\n\n\n\nAdditional Skills\n· Proficiency in Microsoft office suite (Excel, Word, Power point) \n· Excellent Presentation Skills\n· Good Team Player\n\n\n\nPersonal Details\n· Married. \n· Languages: English, Hindi, Telugu, Tamil & Kannada\n\n\n\nShobharani Thabjeela\tshobharani.dnd@gmail.com\t+91 9483033887\n1 | Page\n\nShobharani Thabjeela\tshobharani.dnd@gmail.com\t+91 9483033887\n2 | Page","annotation":[{"label":["Name"],"points":[{"start":4361,"end":4380,"text":"Shobharani Thabjeela"}]},{"label":["Name"],"points":[{"start":4290,"end":4309,"text":"Shobharani Thabjeela"}]},{"label":["Education"],"points":[{"start":3835,"end":3837,"text":"B.E"}]},{"label":["Skills"],"points":[{"start":3692,"end":3695,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":3684,"end":3688,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":3674,"end":3680,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":3663,"end":3670,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":3657,"end":3659,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3651,"end":3653,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3642,"end":3647,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3573,"end":3591,"text":"Mainframe Developer"}]},{"label":["Skills"],"points":[{"start":2342,"end":2360,"text":"Mainframe Developer"}]},{"label":["Skills"],"points":[{"start":2284,"end":2287,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":1982,"end":1987,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1312,"end":1314,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1307,"end":1314,"text":"Base SAS"}]},{"label":["Skills"],"points":[{"start":993,"end":995,"text":"SAS"}]},{"label":["Location"],"points":[{"start":178,"end":186,"text":"Bangalore"}]},{"label":["Skills"],"points":[{"start":81,"end":88,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":74,"end":77,"text":"Hive"}]},{"label":["Skills"],"points":[{"start":64,"end":70,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":58,"end":60,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":52,"end":54,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":47,"end":54,"text":"Base SAS"}]},{"label":["Skills"],"points":[{"start":38,"end":43,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"Shobharani Thabjeela"}]}],"extras":null,"metadata":{"first_done_at":1532669132000,"last_updated_at":1532669132000,"sec_taken":146,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Utkarsh Utsava \n Senior Systems Engineer | Infosys Ltd  \n\n11th Cross, Bellandur, Bangalore | +917411226238 | utkarsh0208@outlook.com |Kaggle : Utkarsh |GitHub : Utkarsh \n\nObjective \n\n· Looking for an opportunity in the field of Machine Learning where I can utilize the platform to showcase my skills and \nknowledge in turn contributing in the success of the organization. \n\nExperience \n\nSENIOR SYSTEMS ENGINEER | INFOSYS LTD | JUNE 2014 – PRESENT  \n\n· Healthcare Visualization Model: Excel & Tableau -> Developed a visualization model to provide insights about the \nconsumption of drugs based on factors like age, gender, geo location etc. \n\n· HR Model: Python, Logistics Regression, Random Forest, Support Vector Machine -> Developed a python based model to \n\npredict if employee will leave the organization based on factors like previous rating, promotion, department etc. \n\n· Product Fitment Score: R, NLP & Regression -> Developed R based model to process the textual product description, \ntitle to predict the fitment score. The project was focused to optimize the product result based on search query. \n\n· Advertisement Analytics: Python, Random Forest, Support Vector Machine, Ensemble, Artificial Neural Network -> \nDeveloped a model to predict if the consumer is going to click on the Advertisement based on feature sets. \n\nSkills & Abilities \n\nPROGRAMMING  \n\n· Python & R \n\n· PowerShell  \n\n· SQL \n\nALGORITHMS \n\n· Linear Regression, Logistic Regression Decision Tree, Support Vector Machines, Text Analytics, Artificial Neural \n\nNetwork \n\n· Ensemble Methods: Random Forest, AdaBoost, Gradient Boosting \n\n· Web Scrapping \n\nPLATFORM \n\n· Windows(XP/7/8/10), Windows Server (2008/2012), Linux, MS SQL, MS Office Suite \n\n· R Studio, Jupyter, Azure ML Studio \n\nLEADERSHIP \n\n· Lead Offshore Team for more than year reporting to onsite client’s manager. \n\n· Participating in onsite-offshore calls as required, Issue tracking, effort/activity tracking across systems. \n\n· Experience of leading team, prepared weekly Work Order report, ensured documentation, and incidents of the team, \nescalation reports and optimization, quality assurance and SLA compliance. \n\n \n\n \n\nmailto:utkarsh0208@outlook.com\nhttps://www.kaggle.com/utkarsh0208\nhttps://github.com/utkarsh0208\n\n\n \n\nEducation \n\nBACHELOR OF ENGINEERING | JUNE 2014 | PES INSTITUTE OF TECHNOLOGY | BANGALORE \n\n· Major: Electrical & Electronics Engineering \n\n· Grade: 9.14 \n\nAISSCE | MAY 2010 | SARASWATI VIDYA MANDIR |BETTIAH, BIHAR \n\n· Major: Physics, Chemistry & Mathematics \n\n· Grade: 87.6% \n\nAISSE | MAY 2007 | SARASWATI VIDYA MANDIR | BETTIAH, BIHAR \n\n· Grade: 80 % \n\n \n\nAchievements  \n\n· Rated Outstanding Employee for the current annual cycle. \n\n· Numerous token of appreciation as monthly awards for all round performance. \n\n· Special Award for leading team in the absence of onsite lead for two months. \n\n· AIR 487 GATE 2014 (EEE) \n\n· Branch Topper (Top 10 of the graduating class) \n\n· District Topper in +2 \n\nCourse & Certificate \n\n· Infosys Certified Big Data R Programmer  \n\n· Python for Data Science and Machine Learning Boot camp \n\n· Data Visualization using Tableau \n\nPersonal Details \n\n· DOB  02nd Aug, 1992  \n\n· Nationality Indian \n\n· Language English & Hindi \n\n· Hobbies Teaching, Listening Songs, Content Writing","annotation":[{"label":["Skills"],"points":[{"start":3126,"end":3132,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":3042,"end":3047,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3024,"end":3024,"text":"R"}]},{"label":["Skills"],"points":[{"start":2871,"end":2871,"text":"R"}]},{"label":["Skills"],"points":[{"start":2647,"end":2647,"text":"R"}]},{"label":["Skills"],"points":[{"start":2606,"end":2606,"text":"R"}]},{"label":["Skills"],"points":[{"start":2589,"end":2589,"text":"R"}]},{"label":["Skills"],"points":[{"start":2570,"end":2570,"text":"R"}]},{"label":["Skills"],"points":[{"start":2484,"end":2484,"text":"R"}]},{"label":["Skills"],"points":[{"start":2468,"end":2468,"text":"R"}]},{"label":["Skills"],"points":[{"start":2449,"end":2449,"text":"R"}]},{"label":["Education"],"points":[{"start":2372,"end":2407,"text":"Electrical & Electronics Engineering"}]},{"label":["Skills"],"points":[{"start":2358,"end":2358,"text":"R"}]},{"label":["Skills"],"points":[{"start":2302,"end":2302,"text":"R"}]},{"label":["Skills"],"points":[{"start":2290,"end":2290,"text":"R"}]},{"label":["Skills"],"points":[{"start":1769,"end":1769,"text":"R"}]},{"label":["Skills"],"points":[{"start":1727,"end":1727,"text":"R"}]},{"label":["Skills"],"points":[{"start":1637,"end":1637,"text":"R"}]},{"label":["Skills"],"points":[{"start":1568,"end":1568,"text":"R"}]},{"label":["Skills"],"points":[{"start":1451,"end":1451,"text":"R"}]},{"label":["Skills"],"points":[{"start":1430,"end":1430,"text":"R"}]},{"label":["Skills"],"points":[{"start":1412,"end":1412,"text":"R"}]},{"label":["Skills"],"points":[{"start":1380,"end":1380,"text":"R"}]},{"label":["Skills"],"points":[{"start":1371,"end":1376,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1358,"end":1358,"text":"R"}]},{"label":["Skills"],"points":[{"start":1355,"end":1355,"text":"R"}]},{"label":["Skills"],"points":[{"start":1145,"end":1145,"text":"R"}]},{"label":["Skills"],"points":[{"start":1137,"end":1142,"text":"Python"}]},{"label":["Skills"],"points":[{"start":935,"end":935,"text":"R"}]},{"label":["Skills"],"points":[{"start":911,"end":911,"text":"R"}]},{"label":["Skills"],"points":[{"start":902,"end":902,"text":"R"}]},{"label":["Skills"],"points":[{"start":684,"end":684,"text":"R"}]},{"label":["Skills"],"points":[{"start":672,"end":672,"text":"R"}]},{"label":["Skills"],"points":[{"start":654,"end":659,"text":"Python"}]},{"label":["Skills"],"points":[{"start":645,"end":645,"text":"R"}]},{"label":["Skills"],"points":[{"start":492,"end":498,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":484,"end":488,"text":"Excel"}]},{"label":["Skills"],"points":[{"start":440,"end":440,"text":"R"}]},{"label":["Skills"],"points":[{"start":409,"end":409,"text":"R"}]},{"label":["Skills"],"points":[{"start":392,"end":392,"text":"R"}]},{"label":["Location"],"points":[{"start":81,"end":89,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Utkarsh Utsava"}]}],"extras":null,"metadata":{"first_done_at":1532668687000,"last_updated_at":1532668687000,"sec_taken":130,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Vamshidhar                                                                                                                                                                                                 \nHyderabad \n\nvamshitopi3.14@gmail.com | https://github.com/Vamshi-dhar                 +91-8886033089 \n\n \nDATA SCIENTIST PROFESSIONAL   \n\n \n\nAn insatiable intellectual curiosity and ability to mine hidden gems located within \n\nlarge datasets using applied statistics and visualization through healthy sense of \n\nexploration. \n\n \nPROFESSIONAL SUMMARY \n\n Strong problem solving and abstract thinking skills. \n Passion to learn new technologies, techniques and apply in practical business \n\nproblems to stay ahead of the Analytics industry curve.  \n Liaising with the clients to understand their requirements, challenges etc. and \n\nkeeping them up to date on the progress of our proposed solution. \n Ability to be flexible and change with the environment, industry and business \n\ndemands. \n Proficiency in end to end coding statistical programming language R, and a database \n\nquerying language SQL. \n Experienced in mathematical modeling and programming, statistical analysis, \n\nforecasting/predictive modeling, visualizations, machine learning, data mining, etc. \n Process & clean raw data structures to create data suitable to be used in a statistical \n\nanalysis.  \n\n \nWORK EXPERIENCE \n\n \n\nWorking as Data Analyst for CLINSTAT SOFTWARE TECHNOLOGIES PRIVATE \nLIMITED, Hyderabad - 500072 Telangana, India from Sep 2014 to till date. \n\n \nTECHNICAL SKILLS \n\n \n\n Data science: general analytics, dash boarding, reporting, predictive modeling. \n Machine Learning: classification, regression, clustering, feature engineering. \n Mathematical statistics: data mining, visualization, hypothesis testing and \n\nconfidence intervals, linear regression, logistic regression, model selection, \nnonlinear regression, time series analysis, and principal component analysis \n\n Software and Programming Languages: advanced R, SQL, Microsoft PowerPoint, \nand Microsoft Excel. Basic knowledge of Tableau, Python and SAS. \n\n Operating systems: Familiar with Windows, Linux variants. \n Computer savvy. \n\n \n \n\nvamshitopi3.14@gmail.com\nhttps://github.com/Vamshi-dhar\n\n\nPROJECT PROFILE \n \nProject# 3 \n\n“Prediction of patients at risk of developing diabetes using Machine Learning Techniques”                                                                                             \n\n[Dec, 2016 to present] \n\n \n\nResponsibilities include doing literature review and come up with possible solutions, \n\nconducting research on a large database of Diabetes patients for finding temporal patterns. \n Tactical and practical approach for treating missing and outliers in the data. \n\n Extracting insights through EDA by doing statistical tests and Visualizations based \n\non type of data. \n\n Understanding various complications that take place during data preparation.  \n\n Spotting the risk factors that are more likely affecting the patients at risk of Diabetes \n\nfor providing better and cost effective treatment to patients.   \n\n Stacking of models is done to develop a robust model for classification of \n\nReadmission of diabetes patients. \n\n Performance of a model is evaluated by various performance measures: \n\nClassification accuracy, sensitivity and specificity. \n\n \nProject# 2 \n\n“Understanding and prediction of Hospital Readmission rates”                                                                                                                         \n[Feb, 2016 to Oct, 2016]   \n \nResponsibilities include conducting statistical analysis to determine key factors for \nplanning and conducting experiments to understand readmission of patients using \nprescriptive and predictive analytics. \n\n Worked closely with domain experts to understand various challenges involving at \n\nthe different levels of the project. \n\n Identifying the potential data sources based on the analytical problem statement \n\nand Generating synthetic features from health insurance claims data. \n\n Feature selection and Feature extraction regarding to both conceptual and practical \n\nconsiderations that optimize statistical efficiency and data quality. \n\n Eliminating redundant features without losing essential classificatory information. \n\n Applying Statistical knowledge to identify and develop various significant models \n\nbased on the data available through hypothesis testing. \n\n Applied appropriate machine learning algorithms like Logistic regression, Naive \n\nBayes, SVM and various Ensemble models like Random Forests to predict the \n\npatients at risk of Diabetes followed by appropriate evaluation techniques. \n\n \n\n\n\nProject# 1 \n\n“Forecasting Bed days in Hospital”     \n[Aug, 2015 to Nov, 2015] \n \n\nResponsibilities include, \n Exploration of time series to identify missing values and outliers in data. \n\n Plotting series and decomposed series in order to identify patterns such as Level, Trend, \n\nSeasonality and Cycles in the data.  \n\n Plot the Autocorrelation function [ACF] and Partial Autocorrelation function [PACF] to \n\nidentify possible models. \n\n Testing for stationarity using Adf test or KPSS test while building ARIMA models and doing \n\nnecessary transformations. \n\n Transforming the series into a stationary series (differencing / seasonal differencing / \n\ntaking log values etc.) \n\n Forecasting the finalized model along with confidence intervals.  \n\n \nCERTIFICATIONS \n \n\n\"Data Science, a 10-course specialization by Johns Hopkins University on Coursera\". Verify \n \n\nThe Data Science Specialization covers the concepts and tools for an entire data \nscience pipeline. Successful participants learn how to use the tools of the trade, think \nanalytically about complex problems, manage large data sets, deploy statistical principles, \ncreate visualizations, build and evaluate machine learning algorithms, publish reproducible \nanalyses, and develop data products.  \n\n \nEDUCATION \n\n Masters’ Degree in Pharmacy, 2014. \n \n\n \n\nhttps://www.coursera.org/account/accomplishments/specialization/certificate/BXSP6TJW259P","annotation":[{"label":["Education"],"points":[{"start":5997,"end":6023,"text":"Masters’ Degree in Pharmacy"}]},{"label":["Skills"],"points":[{"start":2353,"end":2368,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1734,"end":1756,"text":"Mathematical statistics"}]},{"label":["Skills"],"points":[{"start":1652,"end":1667,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1569,"end":1580,"text":"Data science"}]},{"label":["Location"],"points":[{"start":1477,"end":1485,"text":"Hyderabad"}]},{"label":["Location"],"points":[{"start":204,"end":212,"text":"Hyderabad"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Vamshidhar "}]}],"extras":null,"metadata":{"first_done_at":1532671763000,"last_updated_at":1532671763000,"sec_taken":63,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "A K Kamalraj\n#401, Third floor,\nNaidu Building,\nTirumala Layout,\nChannasandra,\nBangalore � 67\n\nEmail ID   \t:   a.k.kamalraj@gmail.com        \nContact No\t:  9036537065/9585439431\n                                                                                                  \t\t                                                              �\n\nCareer Objective\n\nI intend to establish myself as a Senior Software Engineer with an integrated business solution provider through a long time commitment, contributing to the company's growth and in turn ensuring personal growth within the organization. \n\nTechnical Experience  \n\n* [January 2015 � Present] as Senior Programmer Analyst, IDrive Software India Pvt. Ltd, Bangalore, Karnataka, India. \n* [September 2013 � January 2015] as Associate - Software Development, Lancesoft India Pvt. Ltd, Bangalore, Karnataka, India. \n* [July 2012 � August 2013] as Web Developer - PHP, Ixly Technologies, Coimbatore, Tamil nadu, India.\n\nAreas of interest\n\n* Database Programming \n* MVC Architectural programming\n\nTechnical proficiency\n\nDatabases\t\t\t\t:\tMySql, Sqlite3 \nServer Side Languages\t\t:\tPython, PHP\nClient Side Languages\t\t:\tAJAX, Javascript, JQuery, Html, Json\nMVC Frameworks\t\t:\tDjango, Flask, Codeigniter\nIDE\t\t\t\t:\t Geany, Dreamweaver, Php Designer\nWeb Server\t\t\t:\tApache, NGINX\nOperating systems\t\t: \tLinux (Ubuntu), Windows\nAPI\t\t\t\t: \tGoogle Api, Facebook Api, Twitter Api\nWeb services\t\t\t:\tREST Api\nThird Party Plugins\t\t:\tTCPDF, Excel reader, Excel writer, JQuery Validation plugin\n\nEducation Qualification\n\n* Bachelor of Engineering in Electronics and Communication from KIT, Coimbatore, Tamil Nadu, India passed out in July 18 2012 with 79.00%\n* Higher Secondary from R.G. Matric Higher Secondary School, Udumalpet, Tirupur, Tamil Nadu, India passed out in  May 2008 with 80.4%\n* SSLC from S.K.P Higher Secondary School, Udumalpet, Tirupur, Tamil Nadu, India passed out in  May 2006 with 83.8%\n\nProjects \n\nProject #1\n* Title\t\t\t: \tIDrive Vault\n* Framework\t\t: \tDjango\t\t\n* Operating System\t: \tLinux Ubuntu\n* Web Server\t\t:\tNGINX\n* Database\t\t:\tSqlite3\n* Languages\t\t: \tPython, JavaScript, JQuery, JSON, Ajax\n* Role\t\t\t: \tDeveloper\n* Responsibilities\t\n* Working as a team member to understand the application requirements\n* Design and develop the technical solution for the project\n* Involved in User Acceptance Testing\n\nProject Description:\n       IDrive Vault is a Hybrid backup solution for businesses, that bundles local backup and cloud backup, as an integrated package. Perform local backup using the Vault appliance for faster backups and restores, and then choose data from your Vault appliance to be backed up to the IDrive cloud, for access, in the event of a disaster. Vault Appliance has a browser based interface in which cloud application operates.\n \t \nProject #2\n* Title\t\t\t: \tIDrive � DataCenter Edition\n* Framework\t\t: \tFlask\t\t\n* Operating System\t: \tLinux Ubuntu\n* Web Server\t\t:\tApache\n* Database\t\t:\tMySQL\n* Languages\t\t: \tPython , JavaScript, JQuery, JSON, Ajax\n* Role\t\t\t: \tDeveloper\n* Responsibilities\t\n* Working as a team member to understand the application requirements\n* Design and develop the technical solution for the project\n* Involved in User Acceptance Testing\n\nProject Description:\n \tIDrive Backup for Linux servers is a browser-based application provides a graphical interface and enables you to connect to remote Linux servers via any computer or mobile device.  Backup and Restore are the main processes involved along with Scheduled Backup and Restore operations. The Backed up data will be stored in Cloud IDrive account which can be also accessed in idrive.com and it is accessible across all platforms supported by IDrive.\n\nProject #3\n* Title\t\t\t: \tOnline Test Portal\n* Framework\t\t: \tDjango\t \t\n* Operating System\t: \tLinux Ubuntu\n* Web Server\t\t:\tApache\n* Database\t\t:\tMySql\n* Languages\t\t: \tPython, JavaScript, JQuery, JSON, Ajax\n* Role\t\t\t: \tDeveloper\n* Responsibilities\t\n* Working as a team member to understand the application requirements\n* Design and develop the technical solution for the project\n* Involved in User Acceptance Testing\n\nProject Description:\n\tThis Test Portal project is a complete portal to handle the elusive test process for the candidates. The main quality of this software is it provides 360 degree analysis of all the test takers. It mainly helps in tracking the candidates� proficiency in the given domain. The portal has Admin module and Test Module respectively. The software built to generate report card for every test taker in PDF Format.\n\nProject #4\n* Title\t\t\t: \tLancerolls\n* Framework\t\t: \tCodeigniter\t\t\n* Operating System\t: \tLinux Ubuntu\n* Web Server\t\t:\tApache\n* Database\t\t:\tMySQL\n* Languages\t\t: \tPHP, JavaScript, JQuery, JSON, Ajax\n* Role\t\t\t: \tDeveloper\n* Responsibilities\t\n* Working as a team member to understand the application requirements\n* Design and develop the technical solution for the project\nProject Description:\n\tThis Payroll Management system is to provide an option to generate the salary for every employee on every month. This software also equipped with to enter the attendance of each employee in the organization, it help them to track each employee attendance, based on this we can generate the salary. The software built to generate individual pay slip and summary of the payroll. \n\nCompetencies\n\n* Deep understanding of software engineering concepts.\n* System analysis and design.\n* Developing scalable server technology.\n* Analyzing requirements, designing and developing code for all application tiers.\n* User Acceptance Testing.\n* Ability to work with third-party APIs.\n* Requirements gathering.\n* Professional documentation skills.\n* Excellent understanding of Object Oriented Designs.\n* Process modeling, analysis and simulation.\n* Creation of visually compelling applications.\n* Ability to adapt to any environment and gain the required knowledge in short time.\n\t\nAchievements\n* Published a paper on the topic �Novel Image Segmentation through Agile Expanse Merging� in IISTE Journal. http://www.iiste.org/Journals/index.php/CEIS/article/view/380/267\n* Acquired �A� grade in the National Level �A� Certificate Examination conducted by NCC\n\n\n\nPersonal strengths\n\n* Passion to code\n* Self-Motivated\n* Ability to tackle problems and solving it in a unique way\n* Effective Communication in English\n* Time management\n* Effective team player\n* Quick learning\n* Continuous learner\n\nExtracurricular activities\n* Played a part in the combined annual training camp conducted by NCC\n* Won 2nd place in carom doubles in the interdepartmental competition\n\nPersonal profile\n�\nFather�s Name\t\t:\tA. Karthikeyan\nMother�s Name\t\t:�\tK. Rajeswari\nNationality\t\t\t:\tIndian\nDate of Birth\t\t:\t23rd Nov 1990\nHobbies\t\t\t:���\tInternet Surfing, solving mind boggling puzzles, Cricket and Carom \nLanguages Known\t:��� \tTamil, English and Kannada.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeclaration\t\n\n\tI hereby declare that the above details furnished are true to best of my knowledge.\nPlace:\t                                                                                [A.K.KAMALRAJ]\nDate:\nPage | 6","annotation":[{"label":["Skills"],"points":[{"start":4725,"end":4728,"text":"Ajax"}]},{"label":["Skills"],"points":[{"start":4719,"end":4722,"text":"JSON"}]},{"label":["Skills"],"points":[{"start":4711,"end":4716,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":4699,"end":4708,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":3888,"end":3891,"text":"Ajax"}]},{"label":["Skills"],"points":[{"start":3882,"end":3885,"text":"JSON"}]},{"label":["Skills"],"points":[{"start":3874,"end":3879,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":3862,"end":3871,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":3854,"end":3859,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3005,"end":3008,"text":"Ajax"}]},{"label":["Skills"],"points":[{"start":2999,"end":3002,"text":"JSON"}]},{"label":["Skills"],"points":[{"start":2991,"end":2996,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2979,"end":2988,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2970,"end":2975,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2138,"end":2141,"text":"Ajax"}]},{"label":["Skills"],"points":[{"start":2132,"end":2135,"text":"JSON"}]},{"label":["Skills"],"points":[{"start":2124,"end":2129,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":2112,"end":2121,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":2104,"end":2109,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1496,"end":1501,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":1182,"end":1187,"text":"JQuery"}]},{"label":["Skills"],"points":[{"start":1127,"end":1132,"text":"Python"}]},{"label":["Location"],"points":[{"start":839,"end":847,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":712,"end":720,"text":"Bangalore"}]},{"label":["Location"],"points":[{"start":79,"end":87,"text":"Bangalore"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"A K Kamalraj"}]}],"extras":null,"metadata":{"first_done_at":1532672427000,"last_updated_at":1532672427000,"sec_taken":90,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Abhijeet Kumar Gupta\nAddress: House No 11, 3rd Floor, Rahul Colony, Hadapsar, Pune � 411028\nMobile:08149452307 Email: abhijeetv.2015@gmail.com\nPython, Machine Learning, Data Science\nSynopsis:\n� Dynamic and proactive professional, with nearly 5.3 years of experience in IT industry.\n� Excellent in Python programming, Machine learning concepts and Neural Network.\n� Currently working as Senior Engineer with Harman Connected Services, Pune.\n� Previously worked as Senior Engineer,Robert Bosch Engineering and Business Solutions, Bangalore and Project Engineer with Wipro Technologies, Chennai.\n� Involved in python programminng for data analysis.\n� Practiced at planning and organising tasks to successfully complete the goals.\n� Quick learner with excellent problem solving skills and communication skills.\n� Ability to make decisions independently and quickly with minimal escalations.\nCore Competencies:\n� Design build and testing of real world machine learning applications.\n� Worked on real world data set for feature extraction based on different parameters.\n� Worked on the performace tuning of real time applications to improve the accuracy level of prediction models.\n� Knowledge in Manufacturing and Automotive domain. \nCareer Highlights:\n� Awarded FIMC (Feather in My Cap) for outstanding contribution.\n� Contributed independenly for the Hackathon for creatng an independent idea for Simulation comparison tool.\nEducation/Academic Details:\n� B. Engineering � Information Technology, RKDF IST, Bhopal, with 67% in 2012.\n� Higher Secondary (CBSE),BISSS, Bokaro, with 58.33%, in 2006.\n� Senior Secondary (CBSE),DAV Public School, Bokaro, with 70% in 2004.\nOperating Systems\nWindows, Linux, Mac \nLanguages\nPython, MATLAB\nDebugging Tools\nGitHub,svn,Mercurial\nDevelopment Framework\nRADAR Web,RAFT\nMajor Python Libraries Used\njson, Numpy, Matplotlib,scikitlearn,pandas\nOther Tools and Concepts known\n Machine Learning(Linear and Logistic Regression Models,SVM,Neural networks,Decision trees,PCA,Recommendation Systems)\n\n\n\n\n\nHarman Connected Services, Pune\nSenior Engineer, October 2016 � Present.\nProject Name: John Deere STIN\nAbstract : John Deere is an American corporation that manufactures agricultural , construction and forestery machinery , diesel engines , drivetrains used in heavy equipment and lawn care equipment.John Deere also provides financial services and other related activities to thier customers.\n\nRoles and Responsibilities:\n� Worked on real time sensor analytics using data provided by farmers equipments attached to the machinery.\n� Processing of the raw sensor data for appropiate feature extraction based on the equipment to  maximize the eqipment efficiency.\n� Development and scaling of machine learning models for the MyJohnDeere Analytics platform\n\nRobert Bosch Engineering and Business Solutions, Bangalore\nSenior Engineer, April 2015 �September, 2016.\nProject Name: AMESIM Comparison Tool\nAbstract : LMS Imagine. Lab Amesim is a commercial simulation software acquired by Siemens AG for modeling and analysis of multi domain system. Its a software package used to model, analyze and predict the performance of the systems.\n\nAmesim Comparison Tool is used to study the behaviour of various multi domain systems which are being developed and simulated in the Amesim Simulation software package.\n\nThe behaviour is analyzed in terms of the signals and variables of different components of the system.\n \n\n\nRoles and Responsibilities:\n� Analysis of the Customer Requirements to study the behaviour for customer models developed in Amesim \n� Independently came up with the idea of Amesim Comparison Tool for system behaviour  study\n� Developed the Amesim Comparison Tool as a Command Based Application framework using Python data analysis modules like Numpy and Scipy\n� Developed a machine learning recommendation model to recommend the subcomponents to the customer models. \n\nWipro Technologies, Chennai\nProject Engineer, February 2012 � March  2015.\nApple Inc., US, January 2013 � September 2014:\nApple Inc. is premier multinational company that designs, develops, and sells consumer electronics, computer software and personal computers. The project involves testing and implementation of the Apple Corp IS Projects. Apple Corp IS Project involves the testing of Apple�s internal tools and applications. The Applications and Tools are classified under different portfolios (viz. R&D, Finance).\nProject Name: Radar Automation \nAbstract:Radar is the premier communication and tracking system, which issued by Executives, directors, managers, team leaders, EPMs (Engineering Project Managers), engineers, testers, and many others in Apple and it lets them intelligently coordinate their interrelated efforts.\n\nRoles and Responsibilities:\n\n� Script Creation: As per the Suite ,script creation using python scripting language and RAFT (Apple Internal) Automation tool.\n� Creation of Page Objects using Python Libraries.\n� Creation of Methods within Classes in Python.\n� Test Script Creation using Page Objects and Methods designed to Perform Specific Operation.\n� Execution of scripts using RAFT Runner Framework.\n� Log Collection and verification in Jenkins by doing Batch run of scripts using raft runner.\n� \nPersonal/Additional Details:\nDate of Birth\t\t: 29th April, 1988.\nLanguages Known\t: English, Hindi and German(Beginner)","annotation":[{"label":["Skills"],"points":[{"start":4986,"end":4991,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4928,"end":4933,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3746,"end":3751,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1904,"end":1919,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1807,"end":1812,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1712,"end":1717,"text":"Python"}]},{"label":["Skills"],"points":[{"start":297,"end":302,"text":"Python"}]},{"label":["UNKNOWN"],"points":[{"start":169,"end":190,"text":"Data Science\nSynopsis:"}]},{"label":["Skills"],"points":[{"start":151,"end":166,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":143,"end":148,"text":"Python"}]},{"label":["Location"],"points":[{"start":77,"end":82,"text":" Pune "}]},{"label":["Name"],"points":[{"start":0,"end":19,"text":"Abhijeet Kumar Gupta"}]}],"extras":null,"metadata":{"first_done_at":1532671091000,"last_updated_at":1532671091000,"sec_taken":105,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Resume\n\nAbhinav Kumar\n\nORACLE India Total Exp: 9 years Mob: +91 9717996891\n\nEmail: abhinav.kr.86@gmail.com\n\n\nOBJECTIVE\n\n\n\n\nEDUCATION\n\n\nTo carve out a niche for myself marked by professional excellence while actively contributing to the growth of the organization and self by employing my skills.\n\n\n? INDIAN INSTITUTE OF MANAGEMENT, LUCKNOW (2016 � 2017) Jointly offered by KELLY SCHOOL OF BUSINESS (INDIANA UNIVERSITY) 1 year Program in Business Analytics for Executives \n\n? JAYPEE INSTITUTE OF INFORMATION TECHNOLOGY UNIVERSITY (2004 � 2008) \nB. Tech Computer Science and Engineering\n\nCGPA: 7.3/10 (78 %)\n\n? SHANTINIKETAN AWASIYA BAL VIDYALAYA, MUZAFFARPUR (CBSE) Senior Secondary School Examination (XII): 67.4% (2003) Secondary School Examination(X): 74.4% (2000) \n\n\n\n\nKEY SKILLS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPUBLICATON\n\n\n\n\nDescriptive Analytics, Predictive Analytics, Regression, Na�ve-Bayes, Hypotheses Testing, Data Driven Decision making, Machine Learning, Data Visualization, Disaster Recovery\n\nSOFTWARES\n? R \n? Python \n? SAS E-Miner \n\n? Tableau \n? Predictive Modelling \n\nMachine Learning Techniques\n\n? Linear Regression, Logistic Regression \n? Decision Tree \n\n? Neural Networks \n? Self Organizing Maps \n\n? Naive Bayes and so forth ... \n\n\n\nResearch Paper based on 'Machine Learning' published in International Journal: �Framework for vulnerability reduction in real time intrusion detection and prevention systems using SOM based IDS with Netfilter-Iptables�- research paper, published in � International Journal of Computer Science and Information Security, IJCSIS July 2010, Vol. 8 No. 4�- http://sites.google.com/site/ijcsis/vol-8-no-4-jul-2010; paper no 33.\n\n\nACHIEVEMENTS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPROJECTS\n\nPROFESSIONAL\n\n? International Experience: Austin, Texas (USA) - 2012, Singapore - 2015 \n? Oracle Equity Award FY17. \n\n? Awarded Oracle Star performer award along with certificate from Senior Vice President, Cloud Services for Q02, FY12. \n\n? Rated Best employee of the CSC Australia Backup team in the annual review 2009-10. \n\nACADEMIC\n\n? Awarded CERTIFICATE of APPRECIATION by VICE-CHANCELLOR, JIITU for good all round performance during the B.Tech Course. \n\n? 92.44 percentile GATE-2008 examination \n\n\n\n? Dataset preparation dealing with data import, missing value treatment using Imputation, Normalization, type conversion. Data exploration through univariate and bivariate analysis, data normalization. \n\n? Personal Loan predictive model for Bank using Na�ve Bayes in MS Excel pivot table as well as in R. \n\n? Data visualization project using Tableau for complaint tracking and management for The Consumer Financial Protection Bureau (CFPB). \n\n? Predictive model for Students Admission � Involving data preparation, exploration, model building and validation. Used various models like Na�ve-Bayes, Neural Networks, Logistic regression and Decision Trees to compare and analyse the results using R and Tableau. \n\n? Linear regression model for copier maintenance dataset with detailed discussion on regression coefficients, its interpretation and significance using R. \n\n? Statistical analysis and model building SAS E-Miner. \n\n\n\n\nCERTIFICATIONS\n???R\nProgramming,\nEdx,\nMicrosoft,\nCertificate\nId\n\naa62060ccdd04136ad63ccf1df523785\n\n\n\n? Trained in Python by Oracle. \n\n? Python: Programming for Everybody, University of Michigan, Coursera \n? Data-Driven Decision Making, PwC, Coursera, License - RDEAE6E9BTWS \n\n? Business Applications of Hypothesis Testing and Confidence Interval Estimation: Coursera, Rice Business - Jones Graduate School of Business, License - YRZZQK6K9J88 \n? Basic Data Descriptors, Statistical Distributions, and Application to Business Decisions: Coursera, Rice Business - Jones Graduate School of Business, License - 27A8FZ58JZK2 \n\n? The Data Scientist�s Toolbox: Coursera, Johns Hopkins Bloomberg School of Public Health, License - TGXSFGU3M2WC \n\n? ITIL V3 Foundation Certified, Exin \n? Symantec Netbackup 6.5 certified \n\n\nEMPLOYMENT SUMMARY\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFREELANCING\n\nORACLE, Noida, India (6 years 2 Month)\n\n? Oracle Public Cloud, INDIA - ongoing: Data Management, Data Storage, Data Protection, Disaster Recovery. Also includes automation through Python and Shell Scripting. Working constantly on analysing customer satisfaction levels & implementing improvement initiatives. In addition to it worked on best practices deployment following ITIL processes like incident management, problem management and change management. \n\n? Oracle SINGAPORE - Feb 2015: Performed automated Data collection. Handled Migration, Installation and configuration of ZFS Storage using Python scripts. Worked on Oracle Exadata along with Oracle virtual Machines. \n\n? Oracle USA (Austin, TX) - Feb-Mar, 2012: Worked on various onsite activities during the course of project which included Building new Data protection and Storage environments along with automation. \n\nCSC Noida, India (2 years 10 Month)\n\n? Worked on Data Protection and Data Storage. Successfully performed DR (Disaster Recovery) activities for various business applications. \n\n\n\n? Worked on Predictive Model development. \n? Worked on Google Web Analytics for NotNul. \n? Worked on single page website design with cross browser compatibility including chrome, IE, firefox and safari using HTML5 and CSS3. \n\n? Gave numerous presentations to clients like CityKids, Virtual Atlantic etc about useful open source tools for day to day working. \n\n\n\n\nPERSONAL\nFATHER�S NAME: A P Srivastava\nDETAILS\nNATIONALITY: Indian\n\nMARITAL STATUS: Married\n\nDATE OF BIRTH: 26 Feb 1986\n\nCONTACT ADDRESS: Abhinav Kumar\nIndirapuram, Ghaziabad -201014 (UP)\n\nI hereby declare that the information given above is correct to the best of my knowledge. Abhinav Kumar (Signature)","annotation":[{"label":["Name"],"points":[{"start":5714,"end":5726,"text":"Abhinav Kumar"}]},{"label":["Location"],"points":[{"start":5600,"end":5608,"text":"Ghaziabad"}]},{"label":["Name"],"points":[{"start":5573,"end":5585,"text":"Abhinav Kumar"}]},{"label":["Skills"],"points":[{"start":5567,"end":5567,"text":"R"}]},{"label":["Skills"],"points":[{"start":5538,"end":5538,"text":"R"}]},{"label":["Skills"],"points":[{"start":5505,"end":5505,"text":"R"}]},{"label":["Skills"],"points":[{"start":5449,"end":5449,"text":"R"}]},{"label":["Skills"],"points":[{"start":5437,"end":5437,"text":"R"}]},{"label":["Skills"],"points":[{"start":5012,"end":5012,"text":"R"}]},{"label":["Skills"],"points":[{"start":5000,"end":5000,"text":"R"}]},{"label":["Skills"],"points":[{"start":4612,"end":4617,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4489,"end":4489,"text":"R"}]},{"label":["Skills"],"points":[{"start":4195,"end":4200,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4152,"end":4152,"text":"R"}]},{"label":["Skills"],"points":[{"start":4016,"end":4016,"text":"R"}]},{"label":["Skills"],"points":[{"start":4003,"end":4003,"text":"R"}]},{"label":["Skills"],"points":[{"start":3971,"end":3971,"text":"R"}]},{"label":["Skills"],"points":[{"start":3687,"end":3687,"text":"R"}]},{"label":["Skills"],"points":[{"start":3572,"end":3572,"text":"R"}]},{"label":["Skills"],"points":[{"start":3510,"end":3510,"text":"R"}]},{"label":["Skills"],"points":[{"start":3403,"end":3403,"text":"R"}]},{"label":["Skills"],"points":[{"start":3278,"end":3283,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3256,"end":3261,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3160,"end":3160,"text":"R"}]},{"label":["Skills"],"points":[{"start":3144,"end":3144,"text":"R"}]},{"label":["Skills"],"points":[{"start":3124,"end":3134,"text":"SAS E-Miner"}]},{"label":["Skills"],"points":[{"start":3077,"end":3077,"text":"R"}]},{"label":["Skills"],"points":[{"start":2914,"end":2920,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":2908,"end":2908,"text":"R"}]},{"label":["Skills"],"points":[{"start":2556,"end":2562,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":2516,"end":2516,"text":"R"}]},{"label":["Skills"],"points":[{"start":2101,"end":2101,"text":"R"}]},{"label":["Skills"],"points":[{"start":2074,"end":2074,"text":"R"}]},{"label":["Skills"],"points":[{"start":2058,"end":2058,"text":"R"}]},{"label":["Skills"],"points":[{"start":1951,"end":1951,"text":"R"}]},{"label":["Skills"],"points":[{"start":1711,"end":1711,"text":"R"}]},{"label":["Skills"],"points":[{"start":1701,"end":1701,"text":"R"}]},{"label":["Skills"],"points":[{"start":1244,"end":1244,"text":"R"}]},{"label":["Skills"],"points":[{"start":1135,"end":1135,"text":"R"}]},{"label":["Skills"],"points":[{"start":1114,"end":1114,"text":"R"}]},{"label":["Skills"],"points":[{"start":1076,"end":1092,"text":"Machine Learning "}]},{"label":["Skills"],"points":[{"start":1042,"end":1048,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1026,"end":1036,"text":"SAS E-Miner"}]},{"label":["Skills"],"points":[{"start":1016,"end":1021,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1011,"end":1011,"text":"R"}]},{"label":["Skills"],"points":[{"start":1005,"end":1005,"text":"R"}]},{"label":["Skills"],"points":[{"start":989,"end":989,"text":"R"}]},{"label":["Skills"],"points":[{"start":868,"end":868,"text":"R"}]},{"label":["Skills"],"points":[{"start":656,"end":656,"text":"R"}]},{"label":["Skills"],"points":[{"start":653,"end":653,"text":"R"}]},{"label":["Education"],"points":[{"start":544,"end":550,"text":"B. Tech"}]},{"label":["Skills"],"points":[{"start":523,"end":523,"text":"R"}]},{"label":["Skills"],"points":[{"start":499,"end":499,"text":"R"}]},{"label":["Skills"],"points":[{"start":412,"end":412,"text":"R"}]},{"label":["Skills"],"points":[{"start":24,"end":24,"text":"R"}]},{"label":["Name"],"points":[{"start":8,"end":20,"text":"Abhinav Kumar"}]},{"label":["Skills"],"points":[{"start":0,"end":0,"text":"R"}]}],"extras":null,"metadata":{"first_done_at":1532695233000,"last_updated_at":1532695233000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "DARSHAN RAMAN JANI\nMobile No.: 09819876346\nE-Mail: djani22@gmail.com\n\nJob Objective\nSeeking assignments in IT Infrastructure Planning & Management, Service Delivery and IT Operations with an organization of repute preferably in Mumbai & Overseas\n\n\nProfile Summary\n\n· A competent professional with nearly 14 years of experience in:\n\nIT Operations & Infrastructure Management\tService Delivery Management\t\tCost Control\nITIL & Stakeholder Management \t\tCustomer Satisfaction\t\t\tSLA Adherence\nVendor /Asset Management\t\t\tIncident /Change Management \t\tProcess Implementation\nContinuous Improvement\t\t\tService Support \t\t\t\tSystem Administration\nEscalation Management\t\t\tRelease Management\t\t\tTransition Management\n\t\n· Demonstrated excellence in implementing high severity tickets to reduce business loss caused due to incidents\n· Conversant with Service now, BMC Remedy and Windows Flavors.\n· A multi-faceted professional with documented success for Complete IT operations & Release Management.\n· An ambassador of change with the distinction of successful business process re-structuring, implementation of business solutions in organizations.\n· Record of success in creating robust IT architectures & infrastructures.\n· Proven ability to bring the benefits of IT to solve business issues while managing costs and risks\n· Demonstrated excellence in planning / implementing and executing support functions using IT as business tool\n· Strong people and project management skills, including the ability to lead multiple simultaneous projects\n· An effective leader with proven abilities in leading larger teams during the project phase & BAU and guiding team members and enabling knowledge sharing among the team \n· Experience in Managing Transition for different Infrastructure Projects.\n\n\nCore Competencies\n\n· Driving business operations to outperform annual objectives; developing strong business relationships with key strategic accounts \n· Collaborated with the Senior Management and provided strategic direction on technology initiatives in line with the core organizational goals and business & profit objectives of the company\n· Functioning as key driver for business process design and solution identification; negotiating SLAs for large and medium-size business transformation projects\n· Understanding client’s needs, customizing product accordingly and consulting with technical team to provide solutions as per the delivery schedules\n· Acting as escalation point to resolve all support issues, driving resolution of customer's technical support issues; sharing best practices with team members to enhance quality technical support.\n· Managing Releases from end-to-end.\n\n\n\n\nOrganisational Experience\n                                                                                                                                                                                           \n\n\nSince Aug 09- Till now with Capgemini, Mumbai\n\nGrowth Path:\n\n\nSince Aug 2015 till now- Operations Delivery Manager (ODM)\n\nHighlights:\n\n· Single Point of Contact for all delivery related activities that include builds, Application packages and application rollouts.\n· Handle all the quotes and invoices for the packages, builds, all testing & deployment related activities\n· Liaise with all the delivery teams for the Day-to-day operations that include SOE, Discovery/Packaging, Deployment and mentor appropriately throughout the phases.\n· Custodian for ITIL processes for Change, Incident, Problem, and Release Management for End User services Team’s.\n· Manage Client Application Portfolio (held in the Definitive Application library (DAL)).\n· Assess requests and assist with solution crafting, coordinate release activities for delivery teams with the Client.\n· Close liaison with the Client’s representatives to prioritize deliverables and resolve issues related to SCCM, Packaging & SOE Image, MDM devices, Google APPS, Office 365.\n· Oversee Service Transition and Delivery of multiple domains - Systems Management, VDI, O365, PC Backup, Image management, Workplace Security (Endpoint Security Management), Application Packaging, Advanced level remote support for Active Directory & GPO, Remote infrastructure support. \n· Familiar with JIRA concept and tools.\n· Manage Financials for all projects and support unitized costing for invoicing.\n· Team management and resource engagement, oversight and governance while directly accountable for Infrastructure projects and overall Service/Project Delivery\n· Track the package & build releases throughout the lifecycle and maintain the required paperwork\n· Risk Management- Identifying Mitigation plan, Risk acceptance, Transfer, Residual Risk’s by involving stakeholders and driving to successful closure.\n· Driving RPA automation activities in End User Services domains\n· Designing Process documents as per business operations based on ITIL framework.\n· Managing Operation Team – Remote Desktop, SCCM, Packaging, Office 365, MDM, Service desk, Application Support, Service Management, Vendors, Local on-site Support for France and Finland countries.\n· Conducting Daily/Weekly operational meet with operation team to SLA related to Incident, Problem, and Change Management.\n· Reviewing Change’s as per governance process for flawless execution of Changes.\n· Driving CSI’s improvement measures within EUC Team as part of continuous improvement process\n· Identifying shift left opportunities in grooming next level for talent.\n· Attaining KPI’s related to operations by aligning metrics as per ITIL best practices.\n\n\nAug ’09 to July ’15: Wintel IT Operations Lead (ODM)\n\nHighlights:\n· Accountable for:\n· Planning, executing, monitoring and controlling Facility Management Services for IT Infrastructure Project\n· Managing projects with complex SLA through a team of over 70 Certified Engineers\n· Reviewing SLA’s with internal and external customers in order to fulfill needs of IT Infrastructure Facility Management\n· Transition management- Managing Transition from Project to BAU.\n· Designing RACI model for new Services.\n· Conduct Daily Service Review calls to understand issues and concerns for day to day operations.\n· Overseeing implementation of the latest practices and framework like ITIL for achieving practically ‘0’ down time for infrastructure\n· Performing gap analysis & recommending to adoption latest trends in Infrastructure.\n· Planning and implementing improvement plans so as to improve soft & technical skills of the team members                                                                                                                                                                    \nInitiated and engaged in quality measures to reduce cost and efforts by means of automation, global delivery Framework.\n· Conduct Daily Service Review calls to understand issues and concerns for day to day operations.\n· Vendor Management- Managing 3rd Party Vendors for routine operations.\n· Risk Management- Highlighting Risks to stakeholders and identifying mitigation.\n· Capacity Management-Proactive Capacity management to identify capacity issues to avoid outages.\n· Hands-on experience on Wintel , File & Print, Active directory, DNS, DHCP, ISA, VMware, Hyper-V,  SQL, Exchange Servers.\n· Profound knowledge in ITIL process management & Customer Relationship Management.\n\nNov 07 – Nov 09 with Wipro InfoTech as Senior Engineer, Mumbai\n\nHighlights:\n\n· Managing and Administration of Symantec Altris servers-CMS level 1 Suite.\n· Managing and Administration of VMware ESX v 3.5, ISA 2006, Windows2000/2003/2008.\n· Managing and Administration of Web sense Security suite for Web filtering.\n· Managing Active directory, DHCP, DNS, File & Print Servers.\n· Preparation of Daily, Weekly, Monthly service reports for Management review.\n· Vendor Management- Managing 3rd Party Vendors for routine operations.\n· Liaising with European clients for day to day operations.\n\nApril 2007 - October 2007 with Zenith InfoTech as Server Engineer\n\nHighlights:\n\n· Creation of User ID’s, Exchange recipient management, Public Folder Administration.\n· Installation, Configuration & Maintenance of Exchange 2003.\n· Installation & Configuration of windows 2003 server, Domain controllers, DNS, DHCP.\n\nAugust 2006 - March 2007 with IT Source as Customer Support Engineer\n\nHighlights:\n\n· Installation of Active directory, DNS, DHCP, Exchange 2003.\n· Configuration, Monitoring and troubleshooting of all standard software’s and IBM applications.\n· First level support for all Server Issues Including Creation Of user accounts.\n· Managing Desktops and Laptops.\n\n\nAugust 2003 - July 2006 with Syscon InfoTech as Customer Support Engineer\n\nHighlights:\n\n· Managing Desktops and Laptops.\n· First level support for all Server Issues.\n\nEducation\n\n· BCOM, Graduated March 2003- Mumbai University\n· MCOM, Graduated March 2005- Mumbai University\n· PGDCA, Graduated June 2006- Madurai Kamraj University\n\nCertifications:\n· MCSE Certification in Windows 2003 Server\n· MCTS Certification in Windows 2008 Server\n· MCITP: Enterprise Administrator in 2008 Server\n· CCNA: Cisco certified Network Associate\n· ITIL Version 3 Certified\n· ITIL 2011 Intermediate Service Operations Certified\n· ITIL 2011 Intermediate Service Design Certified\n· ITIL 2011 Intermediate Service Transition Certified\n· ITIL 2011 Intermediate CSI Certified\n· ITIL 2011 Intermediate Service Strategy Certified\n· ITIL 2011 Managing Across Lifecycle Certified\n· ITIL 2011 Expert Certified\n· PRINCE2 Foundation & Practioner Certified\n· PMP Trained 35 Hours PDU from University of California , Irvine Extension\n· Conflict Management Specialization from University of California , Irvine Extension\n\n\nPersonal Details \t\t\n· Date of Birth\t\t\t05th Sep 1982\t\n· Address\t-----11/A, Flat No 602, Harmony Society, Mhada Colony, Shailendra Nagar, Dahisar (East)\n· Languages Known\t\tEnglish, Hindi, Guajarati and Marathi","annotation":[{"label":["Location"],"points":[{"start":9804,"end":9810,"text":"Dahisar"}]},{"label":["Education"],"points":[{"start":8857,"end":8861,"text":"PGDCA"}]},{"label":["Skills"],"points":[{"start":3486,"end":3503,"text":"Release Management"}]},{"label":["Skills"],"points":[{"start":961,"end":978,"text":"Release Management"}]},{"label":["Skills"],"points":[{"start":678,"end":698,"text":"Transition Management"}]},{"label":["Skills"],"points":[{"start":657,"end":674,"text":"Release Management"}]},{"label":["Skills"],"points":[{"start":633,"end":653,"text":"Escalation Management"}]},{"label":["Skills"],"points":[{"start":566,"end":587,"text":"Continuous Improvement"}]},{"label":["Skills"],"points":[{"start":513,"end":540,"text":"Incident /Change Management "}]},{"label":["Skills"],"points":[{"start":486,"end":509,"text":"Vendor /Asset Management"}]},{"label":["Skills"],"points":[{"start":416,"end":444,"text":"ITIL & Stakeholder Management"}]},{"label":["Skills"],"points":[{"start":403,"end":414,"text":"Cost Control"}]},{"label":["Skills"],"points":[{"start":374,"end":400,"text":"Service Delivery Management"}]},{"label":["Skills"],"points":[{"start":332,"end":372,"text":"IT Operations & Infrastructure Management"}]},{"label":["Name"],"points":[{"start":0,"end":17,"text":"DARSHAN RAMAN JANI"}]}],"extras":null,"metadata":{"first_done_at":1532687818000,"last_updated_at":1532687818000,"sec_taken":254,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Dinesh Kumar R\nE-Mail: dineshkmrbe@gmail.com  \nMobile: +91-8144108385\nSeeking a position to utilize my skills and abilities in the global competitive environment that offers professional growth as well as corporate growth while being resourceful, innovative and flexible environment.\n\tPROFILE SYNOPSIS\n\n\nOver 5 years of experience in software industry, currently working as Lead Engineer for Python development team.\n· Deft in determining operational feasibility by evaluating, analyzing requirements and solutions.\n· Holds strong knowledge in Odoo (Formerly known as OpenERP) 7& 8 versions.\n· Gained Experience and good knowledge in Odoo Module Customization.\n· Expertise as a Programmer, Analyst and Application Developer using Agile methodology.\n· Designed and Implemented Reports and Dashboards using Jasper Reports.\n· Good knowledge in Human Resource Concepts and have experience of working in Human Resource with Accounting related projects.\n· Good managerial skill in assigning task to team members and coordination of same to complete in correct time.\n· Quickly learn and master new technologies; successful working in both team and self-directed settings. \n· Strong and innovative ideas regarding software development and testing scenarios. \n\tIT SKILLS\n\n\n· Programming Languages:  Python, XML, C#\n· Web technologies: HTML, JavaScript, CSS\n· Database: Oracle10g, PostgreSQL\n· Version Control Tools: Git\n· Operating Systems: Linux, Windows\n· Frameworks: OpenERP(Odoo) , Django\n\tPROFESSIONAL EXPERIENCE\n\n\n· HCL Technologies Ltd. (April 2016 to Present)\n\tDesignation:\n\tLead  Engineer\n\n\tLocation:\n\tChennai, Tamil Nadu, India -  600119\n\n\tProjects Types:\n\tWeb Applications, Desktop Applications\n\n\tKey Roles:\n\t· Involve in requirements walkthrough/analysis.\n\n· Preparation/walkthrough of design documents.\n\n· Developed automated Python tools for application testing.\n\n· Involved in Testing the usability of application with Unit based Test cases.\n\n\n· ITFlux Technologies Pvt Ltd.  (January 2014 to March 2016)\n\tDesignation:\n\tSoftware  Engineer\n\n\tLocation:\n\tKochi,  Kerala, India -  682030\n\n\tProjects Types:\n\tWeb Applications, Desktop Applications, Odoo(Formerly known as OpenERP) 7, 8 & 10\n\n\tKey Roles:\n\t· Customization & creation of Odoo Modules based on requirements of the client.\n· Occupied with development and support programmer for different projects to modify the changes as per requirement of the client.\n· Provide reliable solutions to a variety of problems and follow-up for the client satisfaction.\n· Requirement gathering, analysis, estimate development and deployment efforts based on requirements of the client.\n· Review product and application information including manuals and brochures for technical accuracy.\n· Experience of working as a team leader and good managerial skill in assigning task to team members\n\n\n· Winstrata Software Solutions Pvt Ltd.  (May 2012 to September 2013)\n\tDesignation:\n\tSoftware  Engineer\n\n\tLocation:\n\tBangalore, Karnataka, India -  560054\n\n\tProjects Types:\n\tWeb Applications, Desktop Applications, Odoo(Formerly known as OpenERP) 6 & 7\n\n\tKey Roles:\n\t· Customization & creation of Odoo Modules based on requirements of the client.\n· Database Designing for the Data Entities.\n\n· Documenting the software design.\n\n· Implementation of the approved software design.\n\n· Requirement gathering, analysis, estimate development and deployment efforts based on requirements of the client.\n· Responsible for all report development using Jasper.\n\n\n\tACADEMIC QUALIFICATIONS\n\n\n· Bachelor of Engineering (Computer Science & Engineering) from Anna University, 2011 in First Class.\n\tCERTIFICATIONS & TRAINING\n\n\n· Completed Oracle Certification course in Oracle10g\n· Completed Dot NET course in Times Technologies\n\tPROJECT SUMMARY\n\n\nCurrent Project : I18N\nOrganization\n\n:\nHCL Technologies\n\nClient\n\n\n:       \nCISCO\n      Team Size\n\n:      \n5\n\n      Duration\n\n:      \nApr 2016 to till date\n      Role                                :\nPython Tool Developer\n    \nTools Developed           :\nWeb Scrapping, Bundle Preparation & GLB Issue Tracker\nProject Description: This project is all about working on the client server where it will enlighten and enrich the users to run more number of instances in a go and also where we support the internalization (i18n) i.e. localization in which it supports multiple languages whereas it also supports the respective native language, it is one of the major functionality on the users perspective to use the application.\nProject 1: HRM\nOrganization\n\n:\nITFlux Technologies\n\nDomain\n\n\n:       \nHR\n\nEnvironment\n\n:\nPython, OpenERP, Postgresql, XML, RML, Ubuntu\nClient\n\n\n:       \nVidya Academy, Jomsons, Vinayaka Homes, Amphora\n      Team Size\n\n:      \n2\nRole                                :\nProgrammer\n      Duration\n\n:      \n Feb 2015 to Mar 2016\nProject Description: Employees are considered as one of the biggest assets of any company. A smooth and effective working of a company depends on its employees. Human Resource Management (HRM) project can help the organization to manage the resource properly with effectively and efficiently such as contracts, time management, skills management and other related activity.\nFollowing are the modules implemented for Human Resource Management,\n\n· Employee Profiles\n\n· Employee Contracts\n\n· Expense Management\n\n· Leave Management\n\n· Payroll Management\n\n· Attendance Management\n\n· Recruitment Management\n· Retirement and Resignation of Employees\nProject 2: College Automation ERP\nOrganization\n\n:\nITFlux Technologies\nEnvironment\n\n:\nPython, OpenERP,  Postgresql, XML, RML, Ubuntu\nClient\n\n\n:       \nVidya Academy\n      Team Size\n\n:      \n3 \nRole                                :\nProgrammer\n      Duration\n\n:      \nJan 2014 to Jan 2015\nProject Description: This ERP is mainly done for the smooth functioning of college/school process. This software contains Admissions module, Finance and Accounting, Purchase module, Fixed Assets module, HR & Payroll module to incorporate procedures of school/college. The admission module is mainly dealing with Online Applications, Application Fee Payments, Rank lists, Short Listing of Candidates for Admissions/Scholarships, Waiting Lists, Options, Vacancies, Student ID Generation, Fee Structures, College Transfers, Semester Registrations, Readmissions, Academic Fee Payments and Reimbursements, Fee Waivers, Certificate Records etc. and generating associated reports. The admission module is completely integrated with Finance and Accounting Module. This ERP also provide the feature for Purchase Request Creation/Approval Process. RFQ Generation, Creation of Purchase Order, Supplier Invoice Creation, Incoming Shipments Process. The Asset Module is also incorporated in this ERP i.e Creation of Asset, Depreciation Calculation, Asset Sale, Asset Dispose, Asset Transfer etc. Another module was HR Module which provides facility for payroll generation and leave management. Based upon the different salary components payslip will be generated for each employees and payment to the employees was also incorporated. Leave Management Module contain leave creation/approval, leave allocation to employees. These are the main modules implemented in this project.\n\nProject 3: VVM\nOrganization\n\n:\nWinstrata Software Solutions\n\nEnvironment\n\n:\nPython, OpenERP, Jasper Report, Postgresql, XML, Ubuntu\n      Team Size\n\n:      \n3 \nRole                                :\nProgrammer\n      Duration\n\n:      \nFeb 2012 to Sep 2013\nProject Description: V.V. Mineral (VVM) is India’s largest Mining, Manufacturer and Exporter of Garnet & Ilmenite Minerals.  Goal of this project is to develop application for analyze the process of total production and dispatch quantity of minerals in every day. The product is configurable as per client requirements like online catalog, product details, employer details, order details. Once the Employer gets authenticated then user gets the main page and online catalog is created for that employee to use web store services.\nProject 4: Poultry Automation \nOrganization\n\n:\nWinstrata Software Solutions\n\nEnvironment\n\n:\nPython, OpenERP,  Jasper Report, Postgresql, XML, Ubuntu\n      Team Size\n\n:      \n2 \nRole                                :\nProgrammer\n      Duration\n\n:      \nNov 2012 to Jan 2012\nProject Description: This project is a Web based application, developed by Winstrata Software Solutions Pvt. Ltd. for making the Poultry Management very simple. In this automation user can purchase the birds batch wise, can assign shed for each batch, can manage the batch  by transferring the birds batch from one shed to another shed, can feed the birds batch wise by doing daily activity, can manufacture the feed by using different BoM's, can sell the  birds and eggs. To analyze the bird’s batch wise, to analyze the feed given to each batch wise etc., we developed many reports using jasper reports.\nProject 5: Sanghvi Textiles \n\nOrganization\n\n:\nWinstrata Software Solutions\n\nEnvironment\n\n:\nPython, OpenERP,  Jasper Reports, Postgresql, XML, Ubuntu\n      Team Size\n\n:      \n2 \nRole                                :\nProgrammer\n      Duration\n\n:      \nMay 2012 to Nov 2012\nProject Description: This is a Web Based application, developed by Winstrata Software Solutions, that supports employer to view and order products through online catalog. The purpose of this application is to provide the software requirement details for automating the Sanghvi Mills Production division. Through this application user can easily, \n\n· able to create and manage the customer and supplier details\n\n· able to manage the purchase process of raw materials and  maintenance products                                                                          \n\n· able to record the daily production process like Blow room process, Carding, Drawing, Simplex, Spinning, Winding and Packing\n\n· able to record the daily expenses of each Mill\n\n\tGENERAL DETAILS\n\n\n\tFather's Name\n\tMr. K.S.Ravichandran\n\n\tFather's Occupation\n\tFarmer\n\n\tDate of Birth                           \n\t03/07/1990\n\n\tGender\n\tMale\n\n\tMarital Status\n\n\tSingle\n\n\tLanguages Known\n\tTamil, English, Malayalam\n\n\tResidential Address\n\tPananchalai(Thottam), Malayalappatti(P.O), Veppanthattai(T.K), Perambalur District, Tamil Nadu, India - 621103.\n\n\tHobbies & Interest\n\tListening to Music & Playing Badminton\n\n\n\tPERSONAL TRAITS\n\n\n· Talented with innovative ideas and strong desire for self-improvement.\n· Ability to deal with people diplomatically, good team player and managerial skills.\n· Ability to grasp new concepts and new technologies quickly.\n· Does my work with great  care and devotion\n· Adaptable to new environment, motivating other team members.\n· Ability to code efficiently and handle the project individually.","annotation":[{"label":["Skills"],"points":[{"start":9002,"end":9004,"text":"XML"}]},{"label":["Skills"],"points":[{"start":8956,"end":8961,"text":"Python"}]},{"label":["Skills"],"points":[{"start":8125,"end":8127,"text":"XML"}]},{"label":["Skills"],"points":[{"start":8080,"end":8085,"text":"Python"}]},{"label":["Skills"],"points":[{"start":7323,"end":7325,"text":"XML"}]},{"label":["Skills"],"points":[{"start":7279,"end":7284,"text":"Python"}]},{"label":["Skills"],"points":[{"start":5566,"end":5568,"text":"XML"}]},{"label":["Skills"],"points":[{"start":5536,"end":5541,"text":"Python"}]},{"label":["Skills"],"points":[{"start":4603,"end":4605,"text":"XML"}]},{"label":["Skills"],"points":[{"start":4574,"end":4579,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3961,"end":3966,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1830,"end":1835,"text":"Python"}]},{"label":["Location"],"points":[{"start":1602,"end":1608,"text":"Chennai"}]},{"label":["Skills"],"points":[{"start":1461,"end":1473,"text":"OpenERP(Odoo)"}]},{"label":["Skills"],"points":[{"start":1344,"end":1346,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1332,"end":1341,"text":"JavaScript"}]},{"label":["Skills"],"points":[{"start":1326,"end":1329,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1303,"end":1304,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1298,"end":1300,"text":"XML"}]},{"label":["Skills"],"points":[{"start":1290,"end":1295,"text":"Python"}]},{"label":["Skills"],"points":[{"start":392,"end":397,"text":"Python"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Dinesh Kumar R"}]}],"extras":null,"metadata":{"first_done_at":1532682863000,"last_updated_at":1532682863000,"sec_taken":0,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Govardhana Rao M\n\n\n\nEmail: govardhana841@gmail.com\nMobile No: +91-9912217791\n\n· Having 6+ years of Experience in IT.\n\nHaving around 2 years of experience in IBM Watson technologies (WCA-Watson content development, WEX, WKS-Watson knowledge studio, NLC-Natural Language classifier)\n· Having around 4 Years of experience in the field of Microsoft Business Intelligence (SSIS) and SQL Server\n\n· Having knowledge on SSRS.\n\n· Having working Knowledge on IBM Watson Explorer and Content Analytics. \n\n· Creating Different Types of Scripts like DDL,DML\n\n· Managing SQL Server objects including tables, indexes, views, constraints.\n\n· Development of stored procedures triggers. \n\n· Having good Knowledge on Backing up and restoring the database.\n\n· Having good Working Knowledge on Creating SSIS Packages.\n\n· Implemented ETL Functionality Using SSIS Component.\n\n· Having Knowledge on Creating SSRS Reports.\n\n· Having Good communication and Interpersonal skills, hardworking, dedication at work  and result oriented as an individual and in a team\n\n\nDatabases\n\n\n:   SQL Server, Oracle, \nETL Tools\n\n\n:   SQL Server Integration Services (SSIS)\nLanguages\n\n \n:   TSQL, PL/SQL\nOperating Systems\n\n:   Windows 98, 2000, XP, 2007\nWatson Explorer \n\nFoundational Components\n:   Watson Explorer, Watson Content Analytics, Watson Knowledge Studio\n\nDevelopment tools\n\n:   Notepad++\n\n\tMCA(Master of Computer Applications)\n\tLBRCE(Laki Reddy Bali Reddy  College of Engineering)\n\t2009\n\tJNTU Kakinada\n\n\n\n\tPersistent Systems Ltd\n\tJanuary 2012 to Till date\n\n\tArtech Info Systems Pvt. Ltd\n\tApr 2011 to  October 2011\n\n\n\nProject No: 1\n\nProject Title: \n\nWatson Content Development- Phase 2\n\nClient: \n\n\nIBM\nRole: \n\n\nCognitive Engineer\nSkills:           \nWindows 2007, IBM NLC (Natural Language Classifier)\nFrom: \n\n\nJan 2017.\nTo: \n\n\nDec 2017.\nTeam Size: \n\n15\nScope of Project: Watson Content Development intent to develop the content for the chatbot, which IBM uses for user interaction. This is spread across various domains like Telco, Retail Banking, Energy and Utilities and Insurance.\n\nThe user can have any intent or question, for which he is seeking an answer from the chatbot. The chatbot has to be trained accurately, so that it helps the user in identifying the correct solution to his problem.\n\nFor Example, a user may ask ' What are the bill payment options?\". The chatbot should be trained smart enough to answer this question and provide him with all the available payment options.\n\nThe application required, the development of the content, which should be used for testing the accuracy of the chatbot. The test data should be created in such a manner, that the bot is 75% accurate.\n\nResponsibilities: \n· Developed test data for chatbot, for Retail Banking Domain. \n· Translated the data into multiple languages like Spanish, Italian etc. by taking the help of language experts. \n· Created a dialog flow for chatbot using NLC.\n· Uploaded and trained chatbot data to NLC.\n· Improved the data continuously so that bot gives 75% Accuracy\nProject No: 2\n\nProject Title: \n\nHR Analytics\nClient: \n\n\nPersistent \nRole: \n\n\nCognitive Engineer\nSkills: \n\n\nWindows 2007, Watson Explorer, Watson Content Analytics\nFrom: \n\n\nMar 2016.\nTo: \n\n\nNov 2016.\nTeam Size: \n\n7\nScope of Project: The purpose of this POC is to minimize the time around for the HR people to scrutinize the Resume’s which are matching to the JD’s (Job Description). Instead of keyword search wherein we fetch the resumes using a specific keyword, we can input the JD and fetch the matching resumes with all the parameters defined. The keyword search will fetch numerous resumes who have that respective keyword (skill or experience or education) mentioned in his resume even though he haven’t used that particular skill in his projects. JD’s are company specific and are structured but resumes are unstructured where we need to crawl the resumes from a dump and match to the respective JD’s. Handled ranking for all the resumes which are fetched during the JD input. Also handled the reverse process of inputting the Resume and fetching the respective JD’s which are matched to the skills mentioned in the Resume.\n\nResponsibilities:\n· Created different kinds of Dictionaries like Education, Skills Etc. and Parsing Rules like Candidate Name, Contact Info Etc. for different CV’s using Content Analytics. \n· Created annotations for the using the defined parsing rules. \n· Created Content Analytics Collections to store the values that exported from Content Analytics. \n· Created indexes and facets to export the required fields like Candidate Name, Email, and Contact No. etc. to WEX.\n· Created the association between the facets with the indexes to export the required fields to WEX.\n· Created collections by crawling Resumes in word/ pdf format using IBM Watson Explorer (WEX).Scheduled the collections depending upon the Business requirement. \n· Created Endpoints to display the data to fetch from WEX and to deploy it on the AppBuilder. \n· Created Entities using collections Defined in WEX.\nProject No: 3\nProject Title: \n\nHeartBeat-MTP\n\nClient: \n\n\nHeartBeat\nRole: \n\n\nETL and Database Developer\nSkills: \n\n\nWindowsXP, SSIS, SQL Server 2012\nFrom: \n\n\nJan 2015.\n\nTo: \n\n\nDec 2015.\n\nTeam Size: \n\n6\nScope of Project: The primary purpose of the Heartbeat ODS system is to provide accurate data to the stakeholders. Heartbeat application is designed to help pharmaceutical, biotech, and medical device companies profile and deliver data to their Thought Leaders, Opinion Leaders, Speakers, and Investigators. Heartbeat KOL management tool provides enterprises with an intelligible, logically-structured view of all company KOLs segmented by brand, therapeutic area, region, role, and level of influence.\n\nResponsibilities: \n· Creating Different Types of Scripts like DDL and DML. \n· Backup and restore the databases from Production server to different Servers.\n· Importing the data from Test Environment to Development Environment.\n· Extracted data from various sources like MS SQL Server, Excel, flat files, and loaded into the target MS SQL Server database. Creating SSIS Packages by using different control Flow Task like Execute SQL Task, Execute Package Task, and Execute Process Task to load data into Database. \n· Creating SSIS Packages by using different data Transformations like Derived Column, Lookup, Data Conversion, Conditional Split, Merge, Merge Join, Union all, Fuzzy look up, Fuzzy Grouping and Send Mail Task to load data into Database. \n· Handling the Errors.\n\n· Created Event Handlers for the Packages Using Event Handler tab. Tested Packages in development Environment before moving to Test Environment with Sample data. \n· Tested Packages in Test Environment before moving to Production Environment with Complete data. \n· Created and Managed Package Configurations in XML files to efficiently promote Unit testing. \n· Deploying the Packages on different Environments. \n· Creation and scheduling of ETL Packages Using SQL Server Agent. Monitored and scheduled existing/new jobs on production environment.\nProject No: 4\nProject Title: \n\nJNJ CrossRoads\n\nClient: \n\n\nJohnson&Johnson\nRole: \n\n\nETL and Database Developer \nSkills: \n\n\nWindowsXP, SQL Server 2012, SSIS\nFrom: \n\n\nJan 2013.\nTo: \n\n\nOct 2014.\nTeam Size: \n\n7\nScope of Project: It’s a data conversion Project, where data are being fetched from different Legacy systems like JDE, R2 etc. and Inserting into the Staging Database in SQL server Environment. Once the Staging Environment is complete then those data for each object are being put into an integration database which also exists in SQL Server 2008 by doing the Cleansing, Transforming and applying the Business rules. Then those data are being sent to the Informatica in Flat file format for further Processing and loading into SAP System.\nResponsibilities: \n· Creating tables which meet the requirements. \n· Creating Different Types of Scripts. Writing the Functions, Stored Procedures which meet the requirements. \n· Importing and Exporting Data from Main Database to Local Database for Backup Purpose. \n· Creating SSIS Packages to load the Data from Template to Staging Database. \n· Creating  SSIS Packages by using different data Transformations like Derived column, Lookup, Conditional Split, Merge Join, Sort load Staging Data into Integration Database. \n· Creating SSIS Packages by using Different Tasks like Execute SQL Task, Dataflow Tasks to load Staging Data into Integration Database. \n· Creating SSIS Packages by using different data Tasks like Execute Process Task, ExecuteSQL Task and Dataflow Task to load Integration Data into Flat File. \n· Uploading the data into the FTP Location by using the FTP Task. \n· Maintenance the SSIS packages. Build, Configure and Deploy the SSIS Packages. \nProject No: 5\n\nProject Title: \n\nGMAC Insurance Management Systems\n\nClient: \n\n\nGMAC\n\nRole: \n\n\nETL and SQL Server Developer\n\nSkills: \n\n\nWindowsXP, SQL Server 2008 R2, SSIS\n\nFrom: \n\n\nJan 2012.\n\nTo: \n\n\nDec2012.\n\nTeam Size: \n\n5\n\nScope of Project: GMAC is the largest general insurance group (based on the amount of personal and commercial insurance premiums) and one of the largest bank (Ally Gmac Bank). GMAC insurance specializes in RV insurance, VEHICLE insurance, HOME insurance and also has leading superannuation, investment and asset management business.\n\n\n     We receive the data in the form of xml, excel and flat files which need to be loaded into the Database schemas. For loading data into Data Base, we are designing SSIS Packages and for data representation we are developing by using SSRS. \n\nResponsibilities:\n· Creating staging database for temporary processing of data, consolidating data and Loading database using Integration services.\n\n· Creating Packages on SSIS by using different data Transformations like Derived column, Lookup, Conditional Split, Merge Join, Sort and Execute SQL Task to load data into Database.\n\n· Writing the Stored Procedures which meet the requirements.\n\n· Developing parameterized reports including multi-parameters.\n\n· As per the requirements, rendering the reports in the form of Excel and .CSV formats for each module with credentials.\n\n· Uploading the generated reports to Share Point Folder.\n\n\nProfessional Summary\n\n\n\nTechnical Skills/Abilities\n\n\n\n\n\nEducation\n\n\n\nEmployment History\n\n\n\nP Professional Experience","annotation":[{"label":["Skills"],"points":[{"start":9552,"end":9555,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":8902,"end":8911,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":8858,"end":8867,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":7585,"end":7594,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":7181,"end":7190,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":6961,"end":6970,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":6060,"end":6069,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":5999,"end":6008,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":5153,"end":5162,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1092,"end":1101,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1055,"end":1064,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":884,"end":887,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":557,"end":566,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":412,"end":415,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":378,"end":387,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":335,"end":373,"text":"Microsoft Business Intelligence (SSIS) "}]},{"label":["Skills"],"points":[{"start":157,"end":179,"text":"IBM Watson technologies"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"Govardhana Rao M"}]}],"extras":null,"metadata":{"first_done_at":1532690651000,"last_updated_at":1532690651000,"sec_taken":104,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Kapil Gupta\nKapilg007@gmail.com\n+91 – 9743898016\n+91 – 9986739438\t\n\t\t\t\t\t\t\t\n\nObjective:\n\n· As a Consultant looking for an opportunity to make a difference by bringing my enthusiasm and expertise to the forefront of a leading company’s Business Analytics and Business decisions.\n· Looking forward for a challenging position into Analytics as Senior Analyst/Data Scientist/Consultant that would increase Business productivity and in turn enhance my skills & competency in various domains.\n\n\nCareer Summary:\n· Working as Data Scientist for Wipro Limited with 7.0 years of IT experience in Banking and Financial Services, Retail domain.\n· Worked for 3 years into Mainframe than moved into Analytics, from last 4 years working into Analytics.\n· Now part of Data Science team working on Machine Learning.\n· Worked for various clients - State Street, HSBC Bank, Wal-Mart, Microsoft, and Nokia under Wipro. \n· Completed Wipro internal training on Data Science.\n· Part in few of Data Science competitions on Kaggle.\n· Good experience in Data Extraction, Data Cleaning, Data Preparation, Modification, missing values treatment and outlier detection.\n· Experience in SAS BASE, SAS ADVANCE, SAS/SQL, SAS/PROC, SAS/STAT AND SAS/MACRO.\n· Experience on working various R-packages like – dplyr, Amelia, ggplot2, sqldf etc. \n· Learning Python, working on Python packages – Pandas, Numpy.\n· Basic understanding on Risk Analytics, Basic Statistics, Predictive Analytics.\n· Basic understanding on Big Data tool like – Hadoop, Hive.\n· Have some Hands-on on Data Visualization tool like – Tableau, Alteryx.\n· Worked on few Case Studies & Build Statistical Models by using R.\n· Working on Analytics tools like – SAS EG, R Studio, Azure Machine Learning Studio, CRM Dynamics.\n· Working on SAS 9.4, SAS Base, SAS Advance, R and Python.\n· Working as a Freelance Trainer in Data Science\\Machine Learning using R, SAS with 2+ year’s exp.\n\n\nTechnical Skills:\n· Advanced Analytics                     : Machine Learning, Statistics, Probability, Mathematics\n· Analytics Tools                             :  SAS , R, R Studio, Python, Azure Machine Learning Studio\n· R-Packages                                   : StringR, dplyr, ggplot2,Amelia\n· Python Packages                         : Pandas, Numpy\n· Operating System\t        : WINDOWS -XP/7/8/10, Z/OS 390.\n· Documentation Tools                 : MS Office, MS Word, MS Excel, MS PowerPoint \n· Languages\t\t        :  R-Programming, C-Programming, SQL, Excel\n· Database\t\t        : Hadoop, SQL Server ,Oracle, CRM Dynamics\n\n\n\n\nProfessional Experience:\n\n\n1. Client Microsoft and Nokia, Finland\n    Timeframe June 2017 – Present \n    Role Data Scientist\n    Environment SAS, R- Programming Language, Azure Machine Learning Studio, Statistics, Mathematics, SQL,\n                                   CRM Dynamics  \n\n\nResponsibilities:\n\n· Working on Machine Learning Algorithms, Time-Series Modeling, and Regression Analysis.\n· Preparation of Design and Architecture documents.\n· Data gathering, cleaning, validation, quality, exploratory data analysis, Univariate/Bivariate Analysis, missing value and outlier treatment by using SAS and R.\n· Working on Statistical model development R - Programming Language, Azure Machine Learning Studio.\n\n\n\n2.  Client HSBC Bank, Asia-Region\n     Timeframe January 2016 – May 2017 \n     Role Data Scientist\n     Environment SAS 9.4, SAS Enterprise Guide, R-Programming Language, Statistics, SQL\n\nResponsibilities:\n\n· Worked as a Data Scientist in Risk Analytics/Management domain under Credit Risk &Market Risk section.\n· Worked on Data Analysis, Data mapping, Data mining, and Data Cleaning, Reports, Requirement Gathering, and clients meetings.\n· Worked in Market Risk team to generate MTM, Value at risk (VAR) and Profit\\Loss.\n· Worked on SAS Banking tools like – Risk Management for Banking (RMFB), Risk Dimension.\n· Working on methodologies in measuring market risks i.e. Standardized Measurement Method (SMM) and Internal Models Approach (IMA).\n· Basic understanding on RBI Guidelines.\n· Working on ETL, Playpen Creation, Analysis Running, and Historical VaR Analysis.\n· Market risk model development by using Historical Simulation method, Model validation, and pricing validation.\n· Enhancements, Bug fixing, Generating reports by using SAS and R-Studio.\n· Basic understanding on Data Visualization by using Tableau.\n\n\n\n3.     ClientWal-Mart, USA\n        Time Frame November 2013– December 2015\n        Role Business Analyst \n       Environment SAS 9.4, MS-Office, SAS EG, SQL, Excel\n\nResponsibilities:\n\n· Worked as a Business Analyst.\n· Worked with Marketing Analytics\\Strategy team to help in generating models, reports.\n· Requirement gathering, Data mining, cleansing & processing data.\n· Worked on SAS Reporting.\n· Using SAS, Excel, and SQL to extract, transform & load source data.\n· Data Auditing, creating data reports & monitoring all data for accuracy.\n\n\n\n4.      Client  State Street Corporation, Boston, USA\n         Time Frame  January 2011 – October 2013\n          Role Mainframe Developer\\Analyst \n          Environment IBM Mainframe Platform, MS-Office, Excel\n\nResponsibilities:\n\n· Looking into the daily issues\\requests encountered in the Fund Conversion Accounting Part of State Street.\n· Coordinating with the SME’s of the interface systems in order to resolve the business critical issues within the Service Level Agreement.\n· Consistently communicating with the clients about their queries and imparting Fund Conversion related knowledge to other team members.\n· Maintaining the customer satisfaction, Service Delivery and Service Assurance for State Street Customers.\n\n\n\n\n\n\n\nAchievements:\n\n· Honored with ‘The Prodigy’ for great contribution in the Application Maintenance at Securities Domain Level.\n· Awarded ‘The Outstanding Contribution Certificate’ from the Client IT Manager for completion of a Regulatory Maintenance work and hence avoiding the client to be penalized.\n· Awarded ‘Thanks a Zillion’ for the flexibility to work in any systems and performing well as per the project requirement.\n· Offered for the role of onsite coordinator for State Street to handle Accounting Systems.\n\nTrainings& Projects:\n\n· Completed Wipro internal assessments with 86%.\n· Cleared UCF 1.1, 2.1, 2.2 and Securities-101 assessments (Wipro Internal).\n· Completed Wipro internal Code of Business conduct training, Clients Ambassador Program, Securities assessments.\n· Completed Integrated Service Management(ISM) training.\n· Completed one month training in SUPER THERMAL POWER STATION (1500MW), SURATGARH, Rajasthan (India) in 7th Semester of College..\n· Completed one month training on MATLAB, PLC &SCADA from Prolific Systems and technologies Pvt. Ltd., Jaipur in 7th Semester of College.\n· Submitted Project on Electrical Appliances controlling by using Personal computers in Final Semester of College.\n\nExtra-Curricular Activities:\n\n· Good in sports field and have passion for adventures, travelling and Guitar.\n· Played as Captain for College and School Cricket Team.\n· Played Nationals in Kho-Kho games.\n\n\nEducational Summary:\n\n\tQualification\n\tSchool/College\n\tPercentage\n\tYear Passed\n\n\tB.Tech.\n\tGyan Vihar School of Engineering and Technology  (Electrical Engineering), Rajasthan Technical University\n\t65.77\n\t2010\n\n\t12th\n\tD.A.V. Centenary Public School, Jaipur (C.B.S.E.)\n\t63.80\n\t2005\n\n\t10th\n\tD.A.V. Centenary Public School, Jaipur (C.B.S.E.)\n\t60.00\n\t2003\n\n\n\nPersonal Details:\n\n· Name                                 : Kapil Gupta\n· Father’s Name                 :  Rishi Kumar Gupta\n· Mother’s Name               :  Sunita Gupta \n· Date of Birth \t            :  3rd January, 1988\n· Gender                               :  Male\n· Marital Status                   :  Single\n· Present Address               :  House No.3/4,3rd B Cross, 21stMain,BTM 2ndStage,Bangalore- 560076.\n· Permanent Address        : 11\\93, Kaveri Path, Mansarovar, Jaipur, Rajasthan -302020.\n· Home Town                      :  Jaipur (Rajasthan)\n· Languages Known            :  English, Hindi\n· Passport Available           :  Yes\n\n\n\nDeclaration:\n\nI, Kapil Gupta hereby declare that the information given above is true and correct to the Best of my Knowledge.\n\nDate:-  \n\n\n\n\n\n\n\n\n\n\n (\nSensitivity: Internal & Restricted\n)","annotation":[{"label":["Name"],"points":[{"start":8095,"end":8105,"text":"Kapil Gupta"}]},{"label":["Name"],"points":[{"start":7491,"end":7501,"text":"Kapil Gupta"}]},{"label":["Education"],"points":[{"start":7158,"end":7163,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":5094,"end":5102,"text":"Mainframe"}]},{"label":["Skills"],"points":[{"start":5039,"end":5047,"text":"Mainframe"}]},{"label":["Skills"],"points":[{"start":4781,"end":4783,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":4758,"end":4760,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":4521,"end":4523,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":4501,"end":4503,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":4293,"end":4295,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3791,"end":3793,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3382,"end":3384,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3373,"end":3375,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3229,"end":3244,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":3143,"end":3145,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2863,"end":2878,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2724,"end":2739,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2688,"end":2690,"text":"SAS"}]},{"label":["Location"],"points":[{"start":2605,"end":2611,"text":"Finland"}]},{"label":["Skills"],"points":[{"start":2109,"end":2124,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2076,"end":2078,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1972,"end":1987,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1885,"end":1887,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1859,"end":1874,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1783,"end":1785,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1773,"end":1775,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1764,"end":1766,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1712,"end":1727,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":1688,"end":1690,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1210,"end":1212,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1197,"end":1199,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1187,"end":1189,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1178,"end":1180,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1165,"end":1167,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1155,"end":1157,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":780,"end":795,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":658,"end":666,"text":"Mainframe"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Kapil Gupta"}]}],"extras":null,"metadata":{"first_done_at":1532667219000,"last_updated_at":1532667219000,"sec_taken":172,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "SEQ CHAPTER \\h \\r 1KSHITIJ VICHARE\n5, Shirgaonkar Society, \n\n1178/15, E Ward, Mali Colony, \n\nKolhapur, Maharashtra- 416008, India.\n\nCell: (+91) 9765608736\n    \n\n\n\n\n\nEmail: kpvichare@gmail.com\nSUMMARY:    \nData Scientist passionate about cutting-edge technology and solving real-world problems in e-commerce and healthcare, with experience in predictive analytics and developing data products.\nSKILLS AND TOOLS:    \n\n· Supervised and Unsupervised machine learning\n\n· Python, R\n\n· Scikit-learn, Pandas, Numpy, Scipy, Seaborn\n· Caret, Shiny, dplyr, tidyr, ggplot2\n· Tensorflow, PyTorch\n· Django, Flask \n· SQL, Git, Linux system\n· Working knowledge: Spark, Docker\nWORK EXPERIENCE:\nNavya Network, Bengaluru, Karnataka, India \n\n\n\n          (March 2016 to Current)\nData Scientist\n\n· Designed machine learning pipeline for raw clinical data to collect electronic medical records (EMR) features, combine patient demographic information, and generate insightful features and annotated datasets. Built and deployed well-tuned Random Forest and XGBoost models to predict treatment recommendations. Built web-based dashboard in shiny to automatically test models with different metrics and analyze predicted treatment recommendations with decision tree.\n· Built and deployed well-tuned XGBoost models to predict probability of agreement between representativeness of patients in randomized controlled trials and results of meta-analysis studies.\n· Built and deployed well-tuned XGBoost models to predict ranking score calculated on factors that influence clinical study, based on features crafted on methodology, impact factor, publication and citations of clinical studies.\n· Validated and processed over 3000 rows (medical cases) of EMR data with over 1000 variables. Data based on patient demographics, past medical history and treatment recommendations. Increased overall data quality by data wrangling and cleaning with R libraries like dplyr, tidyr, data.table and lubridate and python libraries like pandas, numpy and scipy to get well structured and formatted datasets.\n· Analyzed and interpreted patterns in EMR and patient demographic data with exploratory data analysis, visualization and using statistical methods like regression analysis and cluster analysis. Applied hierarchical clustering and other machine learning techniques like t-SNE to extract and analyze patterns in treatment recommendations. \n\n· Built and maintained a web-based business intelligence dashboard on AWS for workforce analytics and performance management, programmed in R and shiny dashboard.\nManorama Infosolutions, Kolhapur, Maharashtra, India\n\n\n  (March 2015 to March 2016)\nData Analyst \n· Extracted data from various data sources, applied R functions to transform raw data into information required for reporting and data analysis purposes. Successfully completed training on in-house databases and RDBMS concepts.\n· Prepared various statistical data analysis reports for corporate clients, integrated R functions to in-house .NET platform and SSRS reports.\n· Built machine learning models to predict primary myocardial infarction (MI) from electronic health records on basis of risk factors.\n\n· Built machine learning models to predict survival rates of cardiac patients on basis of risk factors and post-surgery stay.\nEDUCATION:\n· Master of Science in Biotechnology 2014\n\nUniversity of Hertfordshire, Hatfield, United Kingdom\n\n\n\n\n\n· Bachelor of Engineering in Biotechnology 2011\n\nKolhapur Institute of Technology, MH, India               \nPROFESSIONAL DEVELOPMENT ACTIVITIES:\n\n· Completed with distinction online courses in ‘Practical Machine Learning’, ‘R Programming’, ‘Python for Genomic Data Science’, ‘Statistics for Genomic Data Science’, ‘Command Line Tools for Genomic Data Science’, ‘Algorithms for DNA Sequencing’, ‘Bioconductor for Genomic Data Science’ and ‘Genomic Data Science with Galaxy’. \n\n\n\n\nJohn Hopkins University\n\n\n\n\n\n\n             (2014 – 2015)","annotation":[{"label":["Skills"],"points":[{"start":3181,"end":3196,"text":"machine learning"}]},{"label":["Skills"],"points":[{"start":3045,"end":3060,"text":"machine learning"}]},{"label":["Skills"],"points":[{"start":2302,"end":2317,"text":"machine learning"}]},{"label":["Skills"],"points":[{"start":785,"end":800,"text":"machine learning"}]},{"label":["Location"],"points":[{"start":692,"end":700,"text":"Bengaluru"}]},{"label":["Skills"],"points":[{"start":446,"end":461,"text":"machine learning"}]},{"label":["Name"],"points":[{"start":19,"end":33,"text":"KSHITIJ VICHARE"}]}],"extras":null,"metadata":{"first_done_at":1532675139000,"last_updated_at":1532675139000,"sec_taken":25,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "MAHENDAR G\n    \t   gadapa.mahendar@gmail.com\n      \t   Ph: +917702856657                                                                                           \n   \t                                                                       \t\t\t\t\n OBJECTIVE\n\t\n\tHaving 4+ years of Professional experience in GIS and Remote Sensing data Analysis,\nSpatial data analysis, Image processing, clustering and classification (unsupervised and supervised), linear regression and logistic regressions. Knowledge of  R–programming, Python Scripting, MSSQL Server, Machine Learning, MS Excel.\n\t\n RESEARCH SKILLS\n\n· Applying Machine learning concepts into remote sensing, Image Processing and spatial data using R-Programming and Python Scripting.\n· Geo Spatial Analysis, Geo Statistical Analysis, Clustering Analysis for Crop Acreage Estimation. Identification of Different Crop Signatures. Village Level Land Use Land Cover Analysis.\n· Vulnerability Assessment of West Bengal Coast, East Coast of India, assessed Shore line change rate, Sea level rise, Extreme water levels from tide gauge observations and vulnerability mapping.\n· Extensive Use of SRTM, Landsat, Liss III, Liss IV data Sentinel-2A for Topographical analysis.\n· Multi Hazard mapping for the West Bengal Coast. considered elevation, shoreline change rate, Historical Events, Sea level rise Data. \n· Flash Flood and Urban Floods Prediction Using Satellite data, Elevation Data, Precipitation and Historical Event Data.\n· Ground Water Recharge points Identification and Site Suitability Analysis for Rain Harvesting pits Along the Roads Networks, With Mathematical Models, Regression Techniques and Spatial data analysis. Used Elevation, Precipitation and soil data.\n· Road safety, Congestion Studies and Block Spot Identification along the Road by using mathematical Models, Road Network Parameters and Historical Data.\n\n\n\n\n\n\n\n  TECHNICAL SKILLS\n\n· ArcGIS Pro 2.0, ArcGIS 9.x, 10.x , QGIS 2.18, Sentinel Toolbox, ERDAS, SWMM(Storm Water Management Model), SWAT(Soil and Water Assessment Tool), DSAS(Digital Shoreline Analysis System)\n· R-Programming, Python Scripting, MSSQL Server, Machine Learning, MS Excel.\n· Data Extraction, Pruning, Data Analysis and Visualization, Exploratory Data Analysis, Predictive Analytics, Linear Regression, Logistic Regression, Clustering and Classification, Machine Learning Algorithms.\n\n  PROFESSIONAL EXPERIENCE\n\nGIS-CONSULTANT\n\niConcept Software Services Pvt.Ltd (June 2016 to till Date)\n· Crop Acreage estimation using LISS IV, Landsat, Sentinel 2A Data, Field Surveyed and SOI data.\n· Identifying Market Clusters, Hot spot Analysis for different Crops.\n· Extensively used Spatial Analyst, Spatial Statistics, Image Processing, Classification and Tabulation, Cluster, Image Analysis Techniques.\n· Land Use Land Cover Mapping.\n· Cluster Analysis by considering Crop Acreages.\n· Geo Spatial and Geo Statistical data Analysis.\n\nRESEARCH ASSOCIATE\n\nJNTUH/CIVIL/COE-Disaster Management (April 2014 to March 2016)\n· Worked for centre of excellence on Flash floods and urban floods.\n· Road safety and Intelligent Transportation system.\n· Village Adoption for the flash flood mitigation and management.\n· Land use Land Cover Classification for the flood prone area.\n· Application of mathematical models to the flood prone to study the risk factor and quick distribution of flooded water.\n· Finding the Optimal Location of Rain Harvesting pits along the Roads.\n· Used Data SRTM, CartoDEM, Landsat, Liss III, Esri Online Base maps and Filed Survey data for the Research work.\n\n\nPROJECT ASSISTANT\n\nIndian National Centre for Ocean information Services/INCOIS\n(December 2012-December 2013)\n· Coastal Vulnerability Assessment Mapping by using ArcGIS, ERDAS and DSAS for West Bengal Coast.\n· Calculation of Shore line Change Rate - Shore line Erosion and accumulation.\n· Analysis of Mean sea level data to the Area from the Tide Gauge data.\n· Assessment for the Extreme Water values with the Historical Data. \n· Assessment of Hazardous Area.\n· Mapping of Vulnerable area along the West Bengal Coast.\n· Used Data CartoDEM, Landsat, Tide Gauge Data, Mean Sea level Data, Filed Survey data for the Project.\n\nPROJECT ENGINEER\t\n\t\t\nVKHVAC Systems (June 2009 to November 2011)\n· Project Execution for HVAC and Electrical Projects.\n· Support for Documentation of Electrical, HVAC, Contractor Billing.\n· Interact with clients, Contractor & others related to site activities.\n· Coordinating with Client for approval of material, drawings, Works carried in site and Erection & Installation of Equipment.\nSterling & Wilson.Pvt.Ltd (March 2008 to June 2009)\n· Project Engineer for HVAC Project Execution and Maintenance. \n· Erection of Chillers, Cooling Towers, Air Handling Units and Fan Coil Units.\n· Guiding to AutoCAD draftsman for preparation of HVAC drawings for installation of A/C equipment and accessories.\n· Load calculations for Air Conditioning tonnage and Chill water pipe line.\n\n  QUALIFICATION\n\n2014 M tech in Geo Informatics & Surveying Technology from JNTU, Hyderabad \n2007 B tech-EEE from Kamala Institute of Technology & Science – KITS(S),   Huzurabad\n2003 Intermediate from SR Junior College, Hanamkonda\n2001 SSC from SCHS, Mandamarri \n\n\n\n\n  STRENGTHS\n\n· I accept challenging jobs.\n· I am conscientious worker with good communication skills.\n· I have the ability to grasp things quickly.\n· I adapt to changing technologies and keep myself up to date with the latest and the best.\n\n  ACHIEVEMENTS\n\n· Paper Published Within the INCOIS (MOES) on “Coastal Vulnerability Assessment of West Bengal Coast – East Coast of India”.\n· Paper presentation on “Land Use Land Cover Mapping using AWifs Data” at NCRTST-2015 JNTUH CEJ.\n· Qualified GATE-2011 and GATE-2010.\n· Got 33Kv Electrical contract license from the government of Andrapradesh.\n\t\n\n\n  \nPERSONAL PROFILE\n\nName\t\t\t:\tMahendar Gadapa\nFather’s name\t             : \tGopal\nGender\t\t\t:\tMale\nDate of Birth\t\t: \t20th January, 1986\nMarital Status\t             : \tSingle\nLanguages known\t: \tTelugu, Hindi, English\nNationality\t\t:\tIndian\n                                                                  \n  DECLARATION\n\nI do hereby declare that all the information provided above is true to the best of my knowledge and belief, followed by my signature, date & place.\n\nPlace:                                                                                     \n   Date:                                                                                                 \t(Mahendar G)","annotation":[{"label":["Education"],"points":[{"start":4976,"end":4981,"text":"M tech"}]},{"label":["Skills"],"points":[{"start":2342,"end":2357,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2151,"end":2158,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":2133,"end":2148,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":2119,"end":2130,"text":"MSSQL Server"}]},{"label":["Skills"],"points":[{"start":2101,"end":2116,"text":"Python Scripting"}]},{"label":["Skills"],"points":[{"start":2086,"end":2098,"text":"R-Programming"}]},{"label":["Skills"],"points":[{"start":713,"end":728,"text":"Python Scripting"}]},{"label":["Skills"],"points":[{"start":695,"end":707,"text":"R-Programming"}]},{"label":["Skills"],"points":[{"start":567,"end":574,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":549,"end":564,"text":"Machine Learning"}]},{"label":["Skills"],"points":[{"start":535,"end":546,"text":"MSSQL Server"}]},{"label":["Skills"],"points":[{"start":517,"end":532,"text":"Python Scripting"}]},{"label":["Skills"],"points":[{"start":312,"end":339,"text":"Remote Sensing data Analysis"}]},{"label":["Skills"],"points":[{"start":303,"end":306,"text":" GIS"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"MAHENDAR G"}]}],"extras":null,"metadata":{"first_done_at":1532675423000,"last_updated_at":1532675423000,"sec_taken":126,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Naveen Kumar Chigurupalli\n\t(91) 735 836 4906\nnaveenkumarch.bigdata@gmail.com\n\n\n\nProfile\nWorking as Lead- Analytics with proficiency in machine learning \nwith around 8 years of involvement in conveying end-to-end \ninformation science projects using ETL, visualization and tools for \nData science and machine learning.\n.\n\nSkills\n\n\nMachine Learning\n\n\nData wrangling, data preparation and building machine learning \nmodels.\n\n· Supervised and Unsupervised learning models using Python/ R.\n· Logistic, Linear, SVM, KNN, Naïve Bayes, KMeans\n\nData processing platform\n· KYLO, AWS Glue, NIFI, Hadoop, Hive, Pyspark, Talend DI & Talend MDM, Informatica, Datastage\n\nDatabase & Visualization \n\nRedshift, Postgres, SQL Server, Power BI, Tableau\n\nCloud \n\n\nPossess robust design and Implementation skills\n\n· AWS, Microsoft Azure\n\nProject Methodology\n\n· Agile, SDLC\n\n\nExperience\nBioclinica India\nNov’ 2016 - till date\n\nLead Analytics\n\nInternal Product Development\n\n· Performed data cleansing, transformation and statistical analysis using R/ Python.\n\n· Extract the high value information that is found in the unstructured text to make convincing representations.\n· Analyze relevant information such as clinical trial site, selection criteria, study characteristics.\n· Extracted clinical trials information for various sites using NLP to identify Bag of words with unigrams and bigrams world cloud.\n\n· From the word cloud table able to understand which investigators are running clinical trials for diseases xyz, which trials (in a given disease) use drug xyz in combination with another drug.\n· Trained and tested the model with an accuracy of over 87%.\n· Align with the product architect and provide technical solutions as per the product road map.\n· Developed and implemented data feeds from source data models using Talend DI, MDM, TAC and bult visualization in Power BI.\n· Implemented infra-as-a-code to automate the code deployment.\n· Provide solution for technical and business challenges.\n\n· Build POC’s to leverage the current platform for the future technology enhancements.\n\n. \n\n\nBigTapp Analytics\nMarch 2015 - Nov 2016\n\nSenior Decision Analyst\n\n\nTBD AirAsia campaign management product.\n· Interacted with the customer to understand the functional/non-functional requirements.\n· Created database objects on AWS Redshift and ETL jobs on Talend Bigdata DI on AWS Cloud.\n· Built models for sentimental analysis using Naive Bayes and NLP to measure the customer satisfaction.\n\n· Trained and tested the model for over 80000 customer reviews.\n\n· Model was able to predict at an accuracy of over 91.35% with less amount of variance with good sustainability.\n· Developed Customizable and reusable components.\n· Implemented master data reconciliation to identify and report inconsistent or non-coherent data from source to stop potential information loss by using REST API’s.\n\n· Create data flow diagrams, data mapping from source to stage and Stage to Target mapping documents indicating the source tables, columns, data types, transformations required and    business rules to be applied.\n\n\nHexaware Technologies\nDec 2011 - March 2015\n\nSenior Software Engineer\n\nProject 01:\nLufthansa Systems- Germany, Customer Premises.\n· Involve in meetings with the Business in understanding the applications and collect the requirements and transform to documents and coding.\n\n· Initiate the process to get the sign –off for starting the development.\n\n· Develop the code and deliver as per the quick requirement for the business.\n\n· Provide the UTC, UTR’s and review the code and deliver for SIT and fix the defects on priority and perform the RCA for the defects raised.\n\n· Create Mapping Specification documents, develop DB scripts.\n\n\nProject 02:\n\nCustomer Churn Analytics & Pricing for T-Mobile Netherlands\n\nProject 03:\n\nFund Transfer Pricing Process for a leading bank in Singapore, Customer Premises.\n\niFlux Technologies\nNov 2009 - Dec 2011\n\nSoftware Engineer\n\n\nMMIPL \nAug 2006 - Jan 2007\nNetwork Administrator\n\nEducation\nUniversity of Hertfordshire, UK\n2007-2008\n\nPost Graduate Diploma in Computer Science\n\nMadras University\n2000-2004\n\nBachelors in Electronics & Communications Engineering\n\nEnd of the Document","annotation":[{"label":["Education"],"points":[{"start":4044,"end":4064,"text":"Post Graduate Diploma"}]},{"label":["Skills"],"points":[{"start":2350,"end":2353,"text":" AWS"}]},{"label":["Skills"],"points":[{"start":2300,"end":2303,"text":" AWS"}]},{"label":["Skills"],"points":[{"start":798,"end":812,"text":"Microsoft Azure"}]},{"label":["Skills"],"points":[{"start":792,"end":795,"text":" AWS"}]},{"label":["Skills"],"points":[{"start":567,"end":570,"text":" AWS"}]},{"label":["Skills"],"points":[{"start":329,"end":344,"text":"Machine Learning"}]},{"label":["Name"],"points":[{"start":0,"end":24,"text":"Naveen Kumar Chigurupalli"}]}],"extras":null,"metadata":{"first_done_at":1532668869000,"last_updated_at":1532668869000,"sec_taken":99,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Nitin Agarwal\nmnitin3@gmail.com | in.linkedin.com/in/agnitin | +919686479651\n\n\n\nEXPERIENCE    IQVIA | Associate Consultant /Data Scientist                                                                                             Sep’17 – Present\n     Solve Multi-channel business/Analytical problems, which could be addressed with supporting data.\n     Analyzed sales, prescription, units and patient-level datasets using analytics and business rules to provide\nsolutions for business problems.\n\nAccelopt Networks | Freelancer                                                                                  Aug’17 – sep-2017\n     Real-time throughput prediction based on network conditions, in a mobile edge computing platform\n     Predicted call failure of the users in advance using Dynamic Time Warping and SVM techniques in the SON\nto reduce call failures/drops.\n\nKPMG | Senior Associate                                                                                                    May’15 – Aug’17\n     Inventory Analysis\nDeveloped  an  inventory  analysis  tool,  using  SQL  and  Alteryx,  which  extracts  inventory  usage,  inventory purchase data to calculate material values based on inventory accounting methods like LIFO, FIFO and WAC.\n     Exploratory Data Analysis Tool\nDeveloped a prototype of exploratory analysis tool using R and Rshiny to analyze and visualize any delimited file. Refer to the link for live demo:  https://mnitin3.shinyapps.io/ggplot/edat/\n\n     Revenue Sensitivity Analysis\nDeveloped a Tableau dashboard backed by R to perform sensitivity analysis which enables clients to predict, analyze sales and demand using historical data to understand variation in the revenue with market factors.\n\n     ACL to Alteryx Migration\nLead  the  migration  of  data  processing  for  insurance  client  from  ACL  scripts  to  Alteryx  workflow  which involved extracting business and technical understanding of the ACL code, develop workflows to generate expected results in excel.\n\n     Audit Analytical Processing\nAnalyzed clients financial data, which involves extracting/collecting the data from client systems, validate the data, transform and load to a database, perform audit analytical routines using SQL and KPMG propriety tool, develop interactive reports using Tableau,  and communicate the insights to auditors and clients.\n\nMindtree | Module Lead                                                                                                     Nov’14 – May’15\n     Incorporated analytical solutions using SQL and R for Contact Centre and HR department of a UK’ top Media\nclient.\n\tApplied data mining techniques  using  R and SQL  to reduced 8% operational costs with higher customer satisfaction for the contact Centre.\n\nAccenture | Senior Analyst                                                                                                  Jul’11 – Nov’14\n\tLed the development of analytical solutions for a Pharmaceuticals Client covering 3 business units - Supply chain for forecasting demand, R&D for Clinical Trial Management, and Marketing for customer data.\n     Mentored and trained 40+ corporate professionals on relational databases and Business Intelligence.\n\nRaqtdaan | Founder                                                                                                              Nov’12 – Jun’17\n\tDeveloped and launched a digital platform to track potential blood donors, redirecting them based on real- time blood requirements across the country.\n     Used PHP, HTML, CSS and MYSQL to develop the website.\n\nSKILLSET                       R Programming\n    Advanced Excel\n    Data Warehousing, ETL\n    SQL, Alteryx\n\n    Exploratory Data Analysis\n    Descriptive  analysis\n    Tableau\n    Machine Learning\n\n    Text Mining\n    Data Mining\n    Predictive Modelling\n    Data Visualization, Tableau\nEDUCATION             HBX | Harvard Business School                                                                                                       May’16\nPre-MBA (CORe) - Business Analytics, Economics for Managers, Financial Accounting\n\nIIIT Bangalore                                                                                                                                      May’15\nGraduate Certificate Program in Business Analytics\n\nJaypee University of Information Technology                                                                             May’11\nBachelor of Technology in Electronics and Communication Engineering\n\nACHIEVEMENTS         Earned Coursera credentials in R programming from John Hopkins University.\n   Earned edX credentials in Predictive Analytics from IIM, Bangalore.\n   Awarded Client Excellence award for quality delivery and innovation in team initiatives.\n   Completed Six Sigma Yellow Belt certification and implemented a project to reduce 80% of the manual effort.\n   Won IBM Great Mind Challenge ’09 (biggest software development competition as per Limca Book of Records).\n   Stood overall 4th amongst 400 teams in healthcare Innovation Competition Elixir 3.0 organized by IIT Bombay.\n\nOTHER PROJECTS\n\nInternational Gold Price Analytics\n   Predicted  the  international  gold  price  by  analyzing  consumer  demand  obtained  from  social  media  as  well  as financial news-feed data. Acquired the data that would in turn manifest into the international demand, cleansed the data and filtered out only the records that were relevant to our analysis.\n   Performed text mining using statistical tools (R Programming) and techniques to derive certain key sentimental\ninsights about the data  set, stored in MySQL database and further proposed a regression model to ultimately predict the international gold price.\n\nXBRL Data analysis tool\n   Working on development of R Shiny app and dashboard to analyze US financial reports data from XBRL, to help consumers interested in getting source XBRL data for comparative purposes.\n\nHR Analytics – Exploration and Prediction\n   Explored  various  aspects  of  the  data  such  as  satisfaction  level  of  employee  and  others  to  correlate  with  the employees who left. This data has been taken from Kaggle datasets and also created a notebook.\n   Predicted the future employee leaving by using trees based modelling with 90% accuracy.\n\nPrediction of Chronic Kidney Diseases\n   Predicted the Chronic Kidney Disease using classification algorithms using the patient’s data from UCI Machine\nLearning platform.\n   Analyzed the correlation of the class variable with other attributes using correlation matrix, significantly guided in\nreducing the number of predictors to predict the class variable.\n\nAutomated Intravenous Infusion Monitoring System\n   Created  a  device  which  automatically  stops  the  infusion  system  when  the  bottle  gets  emptied  and  perform automatic scheduling of medicinal injections.\n   Presented a working prototype in a healthcare Innovation Competition Elixir 3.0, Techfest [IIT Bombay] and Stood overall 4th amongst 400 teams. The project was covered in an exclusive article by CHIP Magazine in Nov ‘10.\n\nNationalized Online Polling System\n   Developed  a  web  application  to  automate  Online  polling  system  for  the  Election  Commission  of  India  with additional features like ad-hoc & scheduled reports, Forums, chats, real-time poll status with graphics. Developed automated report generating engine using jasper reports API to generated ad-hoc and reports.\n   The project stood all India 5th amongst 30000 participating projects in IBM Great Mind Challenge ’09 (biggest\nsoftware development competition of India as per Limca Book of Records).\n\nAutomation of Civil Courts\n   Developed a web application to automate the functioning of Civil Courts of India and developed an automated report generating engine using jasper reports API to generated ad-hoc and scheduled reports.\n   Participated in IBM Great Mind Challenge ’10 with this project, where it was adjudged amongst the top 30 projects\nall over India.\n\nPERSONAL DETAILS\n\nDate of Birth: 3rd  November 1988\nVISA: Business visa for USA(B1/B2), valid till 2025","annotation":[{"label":["Education"],"points":[{"start":4024,"end":4037,"text":"Pre-MBA (CORe)"}]},{"label":["Skills"],"points":[{"start":3794,"end":3804,"text":"Data Mining"}]},{"label":["Skills"],"points":[{"start":3778,"end":3788,"text":"Text Mining"}]},{"label":["Skills"],"points":[{"start":3755,"end":3771,"text":" Machine Learning"}]},{"label":["Skills"],"points":[{"start":3675,"end":3681,"text":"Alteryx"}]},{"label":["Skills"],"points":[{"start":3669,"end":3672,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":3643,"end":3659,"text":" Data Warehousing"}]},{"label":["Skills"],"points":[{"start":3606,"end":3619,"text":" R Programming"}]},{"label":["Skills"],"points":[{"start":2670,"end":2673,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":2550,"end":2553,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":2238,"end":2241,"text":" SQL"}]},{"label":["Skills"],"points":[{"start":1856,"end":1862,"text":"Alteryx"}]},{"label":["Skills"],"points":[{"start":1746,"end":1752,"text":"Alteryx"}]},{"label":["Skills"],"points":[{"start":1094,"end":1100,"text":"Alteryx"}]},{"label":["Skills"],"points":[{"start":1083,"end":1086,"text":" SQL"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Nitin Agarwal"}]}],"extras":null,"metadata":{"first_done_at":1532673655000,"last_updated_at":1532673655000,"sec_taken":724,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Curriculum Vitae\nRelevant in R Programming & ML : 2.2 Yrs.\n\nPradyut Kumar Parida \n\n\n                 Email: pradyutparida@yahoo.com                           Data Analyst\n\n\n\n\n\n\n   \nMobile: +91-8197395757\n\n\n\n\n\n\n\n      +91-7205291510     \nCAREER OBJECTIVE:\nTo work in a progressive organization which can expand all my knowledge and provided me exciting \nOpportunities to utilize my skills and qualification to produce result fidelity.\nSKILL SET:\n· Statistical Analytics Tool:- R/R Studio/SQL\n· Statistical Analysis :- Supervised , Unsupervised and reinforcement learning, predictive analysis\n· Machine Learning: - Correlation test, Regression Analysis, CART, Random Forest, ARIMA, Clustering,\n Boosting, Bagging, Hypothesis testing, ANOVA, Factor Analysis.\n\n· RDBMS:- Oracle(9i,10g,11g,12c), OEM, SQL, PLSQL, MYSQL\n· Application Package :- SQL Developer, OEM(12c,13c),WinSCP, Service Now, HPSM\nEmployment History:\nCapgemini India pvt. Ltd.\n\nProject #1\n\n\nTitle              :  TRAX Analysis Support\nClient\n         :  Jetstar Airline, Australia\nRole              :  Senior Analyst\n\nTeam Size     :  6\n\nDescription:   \n\n           Client is a value based carrier network providing everyday low fares with an open approach to air travel. In this assignment we were doing the predictive Analysis to help the client to understand and improve the Business Market used by the Client Application.\n\nResponsibilities:\n\n· Market research:-\nPredictive and Inquisitive statistics (R Linear Regression and Time series-ARIMA)\n· Helped the Organization to quantify the increment in sales and identified offers which were leading to the significant spike in sales, Generated reports of ATP, Build Business and Spend using R and ARIMA model.\n\n· Built an automated solution for analyzing the impact of personalized marketing effort which helped in improving the efficiency of the offer, giving weightage using Linear Regression.\n\n· Optimized the existing process of post campaign analysis to help client use the results from initial weeks to improve the offers of ending weeks for a season.\n· Market management to account growth of Organic Customer:-\n\nDescriptive statistics (R and K-Means Clustering)\n\n· Created framework using past purchase and response behavior to identify the list of customer eligible for targeting in a season\n\n· The objective was to find out growth of Organic customers and understanding the key drivers.\n\n· Built an Automated code in R to find the growth of organic customers and clustered the customers according to their spend.\n· Efficacy of Air-carrier:-\nData Visualization (ggplot)\n\n· Helped the client to track the on-time Schedule of the air carriers by summarizing information on the number of on-time, delayed, canceled and diverted flights.\n\n· Worked on ggplot and Tableau to generating dashboards and standardize data for production stage. Generation of Statistical Tables, Listings and Graphs as per client requirement. Creation of plots (Mean plots, Box plots, Linear Plots, charts, graphs and maps).\n· Reporting Creation:-\nDashboard Creation and Advance Visualization (Tableau and Excel)\n· Use all our analysis and create dashboard report and documentation using Tableau and Excel\n· Help the client to understand by Visualization report\n· Dashboards and stories for Service management tickets using tableau\nProject #2\nTitle              :  GE Analysis Support \nClient\n         :  GE Oil & Gas, USA\nRole              :  Environment Report Analyst\nTeam Size     :  6\nDescription:   \n\n           Client is a value based giant in oil & gas sector. In this assignment we were doing the predictive Analysis to help the client to understand and improve the machinery lifecycle and Business Market used by the Client Application.\nResponsibilities:\n\nSub-project # A\n\n· Worked as a senior analyst to predict lifecycle period of machinery used for extraction of oil.\n\n· Helped the Organization to quantify the machinery lifecycle for maintenance using R and random forest model.\n\n· Built an automated solution for analyzing the impact of different attributes like (temp, pressure etc.) which helped in improving the efficiency of the machinery and decreases the possibility for machinery failure.  \n· Optimized the existing process of post campaign analysis to help client use the results from initial weeks to improve the process day by day.\nSub-project # B \n· Worked as an environment Report Analyst and Emission (PMR Report analyst) have been closely working with clients based all across the globe.\n\n· Have created dashboard sand stories for Service management tickets using tableau.\n\n· Have created SQL queries to retrieve data from system.\n\n· Used R to analyze emission reports for over 300 refineries.\n\n· Have used ggplot in R to create emission data visualization and Heat Maps.\n\n· Have worked in Emission forecasting for UK-Forecast model using time series analysis.\n\n· Have clustered emission sources based on GHG emissions using K-means clustering.\n\n· Classifying category of equipment based on emissions.\nIgate Global Solution \n\nProject #3\n\nTitle              :  Orange\nClient\n         :  Switzerland\nTools\n         :  Oracle (9i,10g,11g,12c), SQL Studio, SQL Developer\n\nRole              :  Oracle DBA\n\nTeam Size     :   6\nDescription:   \n           Client is a value based carrier network providing all day everyday telecom services. In this assignment we are supporting the databases used by the Client Application.\nResponsibilities:\n\n· Availability of Databases, Instances and its listeners.\n\n· Growth of Tablespaces, data files and Redo log files.\n· Index creation and partition for easy access and space restoration.\n· Disk space and escalate to OS administrators for any disk space issues and also inform the Client regarding the consequences of it.\n· The existing DR site to make sure that they are in sync with production.\n\n· Monitoring alert logs for errors and resolving them. \n\n· PROD/Training/Test/Experimental environment database support.\n\n· Creation of new databases and administration of existing databases.\n\n· Database User Account creation and administration.\n· Role creation, modification, deletion.\n\n· Deleting older archive logs on regular basis. \n\n· Export/Import or data pump based on backup requirement.\n· Monitoring the RMAN backups scripts and troubleshooting if any failures.\n· Knowledge in listeners setting, TCP/IP, UDP/IP.\n\nProject #4\nTitle             :  Kinetic Concepts, Inc.\n\nClient\n        :  USA\nTools\n        :  OEM 11g and 12c and 13c, WinSCP\nRole             :  OEM Admin\nTeam Size    :  2\nDescription: \n          KCI is a global corporation that produces medical technology and markets its products in more than 25 countries. Client is headquartered San Antonio, Texas.\nResponsibilities:\n· OEM 12c and 13c Monitoring.\n· Installation of Agent in Server, Targets addition in OEM,\n\n· Troubleshooting Any issue or failure in DB level through OEM. \n· Monitoring the RMAN backups scripts and troubleshooting if any failures\n\n· Dashboard report creation automatically through oem.\n\n· Creation and management of schemas as per user requirement.\n· Creation of jobs to automate daily process and DAC jobs.\n· Analyzing performance issues\nAcademic Details \n\tCourse\n\tPassing Year\n\tBoard/University\n\tMark(%)\n\n\tB.Tech\n\t2013\n\tBPUT, Odisha\n\t76\n\n\tIntermediate\n\t2009\n\tCHSE, Odisha\n\t74\n\n\tMatriculation\n\t2007\n\tHSC, Odisha\n\t82\n\n\nAchievements:\n\n· Got Xtra-mile award for outstanding performance and client handling skill in project for year 2017.\n\n· ITIL and Yellow Belt trained and Internal Certified.\n· Achieved 1st position in circuit-design and inter collage volley and badminton competition. \nPlace- Bengaluru\n\n\n\n\n\n\n\nPradyut Parida\n\nDate- 01st OCT 2017\nGE Internal\nGE Internal","annotation":[{"label":["Location"],"points":[{"start":7642,"end":7650,"text":"Bengaluru"}]},{"label":["Education"],"points":[{"start":7256,"end":7261,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":5175,"end":5177,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":5163,"end":5165,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4611,"end":4613,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":839,"end":841,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":810,"end":812,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":803,"end":805,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":796,"end":798,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":487,"end":489,"text":"SQL"}]},{"label":["Name"],"points":[{"start":60,"end":80,"text":"Pradyut Kumar Parida "}]},{"label":["Skills"],"points":[{"start":29,"end":46,"text":"R Programming & ML"}]}],"extras":null,"metadata":{"first_done_at":1532675599000,"last_updated_at":1532675599000,"sec_taken":118,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}
{"content": "Pranav Kumar Virivada   \nTE-3.3 Yrs\n\nRE-3 Yrs\n\nC CTC-5.5 LPA\n\nEX CTC-7.5 LPA\n\nNP- 90 days\n\n1-46, Madhapur, Hyderabad, Telangana, India-500081\nPhone: +91 9441522445/9014131765 \nEmail: pranav.virivada@gmail.com\nCAREER OBJECTIVE\nA Data Science Enthusiast seeking full time position as Data Analyst/Scientist  where I get chance to advance my skills and gain Expertise on cutting edge technologies,Whlile delivering excellence in terms of work and value creation to organisation.\nSkills Summary\n\n· Data Science : Linear Regression, Logistic Regression, Time Series Analysis, Decision Trees, Clustering and PCA Techniques, Text Mining and Random forest.\n\n· Data-preprocessing and Data Cleaning.\n\n· Programming Languages : R Programming, Unix Scripting, SAS.\n· Good Knowledge on Statistics & Probability.\n\n· Environments : Microsoft Windows, Unix, Oracle Weblogic server.\n\n· Working knowledge on PL/SQL.\n· Good Knowledge on Hadoop Ecosystem.\n\nEducation\n\n· B.Tech (Electronics and Communication Engineering) from SRKR Engineering College (affiliated to Andhra University) in year 2013 with 8.4(Percentile).\n\n· 12th class from Sri Chaitanya Educational institute. Vijayawada (Andhra Pradesh Board of Intermediate) in year 2009 with 95.6%.\n\n· 10th class from Montessori EM Concept school(Andhra Pradesh Secondary Education in year 2007) with 91.8%.\n\nCertification Program in BIG DATA ANALYTICS & OPTIMIZATION –\n\nINTERNATIONAL SCHOOL OF ENGINEERING (INSOFE), HYDERABAD, \n\nCERTIFIED BY LTI OF CARNEGIE MELLON UNIVERSITY.\nExperience\n\tCompany Name\n\tDesignation\n\tStart date\n\tEnd Date\n\n\tAccenture Services Private Limited, Hyderabad\n\t   Data Analyst\n\t8th Jan- 2014\n\tTill Date\n\n\nProject working on:\n\n           Currently working on Churn Prediction in Telecom Domain Project.\n\n                                            Liberty Global is a leading telecom services provider in Europe. It has a vast subscriber base, around 11 million mobile subscribers and 7 million WiFi access points. Our main goal is to predict churn for this telecom major. Churn with respect to the Telecom industry, is defined as the percentage of subscribers moving from a specific service or a service provider to another in a given period of time. Given the data of users’ call and data usage patterns and demographics.\nRoles and Responsibilities:\n\n                     Data Pre-processing and Data Cleaning including Data Gathering. Collecting the information from various databases using pl/sql developer.\n Building a global model that predicts churn of the entire subscriber base, where overall misclassification rate should be minimized.\n  Clustering the subscribers based on their usage patterns and build local models across the clusters, where overall misclassification rate is minimized.\n \nTechnologies used: Random forest and Logistic Regression techniques.\n\nProgramming Languages: R programming and SAS.\n\nJan-14 to June-15:\n\n· Well experienced in supporting applications and handling critical situations including maintenance of the application with L2, L3 and Environment Management(EM) Support type supports mostly. \n\n· Automating daily activities with the aid of shell scripts\n\n· Working on high scheduled /emergency maintenance releases.\n\n· Experienced in environment readiness of the applications for deployments. Supporting/Maintaining applications, currently which have more than 100000 users globally. \n\n· Excellent communication, presentation, client facing, problem solving skills and willingness to work in a high pressured environment. \n\n· Experienced in working with different teams with a diverse group of developers, SME’s, project management from multiple teams with assertiveness and tact. \n\n· Application Support for Remedy based ticketing application, Sever maintenance and issue resolution. \n\n· Having great trouble shooting and debugging skills depth research process.\n\n\nCertifications:\nBUSINESS ANALYSIS FOUNDATION CERTIFICATE, BRITISH COMPUTER SOCIETY.\n R-PROGRAMING, JOHNS HOPKINS UNIVERSITY (ONLINE MODE COURSERA)\n\nAwards and Acknowledgements:\nAccenture Celebrates Excellence (ACE) Award (Top-Most Award in Accenture)\nFor demonstrating ownership and working to reduce time and costs on Projects.\n3 times – Star performer of the Month Award.\nFor continuous dedication towards work and Flexibility.\nPERSONAL DETAILS:\nFULL NAME                \n: V H D Pranav Kumar. \n\nFATHER’S NAME         \n: V Anji Babu\nMOTHERS’S NAME      \n: V Eswari \n\nDATE OF BIRTH          \n: 26-August-1992 \n\nAGE                          \n: 25\nSEX                           \n: Male\nNATIONALITY             \n: Indian \n\nLANGUAGES KNOWN      : English, Telugu and Hindi. \n\nDECLARATION: \n        I hereby declare that above mentioned particulars are true to the best of my knowledge and I bear the responsibility for the correctness of the above mentioned particulars.\n\nPlace:                                                                                                                           Yours sincerely,                \n\nHYDERABAD                                                                                                                  Pranav Kumar\n2","annotation":[{"label":["Skills"],"points":[{"start":2872,"end":2874,"text":"SAS"}]},{"label":["Location"],"points":[{"start":1608,"end":1616,"text":"Hyderabad"}]},{"label":["Education"],"points":[{"start":950,"end":955,"text":"B.Tech"}]},{"label":["Skills"],"points":[{"start":918,"end":933,"text":"Hadoop Ecosystem"}]},{"label":["Skills"],"points":[{"start":890,"end":895,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":748,"end":750,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":732,"end":745,"text":"Unix Scripting"}]},{"label":["Skills"],"points":[{"start":717,"end":729,"text":"R Programming"}]},{"label":["Location"],"points":[{"start":107,"end":115,"text":"Hyderabad"}]},{"label":["Name"],"points":[{"start":0,"end":22,"text":"Pranav Kumar Virivada  "}]}],"extras":null,"metadata":{"first_done_at":1532693147000,"last_updated_at":1532693147000,"sec_taken":74,"last_updated_by":"kxUAQF0uE0T0UqJtMqM0rbU9FW52","status":"done","evaluation":"NONE"}}