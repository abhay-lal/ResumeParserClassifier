{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-29T11:25:26.925938Z","iopub.execute_input":"2022-06-29T11:25:26.926648Z","iopub.status.idle":"2022-06-29T11:25:26.934118Z","shell.execute_reply.started":"2022-06-29T11:25:26.926613Z","shell.execute_reply":"2022-06-29T11:25:26.933044Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nimport torch\nfrom transformers import BertTokenizer\nfrom transformers import RobertaTokenizer\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel,RobertaModel\nfrom transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:25:32.573786Z","iopub.execute_input":"2022-06-29T11:25:32.574242Z","iopub.status.idle":"2022-06-29T11:25:43.049759Z","shell.execute_reply.started":"2022-06-29T11:25:32.574203Z","shell.execute_reply":"2022-06-29T11:25:43.048791Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:37:01.122458Z","iopub.execute_input":"2022-06-29T11:37:01.123577Z","iopub.status.idle":"2022-06-29T11:37:01.191075Z","shell.execute_reply.started":"2022-06-29T11:37:01.123526Z","shell.execute_reply":"2022-06-29T11:37:01.190022Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/resumecorpus-cleaned/finale.csv\", index_col=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:26:06.308421Z","iopub.execute_input":"2022-06-29T11:26:06.309552Z","iopub.status.idle":"2022-06-29T11:26:14.301242Z","shell.execute_reply.started":"2022-06-29T11:26:06.309506Z","shell.execute_reply":"2022-06-29T11:26:14.300242Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:37:40.548608Z","iopub.execute_input":"2022-06-29T14:37:40.549110Z","iopub.status.idle":"2022-06-29T14:37:40.556865Z","shell.execute_reply.started":"2022-06-29T14:37:40.549067Z","shell.execute_reply":"2022-06-29T14:37:40.555710Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:26:22.963593Z","iopub.execute_input":"2022-06-29T11:26:22.964404Z","iopub.status.idle":"2022-06-29T11:26:22.994262Z","shell.execute_reply.started":"2022-06-29T11:26:22.964363Z","shell.execute_reply":"2022-06-29T11:26:22.993308Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"classes = df.columns[2:12]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:27:07.091536Z","iopub.execute_input":"2022-06-29T11:27:07.092558Z","iopub.status.idle":"2022-06-29T11:27:07.097532Z","shell.execute_reply.started":"2022-06-29T11:27:07.092500Z","shell.execute_reply":"2022-06-29T11:27:07.096281Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:27:47.708121Z","iopub.execute_input":"2022-06-29T11:27:47.708514Z","iopub.status.idle":"2022-06-29T11:27:56.780796Z","shell.execute_reply.started":"2022-06-29T11:27:47.708456Z","shell.execute_reply":"2022-06-29T11:27:56.779684Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def preprocessing_for_bert(data):\n    input_ids = []\n    attention_masks = []\n    \n    for sent in data:\n        encoded_sent = tokenizer.encode_plus(\n            text = sent,   #preprocess sentence\n            add_special_tokens = True,         #Add `[CLS]` and `[SEP]`\n            max_length= MAX_LEN  ,             #Max length to truncate/pad\n            pad_to_max_length = True,          #pad sentence to max length \n            return_attention_mask= True        #Return attention mask \n        )\n        input_ids.append(encoded_sent.get('input_ids'))\n        attention_masks.append(encoded_sent.get('attention_mask'))\n        \n    input_ids = torch.tensor(input_ids)\n    attention_masks = torch.tensor(attention_masks)\n    \n    return input_ids,attention_masks","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:27:56.805200Z","iopub.execute_input":"2022-06-29T11:27:56.806392Z","iopub.status.idle":"2022-06-29T11:27:56.814982Z","shell.execute_reply.started":"2022-06-29T11:27:56.806367Z","shell.execute_reply":"2022-06-29T11:27:56.813945Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"all_text = np.concatenate([df.Ents])\nlen_sent = [len(sent) for sent in all_text]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:28:27.056796Z","iopub.execute_input":"2022-06-29T11:28:27.057172Z","iopub.status.idle":"2022-06-29T11:28:27.069402Z","shell.execute_reply.started":"2022-06-29T11:28:27.057135Z","shell.execute_reply":"2022-06-29T11:28:27.068212Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"avg_len = np.mean(len_sent)\nprint('Avg length: ',avg_len)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:28:29.899206Z","iopub.execute_input":"2022-06-29T11:28:29.900017Z","iopub.status.idle":"2022-06-29T11:28:29.909028Z","shell.execute_reply.started":"2022-06-29T11:28:29.899978Z","shell.execute_reply":"2022-06-29T11:28:29.907984Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df.Ents.values\ny = df[classes].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2022)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:28:39.574273Z","iopub.execute_input":"2022-06-29T11:28:39.574663Z","iopub.status.idle":"2022-06-29T11:28:39.590780Z","shell.execute_reply.started":"2022-06-29T11:28:39.574630Z","shell.execute_reply":"2022-06-29T11:28:39.589895Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_test[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:05:31.098719Z","iopub.execute_input":"2022-06-29T16:05:31.099673Z","iopub.status.idle":"2022-06-29T16:05:31.109251Z","shell.execute_reply.started":"2022-06-29T16:05:31.099605Z","shell.execute_reply":"2022-06-29T16:05:31.108115Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\n\ntoken_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\nprint('Original: ',X[0])\nprint('Token IDs: ',token_ids)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:28:56.345464Z","iopub.execute_input":"2022-06-29T11:28:56.346125Z","iopub.status.idle":"2022-06-29T11:28:56.364253Z","shell.execute_reply.started":"2022-06-29T11:28:56.346091Z","shell.execute_reply":"2022-06-29T11:28:56.363027Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_inputs, train_masks = preprocessing_for_bert(X_train)\ntest_inputs, test_masks = preprocessing_for_bert(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:29:10.588327Z","iopub.execute_input":"2022-06-29T11:29:10.589031Z","iopub.status.idle":"2022-06-29T11:32:53.283429Z","shell.execute_reply.started":"2022-06-29T11:29:10.588989Z","shell.execute_reply":"2022-06-29T11:32:53.282459Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_labels = torch.tensor(y_train)\ntest_labels = torch.tensor(y_test)\n\nbatch_size = 8\n\n# Create the DataLoader for our training set\ntrain_data = TensorDataset(train_inputs,train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# Create the DataLoader for our validation set\ntest_data = TensorDataset(test_inputs, test_masks, test_labels)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:32:53.285534Z","iopub.execute_input":"2022-06-29T11:32:53.285882Z","iopub.status.idle":"2022-06-29T11:32:53.293539Z","shell.execute_reply.started":"2022-06-29T11:32:53.285846Z","shell.execute_reply":"2022-06-29T11:32:53.292534Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n    def __init__(self, freeze_bert=False):\n        super(BertClassifier,self).__init__()\n        # Specify hidden size of Bert, hidden size of our classifier, and number of labels\n        D_in, H,D_out = 768,30,10\n        \n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        \n        self.classifier = nn.Sequential(\n                            nn.Linear(D_in, H),\n                            nn.ReLU(),\n                            nn.Linear(H, D_out))\n        self.sigmoid = nn.Sigmoid()\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n    \n    def forward(self,input_ids,attention_mask):\n        outputs = self.bert(input_ids=input_ids,\n                           attention_mask = attention_mask)\n        \n        # Extract the last hidden state of the token `[CLS]` for classification task\n        last_hidden_state_cls = outputs[0][:,0,:]\n        \n        # Feed input to classifier to compute logits\n        logit = self.classifier(last_hidden_state_cls)\n        \n#         logits = self.sigmoid(logit)\n        \n        return logit","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:34:19.182250Z","iopub.execute_input":"2022-06-29T11:34:19.182867Z","iopub.status.idle":"2022-06-29T11:34:19.192606Z","shell.execute_reply.started":"2022-06-29T11:34:19.182828Z","shell.execute_reply":"2022-06-29T11:34:19.191445Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def initialize_model(epochs=20):\n    \n    bert_classifier = BertClassifier(freeze_bert=False)\n    bert_classifier.to(device)\n    optimizer = AdamW(bert_classifier.parameters(),\n                     lr=5e-5, \n                     eps=1e-8 \n                     )\n\n    total_steps = len(train_dataloader) * epochs\n    \n    scheduler = get_linear_schedule_with_warmup(optimizer, \n                                              num_warmup_steps=0, \n                                              num_training_steps=total_steps)\n    return bert_classifier, optimizer, scheduler","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:34:51.817668Z","iopub.execute_input":"2022-06-29T11:34:51.818030Z","iopub.status.idle":"2022-06-29T11:34:51.824854Z","shell.execute_reply.started":"2022-06-29T11:34:51.818000Z","shell.execute_reply":"2022-06-29T11:34:51.823879Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport random\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:34:33.109319Z","iopub.execute_input":"2022-06-29T11:34:33.109798Z","iopub.status.idle":"2022-06-29T11:34:33.114250Z","shell.execute_reply.started":"2022-06-29T11:34:33.109766Z","shell.execute_reply":"2022-06-29T11:34:33.113281Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()\n\ndef set_seed(seed_value=42):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)\n\ndef train(model, train_dataloader, test_dataloader=None, epochs=20, evaluation=False):\n    print(\"Start training...\\n\")\n    for epoch_i in range(epochs):\n        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Test Loss':^10} | {'Test Acc':^9} | {'Elapsed':^9}\")\n        print(\"-\"*70)\n\n        t0_epoch, t0_batch = time.time(), time.time()\n\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n\n        model.train()\n\n        for step, batch in enumerate(train_dataloader):\n            batch_counts +=1\n       \n            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n\n        \n            model.zero_grad()\n\n            logits = model(b_input_ids, b_attn_mask)\n\n            loss = loss_fn(logits, b_labels.float())\n            batch_loss += loss.item()\n            total_loss += loss.item()\n\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            optimizer.step()\n            scheduler.step()\n\n            if (step % 50000 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n                # Calculate time elapsed for 20 batches\n                time_elapsed = time.time() - t0_batch\n\n                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n\n                batch_loss, batch_counts = 0, 0\n                t0_batch = time.time()\n\n        avg_train_loss = total_loss / len(train_dataloader)\n\n        print(\"-\"*70)\n\n        if evaluation == True:\n\n            test_loss, test_accuracy = evaluate(model, test_dataloader)\n\n            time_elapsed = time.time() - t0_epoch\n            \n            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {test_loss:^10.6f} | {test_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n            print(\"-\"*70)\n        print(\"\\n\")\n    \n    print(\"Training complete!!!\")\n\n\ndef evaluate(model, test_dataloader):\n   \n    model.eval()\n\n    test_accuracy = []\n    test_loss = []\n\n    # For each batch in our validation set...\n    for batch in test_dataloader:\n        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n\n        with torch.no_grad():\n            logits = model(b_input_ids, b_attn_mask)\n\n        loss = loss_fn(logits, b_labels.float())\n        test_loss.append(loss.item())\n\n        accuracy = accuracy_thresh(logits.view(-1,10),b_labels.view(-1,10))\n        \n        test_accuracy.append(accuracy)\n\n    test_loss = np.mean(test_loss)\n    test_accuracy = np.mean(test_accuracy)\n\n    return test_loss, test_accuracy\n\ndef accuracy_thresh(y_pred, y_true, thresh:float=0.5, sigmoid:bool=True):\n    if sigmoid: \n        y_pred = y_pred.sigmoid()\n    return ((y_pred>thresh)==y_true.byte()).float().mean().item()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:49:33.678618Z","iopub.execute_input":"2022-06-29T11:49:33.678966Z","iopub.status.idle":"2022-06-29T11:49:33.697527Z","shell.execute_reply.started":"2022-06-29T11:49:33.678936Z","shell.execute_reply":"2022-06-29T11:49:33.696555Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"set_seed(42)    \nbert_classifier, optimizer, scheduler = initialize_model(epochs=1)\ntrain(bert_classifier, train_dataloader, test_dataloader, epochs=1, evaluation=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T11:49:38.174040Z","iopub.execute_input":"2022-06-29T11:49:38.174390Z","iopub.status.idle":"2022-06-29T12:15:06.302732Z","shell.execute_reply.started":"2022-06-29T11:49:38.174361Z","shell.execute_reply":"2022-06-29T12:15:06.301562Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def bert_predict(model, test_dataloader):\n\n    model.eval()\n\n    all_logits = []\n\n    for batch in test_dataloader:\n        # Load batch to GPU\n        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n\n        # Compute logits\n        with torch.no_grad():\n            logits = model(b_input_ids, b_attn_mask)\n        all_logits.append(logits)\n    \n    # Concatenate logits from each batch\n    all_logits = torch.cat(all_logits, dim=0)\n\n    # Apply softmax to calculate probabilities\n    #probs = F.softmax(all_logits, dim=1).cpu().numpy()\n    probs = all_logits.sigmoid().cpu().numpy()\n    \n\n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-06-29T12:20:43.292784Z","iopub.execute_input":"2022-06-29T12:20:43.293151Z","iopub.status.idle":"2022-06-29T12:20:43.300850Z","shell.execute_reply.started":"2022-06-29T12:20:43.293119Z","shell.execute_reply":"2022-06-29T12:20:43.299697Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"probs = bert_pre(bert_classifier,train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:33:14.403409Z","iopub.execute_input":"2022-06-29T15:33:14.404118Z","iopub.status.idle":"2022-06-29T15:40:52.978763Z","shell.execute_reply.started":"2022-06-29T15:33:14.404083Z","shell.execute_reply":"2022-06-29T15:40:52.977793Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"probs.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:51:15.299185Z","iopub.execute_input":"2022-06-29T15:51:15.299743Z","iopub.status.idle":"2022-06-29T15:51:15.311950Z","shell.execute_reply.started":"2022-06-29T15:51:15.299704Z","shell.execute_reply":"2022-06-29T15:51:15.310809Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(probs,columns=['Software_Developer', 'Database_Administrator', 'Systems_Administrator',\n       'Project_manager', 'Web_Developer', 'Network_Administrator',\n       'Security_Analyst', 'Python_Developer', 'Java_Developer',\n       'Front_End_Developer'])","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:53:45.024542Z","iopub.execute_input":"2022-06-29T15:53:45.024919Z","iopub.status.idle":"2022-06-29T15:53:45.031413Z","shell.execute_reply.started":"2022-06-29T15:53:45.024888Z","shell.execute_reply":"2022-06-29T15:53:45.030347Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"./train.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:02:28.528010Z","iopub.execute_input":"2022-06-29T16:02:28.528626Z","iopub.status.idle":"2022-06-29T16:02:28.868341Z","shell.execute_reply.started":"2022-06-29T16:02:28.528591Z","shell.execute_reply":"2022-06-29T16:02:28.867280Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"y_train[:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:07:56.071239Z","iopub.execute_input":"2022-06-29T16:07:56.071744Z","iopub.status.idle":"2022-06-29T16:07:56.080319Z","shell.execute_reply.started":"2022-06-29T16:07:56.071699Z","shell.execute_reply":"2022-06-29T16:07:56.079240Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:54:53.517426Z","iopub.execute_input":"2022-06-29T15:54:53.518030Z","iopub.status.idle":"2022-06-29T15:54:53.537339Z","shell.execute_reply.started":"2022-06-29T15:54:53.517988Z","shell.execute_reply":"2022-06-29T15:54:53.535843Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"y_test[:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:54:36.862990Z","iopub.execute_input":"2022-06-29T15:54:36.863338Z","iopub.status.idle":"2022-06-29T15:54:36.870033Z","shell.execute_reply.started":"2022-06-29T15:54:36.863308Z","shell.execute_reply":"2022-06-29T15:54:36.869011Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"full_train_data = torch.utils.data.ConcatDataset([train_data, test_data])\nfull_train_sampler = RandomSampler(full_train_data)\nfull_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=batch_size)\n\nset_seed(42)\nbert_classifier, optimizer, scheduler = initialize_model(epochs=4)\ntrain(bert_classifier, full_train_dataloader, epochs=4)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T12:33:09.322189Z","iopub.execute_input":"2022-06-29T12:33:09.322923Z","iopub.status.idle":"2022-06-29T14:22:20.188941Z","shell.execute_reply.started":"2022-06-29T12:33:09.322884Z","shell.execute_reply":"2022-06-29T14:22:20.187947Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"torch.save(bert_classifier.state_dict(), \"bert.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:54:50.128596Z","iopub.execute_input":"2022-06-29T14:54:50.129165Z","iopub.status.idle":"2022-06-29T14:54:51.161739Z","shell.execute_reply.started":"2022-06-29T14:54:50.129130Z","shell.execute_reply":"2022-06-29T14:54:51.160543Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"## Run preprocessing_for_bert on the test set\nprint('Tokenizing data...')\ntest_inputs, test_masks = preprocessing_for_bert(X_test)\n\n# Create the DataLoader for our test set\ntest_dataset = TensorDataset(test_inputs, test_masks)\ntest_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:33:02.925826Z","iopub.execute_input":"2022-06-29T14:33:02.926639Z","iopub.status.idle":"2022-06-29T14:33:24.397643Z","shell.execute_reply.started":"2022-06-29T14:33:02.926603Z","shell.execute_reply":"2022-06-29T14:33:24.396553Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"probs2 = bert_predict(bert_classifier, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:33:41.274563Z","iopub.execute_input":"2022-06-29T14:33:41.275607Z","iopub.status.idle":"2022-06-29T14:34:30.558920Z","shell.execute_reply.started":"2022-06-29T14:33:41.275565Z","shell.execute_reply":"2022-06-29T14:34:30.557944Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"probs.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:35:49.716546Z","iopub.execute_input":"2022-06-29T14:35:49.717646Z","iopub.status.idle":"2022-06-29T14:35:49.723997Z","shell.execute_reply.started":"2022-06-29T14:35:49.717598Z","shell.execute_reply":"2022-06-29T14:35:49.722793Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(probs2,columns=['Software_Developer', 'Database_Administrator', 'Systems_Administrator',\n       'Project_manager', 'Web_Developer', 'Network_Administrator',\n       'Security_Analyst', 'Python_Developer', 'Java_Developer',\n       'Front_End_Developer'])\n'''\ntest[['Software_Developer', 'Database_Administrator', 'Systems_Administrator',\n       'Project_manager', 'Web_Developer', 'Network_Administrator',\n       'Security_Analyst', 'Python_Developer', 'Java_Developer',\n       'Front_End_Developer']]=submission\nfinal_sub = test[['Software_Developer', 'Database_Administrator', 'Systems_Administrator',\n       'Project_manager', 'Web_Developer', 'Network_Administrator',\n       'Security_Analyst', 'Python_Developer', 'Java_Developer',\n       'Front_End_Developer']]\nfinal_sub.head()\n'''","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:08:54.893217Z","iopub.execute_input":"2022-06-29T16:08:54.893665Z","iopub.status.idle":"2022-06-29T16:08:54.911457Z","shell.execute_reply.started":"2022-06-29T16:08:54.893624Z","shell.execute_reply":"2022-06-29T16:08:54.910167Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-29T14:42:19.738005Z","iopub.execute_input":"2022-06-29T14:42:19.738463Z","iopub.status.idle":"2022-06-29T14:42:19.748695Z","shell.execute_reply.started":"2022-06-29T14:42:19.738422Z","shell.execute_reply":"2022-06-29T14:42:19.747564Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"./test.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:09:01.276232Z","iopub.execute_input":"2022-06-29T16:09:01.276626Z","iopub.status.idle":"2022-06-29T16:09:01.321848Z","shell.execute_reply.started":"2022-06-29T16:09:01.276592Z","shell.execute_reply":"2022-06-29T16:09:01.320969Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:09:03.202432Z","iopub.execute_input":"2022-06-29T16:09:03.203386Z","iopub.status.idle":"2022-06-29T16:09:03.219568Z","shell.execute_reply.started":"2022-06-29T16:09:03.203351Z","shell.execute_reply":"2022-06-29T16:09:03.218614Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:09:17.707755Z","iopub.execute_input":"2022-06-29T16:09:17.708371Z","iopub.status.idle":"2022-06-29T16:09:17.714237Z","shell.execute_reply.started":"2022-06-29T16:09:17.708333Z","shell.execute_reply":"2022-06-29T16:09:17.713330Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"y_test[:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:26:38.655826Z","iopub.execute_input":"2022-06-29T15:26:38.656816Z","iopub.status.idle":"2022-06-29T15:26:38.663322Z","shell.execute_reply.started":"2022-06-29T15:26:38.656766Z","shell.execute_reply":"2022-06-29T15:26:38.662273Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-29T15:27:08.318779Z","iopub.execute_input":"2022-06-29T15:27:08.319236Z","iopub.status.idle":"2022-06-29T15:27:08.326825Z","shell.execute_reply.started":"2022-06-29T15:27:08.319195Z","shell.execute_reply":"2022-06-29T15:27:08.325548Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnp.savetxt(\"y-test-kaggle.txt\", y_test, fmt=\"%f\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T16:30:01.457890Z","iopub.execute_input":"2022-06-29T16:30:01.458554Z","iopub.status.idle":"2022-06-29T16:30:01.480555Z","shell.execute_reply.started":"2022-06-29T16:30:01.458519Z","shell.execute_reply":"2022-06-29T16:30:01.479669Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}